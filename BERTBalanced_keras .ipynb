{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "BERTBalanced_keras.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-v82rA5qF1eA",
        "outputId": "09fe840d-7a85-4b7c-d2a9-0469cb608bac"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCE9CLR6F23W",
        "outputId": "12319a60-e1ba-41f6-d647-a3a07c30cf5a"
      },
      "source": [
        "!pip install keras-bert"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras-bert in /usr/local/lib/python3.6/dist-packages (0.86.0)\n",
            "Requirement already satisfied: Keras>=2.4.3 in /usr/local/lib/python3.6/dist-packages (from keras-bert) (2.4.3)\n",
            "Requirement already satisfied: keras-transformer>=0.38.0 in /usr/local/lib/python3.6/dist-packages (from keras-bert) (0.38.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-bert) (1.19.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.4.3->keras-bert) (2.10.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.4.3->keras-bert) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.4.3->keras-bert) (3.13)\n",
            "Requirement already satisfied: keras-layer-normalization>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from keras-transformer>=0.38.0->keras-bert) (0.14.0)\n",
            "Requirement already satisfied: keras-position-wise-feed-forward>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from keras-transformer>=0.38.0->keras-bert) (0.6.0)\n",
            "Requirement already satisfied: keras-multi-head>=0.27.0 in /usr/local/lib/python3.6/dist-packages (from keras-transformer>=0.38.0->keras-bert) (0.27.0)\n",
            "Requirement already satisfied: keras-embed-sim>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from keras-transformer>=0.38.0->keras-bert) (0.8.0)\n",
            "Requirement already satisfied: keras-pos-embd>=0.11.0 in /usr/local/lib/python3.6/dist-packages (from keras-transformer>=0.38.0->keras-bert) (0.11.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->Keras>=2.4.3->keras-bert) (1.15.0)\n",
            "Requirement already satisfied: keras-self-attention==0.46.0 in /usr/local/lib/python3.6/dist-packages (from keras-multi-head>=0.27.0->keras-transformer>=0.38.0->keras-bert) (0.46.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Eh-sgIjGHaa"
      },
      "source": [
        "import os\n",
        "os.environ['TF_KERAS'] = '1'    # Required to use tensorflow.python.keras with keras-bert"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a--BKbtTGJwY"
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXlI_3KOGLtf",
        "outputId": "220c96c6-7cd9-4009-b1ee-71296ed2cffe"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "    print('We will use the GPU:', device_name)\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "We will use the GPU: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4E1D2R2qGNVU"
      },
      "source": [
        "train = pd.read_csv('/content/drive/My Drive/Colab Notebooks/train_file.txt', sep='{}{}{}', engine = 'python')\n",
        "test = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/test_file.txt\", sep= '{}{}{}', engine = 'python')\n",
        "\n",
        "#from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, val =  train,test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4t22qlGLILMN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3kcZjJQGU6s",
        "outputId": "6830e3cf-9713-40e1-a444-2cd0c248cb4c"
      },
      "source": [
        "# Give -nc (--no-clobber) argument so that the file isn't downloaded multiple times \n",
        "!wget -nc https://storage.googleapis.com/bert_models/2018_10_18/cased_L-12_H-768_A-12.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File ‘cased_L-12_H-768_A-12.zip’ already there; not retrieving.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCTHImPIG-mJ",
        "outputId": "c0851da5-fe55-4b7e-e9bb-9c686fb41eba"
      },
      "source": [
        "# Give -n argument so that existing files aren't overwritten \n",
        "!unzip -n cased_L-12_H-768_A-12.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  cased_L-12_H-768_A-12.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-UK3uFSHBDT"
      },
      "source": [
        "bert_vocab_path = 'cased_L-12_H-768_A-12/vocab.txt'\n",
        "bert_config_path = 'cased_L-12_H-768_A-12/bert_config.json'\n",
        "bert_checkpoint_path = 'cased_L-12_H-768_A-12/bert_model.ckpt'    # suffixes not required"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8sqldgoHDZp"
      },
      "source": [
        "model_is_cased = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "_OpqP4RwHFN4",
        "outputId": "fe1fa14b-be3a-4d10-84a4-2b6a76d0b6b5"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "\n",
        "train = shuffle(train)\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>14448</th>\n",
              "      <td>__label__df</td>\n",
              "      <td>I know that sounds silly. I have always been t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1562</th>\n",
              "      <td>__label__ss</td>\n",
              "      <td>Legends of the Maori  The Taniwha -- The Landi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13887</th>\n",
              "      <td>__label__sr</td>\n",
              "      <td>'Supersub' Is Not A Slur Edin  Edin Dzeko may ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5137</th>\n",
              "      <td>__label__ne</td>\n",
              "      <td>Cookies on the IWCP website  This website uses...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11001</th>\n",
              "      <td>__label__ds</td>\n",
              "      <td>Bradford Theatres would like to make you aware...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Label                                               Text\n",
              "14448  __label__df  I know that sounds silly. I have always been t...\n",
              "1562   __label__ss  Legends of the Maori  The Taniwha -- The Landi...\n",
              "13887  __label__sr  'Supersub' Is Not A Slur Edin  Edin Dzeko may ...\n",
              "5137   __label__ne  Cookies on the IWCP website  This website uses...\n",
              "11001  __label__ds  Bradford Theatres would like to make you aware..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4voXgqORK1r",
        "outputId": "30d407d5-f791-465f-f04f-1fe1a4e3f1dc"
      },
      "source": [
        "vocabulary = []\r\n",
        "with open(bert_vocab_path) as f:\r\n",
        "    for i, line in enumerate(f):\r\n",
        "        vocabulary.append(line.rstrip('\\n'))    # rstrip to remove newline characters\r\n",
        "\r\n",
        "\r\n",
        "# Print a list with every 100th vocabulary item\r\n",
        "print(vocabulary[0::100])\r\n",
        "print(len(vocabulary))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[PAD]', '[UNK]', '¡', 'İ', 'Θ', 'щ', 'ک', 'ი', '⁰', 'く', '吉', '－', '##er', 'four', 'got', 'told', 'James', 'position', 'someone', 'director', 'space', 'hear', '##ized', 'Force', 'property', 'operations', 'Irish', 'selected', 'Line', 'native', 'proposed', 'Will', 'ones', 'account', 'concept', 'Oxford', 'tight', 'Historic', 'Junior', 'Cambridge', 'showing', 'Ford', 'Round', 'institutions', 'usual', 'domestic', 'solid', 'hockey', 'Design', 'shock', 'mountains', '##tta', 'presidential', 'signs', 'gate', 'commission', 'rates', '##gs', '##ess', 'heritage', 'voices', 'gonna', 'Stars', 'exit', 'LP', 'associate', 'stress', 'experimental', 'merchant', 'Chart', 'hills', 'brings', '##war', 'clinical', 'manufacturer', 'Guide', 'coaching', 'wire', 'Sophie', 'Voice', 'relaxed', 'planted', 'connects', 'owns', 'threatening', 'Page', 'examined', 'Casey', 'Armstrong', '##RS', 'Heights', 'resource', '1830', 'Joey', '##ination', 'singers', 'desperately', 'halt', 'Ho', '##ander', 'Interior', 'explaining', 'Clara', 'developers', 'essay', 'considers', 'Excellence', 'strategies', 'Legal', 'surveillance', 'facilitate', 'introducing', 'cure', 'Inter', 'Francesco', 'shouting', 'Vic', '##usa', 'jungle', 'Cave', '1826', 'foster', 'bull', 'decorative', 'gentleman', 'constitute', 'tide', 'Solar', 'brutal', 'Aria', 'alter', 'outskirts', '##lop', 'advantages', 'Canberra', 'clip', 'Rise', 'Luna', 'freshwater', 'valleys', 'Into', 'drowned', '##alis', '##yte', 'unnamed', 'Memory', 'Vista', 'Dunn', '##я', 'confessed', 'ballad', '##ilization', 'reddish', '##scope', 'witches', 'Owens', 'bind', 'mirrors', 'curtains', 'Mk', 'Langdon', '##beth', 'tapes', 'posters', 'Brenda', 'aquatic', 'reproduction', 'developmental', 'Sunset', 'discusses', 'stereo', 'Rocket', 'campaigned', 'Monthly', 'denying', 'Cass', '##25', 'panting', '##cover', 'perfection', 'Shock', '##bedience', 'sampling', 'violinist', 'abused', '195', 'Saul', 'pepper', 'oversee', '##warm', '##tec', 'axle', 'Seal', 'piled', '##VR', '##sonic', 'norms', '##uria', 'ideological', 'Tall', 'attested', 'Nike', 'disqualified', '##istan', 'bowls', '##rdes', 'mystical', 'bump', '##ishi', '##mper', '1840s', 'accusation', '##watch', 'Understanding', 'gamma', '##90', 'battled', 'Bin', 'tactic', 'Wolverhampton', 'Guys', 'Gareth', 'Jesuits', '##having', '##biotic', '##rien', '##ndy', 'Giving', 'boilers', '##9th', 'Munro', '226', 'collaborate', 'Thatcher', 'skeletal', 'Ursula', 'ecosystems', 'dub', 'brewing', 'Sunrise', 'mesh', 'amazement', '##rgus', '##Pad', '##01', 'diplomacy', 'Sovereign', 'Mead', 'Martial', 'Diamonds', 'Newmarket', '##neer', 'banging', '##kner', 'compatibility', '##oughs', 'clicking', 'Lyndon', 'Incorporated', 'McCormick', 'synthesizers', 'vase', '##graving', '##tized', 'dictator', 'Drugs', 'pulmonary', 'buffalo', '##urage', '##uristic', 'monstrous', 'bliss', '272', '##hesia', 'Bit', '##ynamic', '##logies', 'Belinda', '##liography', 'Bai', 'troll', '##agger', '##æ', '##ʷ', '##л', '##ٹ', '##ོ', '##″', '##そ', '##城']\n",
            "28996\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnDOoM0bHJ5y",
        "outputId": "62460293-67ba-42c0-b3ed-7aa5eddcf366"
      },
      "source": [
        "from pprint import pprint    # pretty-printer for output\n",
        "import json\n",
        "\n",
        "with open(bert_config_path) as f:\n",
        "    config = json.load(f)\n",
        "\n",
        "\n",
        "# Print configuration contents\n",
        "pprint(config)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'attention_probs_dropout_prob': 0.1,\n",
            " 'hidden_act': 'gelu',\n",
            " 'hidden_dropout_prob': 0.1,\n",
            " 'hidden_size': 768,\n",
            " 'initializer_range': 0.02,\n",
            " 'intermediate_size': 3072,\n",
            " 'max_position_embeddings': 512,\n",
            " 'num_attention_heads': 12,\n",
            " 'num_hidden_layers': 12,\n",
            " 'type_vocab_size': 2,\n",
            " 'vocab_size': 28996}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4t0UGv2MHM1t",
        "outputId": "9f03d69e-43cf-4c64-9199-8d5460a13752"
      },
      "source": [
        "import random\n",
        "# Create mapping from vocabulary items to their indices in the vocabulary\n",
        "token_dict = { v: i for i, v in enumerate(vocabulary) }\n",
        "\n",
        "\n",
        "# Print some random examples of the mapping\n",
        "pprint(dict(random.choices(list(token_dict.items()), k=15)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'##ydro': 19694,\n",
            " 'Chen': 8742,\n",
            " 'Romani': 27876,\n",
            " 'Samson': 19893,\n",
            " 'Tan': 13880,\n",
            " 'additional': 2509,\n",
            " 'crime': 3755,\n",
            " 'improve': 4607,\n",
            " 'infringement': 23040,\n",
            " 'leveled': 25569,\n",
            " 'reel': 24548,\n",
            " 'resembling': 16562,\n",
            " 'trapped': 7333,\n",
            " 'wicket': 13386,\n",
            " 'ো': 668}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbXynyasHP5b",
        "outputId": "2b6e7cb5-8d33-4917-fe8a-d132865d4234"
      },
      "source": [
        "from keras_bert import Tokenizer\n",
        "\n",
        "\n",
        "tokenizer = Tokenizer(token_dict, cased=model_is_cased)\n",
        "\n",
        "\n",
        "# Let's test that out\n",
        "for s in ['I am doing my NLP thesis']:\n",
        "    print('Original string:', s)\n",
        "    print('Tokenized:', tokenizer.tokenize(s))\n",
        "    indices, segments = tokenizer.encode(s, max_len=20)    # max_len for padding and truncation\n",
        "    print('Encoded:', indices)\n",
        "    print('Segments:', segments)\n",
        "    print('Decoded:', ' '.join(tokenizer.decode(indices)))\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original string: I am doing my NLP thesis\n",
            "Tokenized: ['[CLS]', 'I', 'am', 'doing', 'my', 'NL', '##P', 'thesis', '[SEP]']\n",
            "Encoded: [101, 146, 1821, 1833, 1139, 21239, 2101, 9593, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Segments: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Decoded: I am doing my NL ##P thesis\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnaayjIMHSsc",
        "outputId": "a0b59f65-d643-4b44-96cb-5780b7e837c5"
      },
      "source": [
        "#print(train['Text'].values[17587])\n",
        "len(tokenizer.tokenize(train['Text'].values[17587]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7624"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYYaTmKJHXAQ",
        "outputId": "234df22a-8c83-4121-8a48-aa4f44979831"
      },
      "source": [
        "train.head()\n",
        "train['Label'].values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['__label__df', '__label__ss', '__label__sr', ..., '__label__sr',\n",
              "       '__label__sr', '__label__ne'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N99fjhQ0J8N8",
        "outputId": "b37bcd98-7728-4cab-90cc-1824349e7c1f"
      },
      "source": [
        "#Label encoding the label columns\n",
        "\n",
        "label_encode = {}\n",
        "for i, v  in enumerate(train['Label'].unique()):\n",
        "  label_encode[v] = i\n",
        "label_encode"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'__label__av': 13,\n",
              " '__label__df': 0,\n",
              " '__label__dp': 12,\n",
              " '__label__ds': 4,\n",
              " '__label__dt': 9,\n",
              " '__label__en': 15,\n",
              " '__label__fi': 18,\n",
              " '__label__fs': 25,\n",
              " '__label__ha': 21,\n",
              " '__label__ht': 11,\n",
              " '__label__ib': 20,\n",
              " '__label__it': 19,\n",
              " '__label__ne': 3,\n",
              " '__label__ob': 5,\n",
              " '__label__pb': 10,\n",
              " '__label__po': 23,\n",
              " '__label__qa': 6,\n",
              " '__label__ra': 14,\n",
              " '__label__re': 8,\n",
              " '__label__rs': 16,\n",
              " '__label__rv': 7,\n",
              " '__label__sl': 17,\n",
              " '__label__sr': 2,\n",
              " '__label__ss': 1,\n",
              " '__label__tb': 22,\n",
              " '__label__tv': 24}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "JvqB5ZMHJ8Q-",
        "outputId": "cf892c51-d4cf-44cf-f822-19aa35d89bd4"
      },
      "source": [
        "train['Label_enc'] = train['Label'].map(label_encode)\n",
        "val['Label_enc'] = val['Label'].map(label_encode)\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Text</th>\n",
              "      <th>Label_enc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>14448</th>\n",
              "      <td>__label__df</td>\n",
              "      <td>I know that sounds silly. I have always been t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1562</th>\n",
              "      <td>__label__ss</td>\n",
              "      <td>Legends of the Maori  The Taniwha -- The Landi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13887</th>\n",
              "      <td>__label__sr</td>\n",
              "      <td>'Supersub' Is Not A Slur Edin  Edin Dzeko may ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5137</th>\n",
              "      <td>__label__ne</td>\n",
              "      <td>Cookies on the IWCP website  This website uses...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11001</th>\n",
              "      <td>__label__ds</td>\n",
              "      <td>Bradford Theatres would like to make you aware...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Label  ... Label_enc\n",
              "14448  __label__df  ...         0\n",
              "1562   __label__ss  ...         1\n",
              "13887  __label__sr  ...         2\n",
              "5137   __label__ne  ...         3\n",
              "11001  __label__ds  ...         4\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aR054CJHdj5",
        "outputId": "1c5097f9-8ed9-4c46-e337-424fba52c503"
      },
      "source": [
        "print(\"Training Set Shape :\", train.shape)\n",
        "print(\"Test Set Shape :\", val.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Set Shape : (17588, 3)\n",
            "Test Set Shape : (2210, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axqRqtaSJFqh",
        "outputId": "8d5fbf4f-c272-41b9-f24e-941c5457fe50"
      },
      "source": [
        "#Get value counts of each classes\n",
        "\n",
        "train['Label_enc'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3     5577\n",
              "2     1711\n",
              "5     1445\n",
              "0     1268\n",
              "10    1203\n",
              "9     1108\n",
              "7      802\n",
              "6      638\n",
              "11     586\n",
              "4      482\n",
              "17     369\n",
              "15     326\n",
              "16     323\n",
              "14     294\n",
              "20     236\n",
              "13     222\n",
              "12     213\n",
              "19     193\n",
              "21     145\n",
              "1      129\n",
              "22      90\n",
              "8       89\n",
              "18      76\n",
              "23      38\n",
              "25      16\n",
              "24       9\n",
              "Name: Label_enc, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVNFWSgpILJL"
      },
      "source": [
        "# Separate the dataset for the purpose of upsampling and downsampling based on threshold of 802\n",
        "\n",
        "trainDown = train[train['Label_enc'].map(train['Label_enc'].value_counts()) >= 802]\n",
        "trainUp = train[train['Label_enc'].map(train['Label_enc'].value_counts()) <= 802]\n",
        "#trainUp['Label_enc'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMYdaoslH7X5"
      },
      "source": [
        "# Separate the dataset for the purpose of upsampling and downsampling based on threshold of 802\n",
        "\n",
        "trainDown = train[train['Label_enc'].map(train['Label_enc'].value_counts()) >= 802]\n",
        "trainUp = train[train['Label_enc'].map(train['Label_enc'].value_counts()) <= 802]\n",
        "#trainUp['Label_enc'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVCpnT3FKTeC",
        "outputId": "4800f7cc-2cb0-4612-9fba-b77c0c25c8e3"
      },
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "rus = RandomUnderSampler(random_state=0)\n",
        "ros = RandomOverSampler(random_state = 0)\n",
        "\n",
        "X_down, y_down = rus.fit_resample(trainDown,trainDown['Label_enc'])\n",
        "X_up, u_up = ros.fit_resample(trainUp, trainUp['Label_enc'])\n",
        "# X_down, y_down = rus.fit_resample(trainDown['Text'], trainDown['Label'])\n",
        "# X_up, u_up = ros.fit_resample(trainUp['Text'], trainUp['Label'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlPIOTFFKWTv",
        "outputId": "915d3f16-038f-438f-dfd8-04c14104ebe7"
      },
      "source": [
        "Xd = pd.DataFrame(X_down, columns = ['Label','Text','Label_enc'])\n",
        "#Xd=Xd[Xd.Label_enc != 6]\n",
        "Xd['Label_enc'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10    802\n",
              "9     802\n",
              "7     802\n",
              "5     802\n",
              "3     802\n",
              "2     802\n",
              "0     802\n",
              "Name: Label_enc, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MMn2XPhKZdp",
        "outputId": "e3a59be7-df1f-4e0a-bdd6-bc478ba09d4e"
      },
      "source": [
        "Xu = pd.DataFrame(X_up, columns = ['Label','Text','Label_enc'])\n",
        "Xu['Label_enc'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25    802\n",
              "24    802\n",
              "4     802\n",
              "6     802\n",
              "7     802\n",
              "8     802\n",
              "11    802\n",
              "12    802\n",
              "13    802\n",
              "14    802\n",
              "15    802\n",
              "16    802\n",
              "17    802\n",
              "18    802\n",
              "19    802\n",
              "20    802\n",
              "21    802\n",
              "22    802\n",
              "23    802\n",
              "1     802\n",
              "Name: Label_enc, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDLYdmdtdseN",
        "outputId": "167bb729-77e0-4efe-dae8-def2f252c068"
      },
      "source": [
        "Xu = Xu[Xu.Label_enc != 7]\r\n",
        "Xu['Label_enc'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25    802\n",
              "15    802\n",
              "4     802\n",
              "6     802\n",
              "8     802\n",
              "11    802\n",
              "12    802\n",
              "13    802\n",
              "14    802\n",
              "16    802\n",
              "24    802\n",
              "17    802\n",
              "18    802\n",
              "19    802\n",
              "20    802\n",
              "21    802\n",
              "22    802\n",
              "23    802\n",
              "1     802\n",
              "Name: Label_enc, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONoOC4z7KcZJ",
        "outputId": "4fa567d5-7d5b-4abe-ac27-e206b9a01766"
      },
      "source": [
        "new_df = pd.concat([Xd,Xu]).reset_index(drop=True)\n",
        "new_df['Label_enc'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25    802\n",
              "24    802\n",
              "1     802\n",
              "2     802\n",
              "3     802\n",
              "4     802\n",
              "5     802\n",
              "6     802\n",
              "7     802\n",
              "8     802\n",
              "9     802\n",
              "10    802\n",
              "11    802\n",
              "12    802\n",
              "13    802\n",
              "14    802\n",
              "15    802\n",
              "16    802\n",
              "17    802\n",
              "18    802\n",
              "19    802\n",
              "20    802\n",
              "21    802\n",
              "22    802\n",
              "23    802\n",
              "0     802\n",
              "Name: Label_enc, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l02IH2muKg7e"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "train_token_indices, train_segment_ids = [], []  #bert tokenizer indices and their segment ids  (to separate sequences)\n",
        "val_token_indices, val_segment_ids = [], []\n",
        "for text in train['Text'].values:\n",
        "    # tokenizer.encode() returns a sequence of token indices\n",
        "    # and a sequence of segment IDs. BERT expects both as input,\n",
        "    # even if the segments IDs are just all zeros (like here).\n",
        "    ttid, tsid = tokenizer.encode(text, max_len=256)\n",
        "    train_token_indices.append(ttid)\n",
        "    train_segment_ids.append(tsid)\n",
        "\n",
        "for text in test['Text'].values:\n",
        "    # tokenizer.encode() returns a sequence of token indices\n",
        "    # and a sequence of segment IDs. BERT expects both as input,\n",
        "    # even if the segments IDs are just all zeros (like here).\n",
        "    vtid, vsid = tokenizer.encode(text, max_len=256)\n",
        "    val_token_indices.append(vtid)\n",
        "    val_segment_ids.append(vsid)\n",
        "\n",
        "# Format input as list of two numpy arrays\n",
        "train_X = [np.array(train_token_indices), np.array(train_segment_ids)]\n",
        "val_X = [np.array(val_token_indices), np.array(val_segment_ids)]\n",
        "\n",
        "\n",
        "# Print some examples\n",
        "# print('Token indices:')\n",
        "# print(val_X[0][:2])\n",
        "# print('Decoded:')\n",
        "# for i in val_X[0][:2]:\n",
        "#     print(tokenizer.decode(list(i)))\n",
        "# print('Segment ids:')\n",
        "# print(val_X[1][:2])\n",
        "# print()\n",
        "# print()\n",
        "\n",
        "# print('Token indices:')\n",
        "# print(train_X[0][:2])\n",
        "# print('Decoded:')\n",
        "# for i in train_X[0][:2]:\n",
        "#     print(tokenizer.decode(list(i)))\n",
        "# print('Segment ids:')\n",
        "# print(train_X[1][:2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmsFq5DGK_0B"
      },
      "source": [
        "from keras_bert import load_trained_model_from_checkpoint\n",
        "\n",
        "\n",
        "pretrained_model = load_trained_model_from_checkpoint(\n",
        "    config_file = bert_config_path,\n",
        "    checkpoint_file = bert_checkpoint_path,\n",
        "    training = False,\n",
        "    trainable = True,\n",
        "    seq_len = 256\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mesq8_g4NDkf",
        "outputId": "dd8426a4-96a8-4484-f595-fc508c44cde1"
      },
      "source": [
        "# This is a keras model, so we can figure out what inputs it takes like so:\n",
        "pretrained_model.inputs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<KerasTensor: shape=(None, 256) dtype=float32 (created by layer 'Input-Token')>,\n",
              " <KerasTensor: shape=(None, 256) dtype=float32 (created by layer 'Input-Segment')>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0VHp67RNOm5",
        "outputId": "8f2ac89d-5c19-470e-eeb4-81df9a381017"
      },
      "source": [
        "# And similarly for outputs:\n",
        "pretrained_model.outputs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<KerasTensor: shape=(None, 256, 768) dtype=float32 (created by layer 'Encoder-12-FeedForward-Norm')>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DP5YmQQhNQ5j",
        "outputId": "59fcc45c-e7ed-4a8f-d190-44970ae2b9e9"
      },
      "source": [
        "#@title Default title text\n",
        "\n",
        "pretrained_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "Input-Token (InputLayer)        [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Input-Segment (InputLayer)      [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Token (TokenEmbedding [(None, 256, 768), ( 22268928    Input-Token[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Segment (Embedding)   (None, 256, 768)     1536        Input-Segment[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Token-Segment (Add)   (None, 256, 768)     0           Embedding-Token[0][0]            \n",
            "                                                                 Embedding-Segment[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Position (PositionEmb (None, 256, 768)     196608      Embedding-Token-Segment[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Dropout (Dropout)     (None, 256, 768)     0           Embedding-Position[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Norm (LayerNormalizat (None, 256, 768)     1536        Embedding-Dropout[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, 256, 768)     2362368     Embedding-Norm[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-1-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, 256, 768)     0           Embedding-Norm[0][0]             \n",
            "                                                                 Encoder-1-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-1-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-1-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-1-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-1-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-1-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-1-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, 256, 768)     2362368     Encoder-1-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-2-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-1-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-2-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-2-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-2-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-2-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-2-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-2-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-2-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttentio (None, 256, 768)     2362368     Encoder-2-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-3-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-2-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-3-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-3-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-3-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-3-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-3-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-3-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-3-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttentio (None, 256, 768)     2362368     Encoder-3-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-4-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-3-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-4-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-4-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-4-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-4-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-4-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-4-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-4-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttentio (None, 256, 768)     2362368     Encoder-4-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-5-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-4-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-5-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-5-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-5-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-5-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-5-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-5-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-5-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttentio (None, 256, 768)     2362368     Encoder-5-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-6-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-5-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-6-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-6-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-6-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-6-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-6-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-6-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-6-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttentio (None, 256, 768)     2362368     Encoder-6-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-7-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-6-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-7-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-7-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-7-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-7-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-7-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-7-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-7-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttentio (None, 256, 768)     2362368     Encoder-7-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-8-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-7-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-8-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-8-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-8-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-8-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-8-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-8-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-8-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttentio (None, 256, 768)     2362368     Encoder-8-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-9-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-8-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-9-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-9-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-9-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-9-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-9-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-9-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-9-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttenti (None, 256, 768)     2362368     Encoder-9-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttenti (None, 256, 768)     0           Encoder-10-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttenti (None, 256, 768)     0           Encoder-9-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-10-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttenti (None, 256, 768)     1536        Encoder-10-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward (FeedFor (None, 256, 768)     4722432     Encoder-10-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward-Dropout  (None, 256, 768)     0           Encoder-10-FeedForward[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward-Add (Add (None, 256, 768)     0           Encoder-10-MultiHeadSelfAttention\n",
            "                                                                 Encoder-10-FeedForward-Dropout[0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward-Norm (La (None, 256, 768)     1536        Encoder-10-FeedForward-Add[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttenti (None, 256, 768)     2362368     Encoder-10-FeedForward-Norm[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttenti (None, 256, 768)     0           Encoder-11-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttenti (None, 256, 768)     0           Encoder-10-FeedForward-Norm[0][0]\n",
            "                                                                 Encoder-11-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttenti (None, 256, 768)     1536        Encoder-11-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward (FeedFor (None, 256, 768)     4722432     Encoder-11-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward-Dropout  (None, 256, 768)     0           Encoder-11-FeedForward[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward-Add (Add (None, 256, 768)     0           Encoder-11-MultiHeadSelfAttention\n",
            "                                                                 Encoder-11-FeedForward-Dropout[0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward-Norm (La (None, 256, 768)     1536        Encoder-11-FeedForward-Add[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttenti (None, 256, 768)     2362368     Encoder-11-FeedForward-Norm[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttenti (None, 256, 768)     0           Encoder-12-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttenti (None, 256, 768)     0           Encoder-11-FeedForward-Norm[0][0]\n",
            "                                                                 Encoder-12-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttenti (None, 256, 768)     1536        Encoder-12-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward (FeedFor (None, 256, 768)     4722432     Encoder-12-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward-Dropout  (None, 256, 768)     0           Encoder-12-FeedForward[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward-Add (Add (None, 256, 768)     0           Encoder-12-MultiHeadSelfAttention\n",
            "                                                                 Encoder-12-FeedForward-Dropout[0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward-Norm (La (None, 256, 768)     1536        Encoder-12-FeedForward-Add[0][0] \n",
            "==================================================================================================\n",
            "Total params: 107,523,072\n",
            "Trainable params: 107,523,072\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXgeVGijNTqv",
        "outputId": "ae480dd7-f494-416e-8199-2561b4595d7c"
      },
      "source": [
        "# model.outputs is a list, here with a single item. Here\n",
        "# pretrained_model.outputs[0] just grabs that item (the output tensor).\n",
        "# Indxing that tensor with [:,0] gives the first position in the sequence\n",
        "# for all elements in the batch (the `:`).\n",
        "bert_out = pretrained_model.outputs[0][:,0]\n",
        "\n",
        "print(bert_out)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KerasTensor(type_spec=TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), name='tf.__operators__.getitem/strided_slice:0', description=\"created by layer 'tf.__operators__.getitem'\")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G95iv8TBNWkl"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "#num_labels = 26\n",
        "\n",
        "dropout_layer = Dropout(.5, input_shape=(768,))(bert_out)\n",
        "out = Dense(26, activation='softmax')(dropout_layer)\n",
        "model = Model(\n",
        "    inputs=pretrained_model.inputs,\n",
        "    outputs=[out]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bbECF1KNZBs"
      },
      "source": [
        "from keras_bert import calc_train_steps, AdamWarmup\n",
        "\n",
        "\n",
        "# Calculate the number of steps for warmup\n",
        "total_steps, warmup_steps = calc_train_steps(\n",
        "    num_example=len(train['Text'].values),\n",
        "    batch_size=8,\n",
        "    epochs=3,\n",
        "    warmup_proportion=0.1,\n",
        ")\n",
        "\n",
        "optimizer = AdamWarmup(\n",
        "    total_steps,\n",
        "    warmup_steps,\n",
        "    lr=0.00002,\n",
        "    epsilon=1e-6,\n",
        "    weight_decay=0.01,\n",
        "    weight_decay_pattern=['embeddings', 'kernel', 'W1', 'W2', 'Wk', 'Wq', 'Wv', 'Wo']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjfiK3_ENep0"
      },
      "source": [
        "from keras.metrics import sparse_categorical_accuracy\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['sparse_categorical_accuracy']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zMAMj1_Nug0",
        "outputId": "baebc1ae-239b-4c4f-9ce7-70ab8648da32"
      },
      "source": [
        "Y = train['Label_enc'].values\n",
        "Y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, ..., 2, 2, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilam_ljSN0oq"
      },
      "source": [
        "val_y = val['Label_enc'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lt0O-n5XNhLb",
        "outputId": "a9d42d72-d32b-43fd-c20d-bf80c5e37905"
      },
      "source": [
        "# from tensorflow import keras\n",
        "# model = keras.models.load_model('/content/drive/My Drive/Colab Notebooks/assets')\n",
        "history = model.fit(\n",
        "    train_X,\n",
        "    Y,\n",
        "    epochs=3,\n",
        "    batch_size=8,\n",
        "    validation_data= (val_X,val_y)\n",
        "    \n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "2199/2199 [==============================] - 1414s 621ms/step - loss: 1.9550 - sparse_categorical_accuracy: 0.4806 - val_loss: 0.8663 - val_sparse_categorical_accuracy: 0.7421\n",
            "Epoch 2/3\n",
            "2199/2199 [==============================] - 1338s 609ms/step - loss: 0.6774 - sparse_categorical_accuracy: 0.8036 - val_loss: 0.8627 - val_sparse_categorical_accuracy: 0.7593\n",
            "Epoch 3/3\n",
            "2199/2199 [==============================] - 1279s 582ms/step - loss: 0.3781 - sparse_categorical_accuracy: 0.8864 - val_loss: 0.8706 - val_sparse_categorical_accuracy: 0.7647\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "aG070qzMNjY8",
        "outputId": "76dcd05f-4a56-4e87-bedb-a5624542f99a"
      },
      "source": [
        "train_X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[  101,   146,  1221, ...,  1119,   112,   102],\n",
              "        [  101, 15704,  1104, ...,  1284,  1163,   102],\n",
              "        [  101,   112,  3198, ...,   119,   138,   102],\n",
              "        ...,\n",
              "        [  101, 25931,  2154, ...,     0,     0,     0],\n",
              "        [  101,   160, 11607, ...,  1120,  1103,   102],\n",
              "        [  101, 22412, 10224, ...,  1107,  3073,   102]]),\n",
              " array([[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WOt4yzkQOfqe",
        "outputId": "5fc2f978-df6e-4fef-f828-7698133e9fa6"
      },
      "source": [
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "def plot_history(history):\n",
        "    plt.plot(history.history['sparse_categorical_accuracy'],label=\"Training set accuracy\")\n",
        "    plt.plot(history.history['val_sparse_categorical_accuracy'],label=\"Validation set accuracy\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_history(history)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deVyVZf7/8ddHVllcEDUVUckFNxZBcKlGM9PMtGxzmRS1LNv7TvWzZaqpaZmZZm2aJptcKgzLyqyxmtScmkw2xQ13VAR3UBaR7XD9/uBIRwQ56oEDh8/z8eDBOfd93ff5nJvDm4vrvs91xBiDUkop19XC2QUopZSqXxr0Sinl4jTolVLKxWnQK6WUi9OgV0opF6dBr5RSLs6uoBeRsSKyU0T2iMi8GtZ3E5HVIrJZRNaKSJDNuhkistv6NcORxSullKqb1HUdvYi4AbuA0UAWkAxMMcak27T5GPjSGLNYRK4FZhpj7hKRACAFiAYMkApEGWNO1suzUUopdR57evQxwB5jTIYxphRIACZWa9MPWGO9/Z3N+jHAt8aYXGu4fwuMvfyylVJK2cvdjjZdgIM297OA2GptNgGTgL8CtwD+ItKulm27VH8AEZkDzAHw9fWNCg0Ntbd+pZRSQGpq6gljTPua1tkT9PZ4HPi7iMQB3wPZgMXejY0x84H5ANHR0SYlJcVBZSmlVPMgIgdqW2dP0GcDXW3uB1mXVTHGHKKyR4+I+AG3GmNOiUg2MKLatmvtqloppZRD2DNGnwz0EpEeIuIJTAZW2DYQkUARObuvp4AF1tvfANeLSFsRaQtcb12mlFKqgdQZ9MaYcuBBKgN6O/CRMWabiLwoIhOszUYAO0VkF9AReNm6bS7wEpV/LJKBF63LlFJKNZA6L69saDWN0ZeVlZGVlUVxcbGTqlKuzNvbm6CgIDw8PJxdilKXTERSjTHRNa1z1MnYepWVlYW/vz/du3dHRJxdjnIhxhhycnLIysqiR48ezi5HqXrRJKZAKC4upl27dhryyuFEhHbt2ul/i8qlNYmgBzTkVb3R15ZydU0m6JVSylUVl1lYvjGbJYmZ9bJ/DXo75OTkEBERQUREBFdccQVdunSpul9aWnrBbVNSUnj44YfrfIxhw4Y5qtyL8sorrzjlcZVSsO/EaV5ZuZ2hr67m0aVpfJx6kPq4QKZJXHWzfft2+vbt66SKzvXCCy/g5+fH448/XrWsvLwcd/cmcV77PH5+fhQWFjq1hsZw/BrTa0y5tjJLBavSjxKfmMn/9pzArYVwfb+OTIvtxrAr29GixaUNJV7oqhvt0V+iuLg47rvvPmJjY3nyySdJSkpi6NChREZGMmzYMHbu3AnA2rVrGT9+PFD5R2LWrFmMGDGCkJAQ/va3v1Xtz8/Pr6r9iBEjuO222wgNDWXatGlVf+FXrlxJaGgoUVFRPPzww1X7tbVt2zZiYmKIiIggLCyM3bt3A/DBBx9ULb/33nuxWCzMmzePM2fOEBERwbRp087b19y5c4mOjqZ///48//zzVcuTk5MZNmwY4eHhxMTEUFBQgMVi4fHHH2fAgAGEhYXxxhtvANC9e3dOnDgBVP53M2LEiKpjcddddzF8+HDuuusu9u/fz9VXX82gQYMYNGgQ69atq3q83/3udwwcOJDw8HDmzZvH3r17GTRoUNX63bt3n3NfqcYo62QRr3+zk2GvrWFu/Ab2nTjN49f35qd51/LWL6O4qlfgJYd8XZpcN/Q3X2wj/VC+Q/fZr3Mrnr+p/0Vvl5WVxbp163BzcyM/P58ffvgBd3d3Vq1axdNPP80nn3xy3jY7duzgu+++o6CggD59+jB37tzzrt/euHEj27Zto3PnzgwfPpwff/yR6Oho7r33Xr7//nt69OjBlClTaqzpn//8J4888gjTpk2jtLQUi8XC9u3bWbp0KT/++CMeHh7cf//9xMfH89prr/H3v/+dtLS0Gvf18ssvExAQgMViYdSoUWzevJnQ0FDuvPNOli5dyuDBg8nPz6dly5bMnz+f/fv3k5aWhru7O7m5db8vLj09nf/973+0bNmSoqIivv32W7y9vdm9ezdTpkwhJSWFr776is8//5zExER8fHzIzc0lICCA1q1bk5aWRkREBAsXLmTmzJl2/MSUaliWCsPanceIT8zku53HALi2TwemDQnmF7074FZPwV5dkwv6xuT222/Hzc0NgLy8PGbMmMHu3bsREcrKymrc5sYbb8TLywsvLy86dOjA0aNHCQoKOqdNTExM1bKIiAj279+Pn58fISEhVdd6T5kyhfnz55+3/6FDh/Lyyy+TlZXFpEmT6NWrF6tXryY1NZXBgwcDcObMGTp06FDn8/voo4+YP38+5eXlHD58mPT0dESETp06Ve2rVatWAKxatYr77ruvaggmICCgzv1PmDCBli1bApVvinvwwQdJS0vDzc2NXbt2Ve135syZ+Pj4nLPfu+++m4ULF/KnP/2JpUuXkpSUVOfjKdVQjuYXszT5IAlJmRzKK6aDvxcPjuzJnYO7EtTWp8HraXJBfyk97/ri6+tbdfvXv/41I0eO5LPPPmP//v1VQxTVeXl5Vd12c3OjvLz8ktrUZurUqcTGxvLvf/+bcePG8fbbb2OMYcaMGbz66qt272ffvn28/vrrJCcn07ZtW+Li4i7pWnN3d3cqKioAztve9vj9+c9/pmPHjmzatImKigq8vb0vuN9bb72V3/zmN1x77bVERUXRrl27i65NKUeqqDD8uPcE8esz+Xb7USwVhqt7BfLcTf0Y1bcjHm7OGynXMXoHycvLo0uXyqn2Fy1a5PD99+nTh4yMDPbv3w/A0qVLa2yXkZFBSEgIDz/8MBMnTmTz5s2MGjWKZcuWcexY5b+Oubm5HDhQOaOph4dHjf995Ofn4+vrS+vWrTl69ChfffVVVR2HDx8mOTkZgIKCAsrLyxk9ejRvv/121R+ls0M33bt3JzU1FaDGoayz8vLy6NSpEy1atOD999/HYqmc5Xr06NEsXLiQoqKic/br7e3NmDFjmDt3rg7bKKfKKSzh7f/uZeQf13LXu0kk7svh7qt6sPbxEbw/O5axAzo5NeRBg95hnnzySZ566ikiIyMvqgdur5YtW/KPf/yDsWPHEhUVhb+/P61btz6v3UcffcSAAQOIiIhg69atTJ8+nX79+vHb3/6W66+/nrCwMEaPHs3hw4cBmDNnDmFhYeedjA0PDycyMpLQ0FCmTp3K8OHDAfD09GTp0qU89NBDhIeHM3r0aIqLi7n77rsJDg4mLCyM8PBwlixZAsDzzz/PI488QnR0dNUwV03uv/9+Fi9eTHh4ODt27Kjq7Y8dO5YJEyYQHR1NREQEr7/+etU206ZNo0WLFlx//fWXd3CVukjGGBIzcnj4w40MfXUNr361g46tvPnr5AjWPz2Kp8b1pXugb907aiB6eWUTUlhYiJ+fH8YYHnjgAXr16sVjjz3m7LKc5vXXXycvL4+XXnrpsvelrzFlj7yiMj7dmEV8YiZ7jhXi7+3OrYOCmBYbTK+O/k6trclPaqYqvfPOOyxevJjS0lIiIyO59957nV2S09xyyy3s3buXNWvW1N1YqctgjCHt4CmWJGbyxeZDFJdVEN61Db+/LYybwjrT0rP2/1QbC+3RK4W+xtT5CkvK+Twtm/j1maQfzsfH042bI7swNSaYAV3OHzZ1Nu3RK6WUndIP5ROfeIDlG7M5XWqhb6dW/PbmAUyM6Iy/d9P8zAINeqVUs3em1MKXmw8Rn5hJ2sFTeLm34KbwzkyNDSaya5smP8OpBr1Sqtnac6yA+MRMPknNIr+4nCvb+/Lc+H7cOiiI1j5Ns/deEw16pVSzUlJu4eutR1iSmEnivlw83ISxAzoxLTaY2B4BTb73XhO9jt4OI0eO5Jtvvjln2V/+8hfmzp1b6zYjRozg7EnlcePGcerUqfPavPDCC+dcF16T5cuXk56eXnX/ueeeY9WqVRdTvkPodMaqqTuQc5pXv9rO0FfX8EhCGofzipl3Qyg/PTWKN6ZEMiTEdT/FTnv0dpgyZQoJCQmMGTOmallCQgK///3v7dp+5cqVl/zYy5cvZ/z48fTr1w+AF1988ZL3dTleeeUVnn76aac89lmNYTpj1bSUWSpYvf0Y8YkH+GF35ZTA1/XtwLTYblzVs/5mi2xstEdvh9tuu41///vfVR8ysn//fg4dOsTVV19d61S+tmyn6n355Zfp3bs3V111VdVUxlB5jfzgwYMJDw/n1ltvpaioiHXr1rFixQqeeOIJIiIi2Lt3L3FxcSxbtgyA1atXExkZycCBA5k1axYlJSVVj/f8888zaNAgBg4cyI4dO86rSaczVq7s0Kkz/Ok/O7nqd2u474NU9hwr5LHrevPj/7uWt++K5pre7ZtNyENT7NF/NQ+ObHHsPq8YCDe8VuvqgIAAYmJi+Oqrr5g4cSIJCQnccccdiEiNU/mGhYXVuJ/U1FQSEhJIS0ujvLycQYMGERUVBcCkSZO45557AHj22Wd59913eeihh5gwYQLjx4/ntttuO2dfxcXFxMXFsXr1anr37s306dN56623ePTRRwEIDAxkw4YN/OMf/+D111/nX//61znb63TGytVYKgzf7zpOfOIB1uw4hgFG9G7Pyzd3Y0Sf9rg7eb4ZZ2p6Qe8kZ4dvzgb9u+++C9Q8lW9tQf/DDz9wyy23VE25O2HChKp1W7du5dlnn+XUqVMUFhaeM0xUk507d9KjRw969+4NwIwZM3jzzTergn7SpEkAREVF8emnn563vU5nrFzFsYJiPk7JYkliJtmnzhDo58XcEVcyeXAwXQMafkrgxqjpBf0Fet71aeLEiTz22GNs2LCBoqIioqKiHDaVL1R+YtXy5csJDw9n0aJFrF279rLqPTvVcW3THOt0xqopq6gw/JSRQ3ziAf6z7SjlFYbhPdvxzI19ua5vRzzdm2/vvSZ6NOzk5+fHyJEjmTVrVtWnO9U2lW9trrnmGpYvX86ZM2coKCjgiy++qFpXUFBAp06dKCsrIz4+vmq5v78/BQUF5+2rT58+7N+/nz179gDw/vvv84tf/MLu56PTGaumKPd0Ke98n8GoP/2Xaf9KZN3eHGYO786aX/2C+LuHMG5gJw35GugRuQhTpkxh06ZNVUFf21S+tRk0aBB33nkn4eHh3HDDDVXDGgAvvfQSsbGxDB8+nNDQ0KrlkydP5g9/+AORkZHs3bu3arm3tzcLFy7k9ttvZ+DAgbRo0YL77rvP7uei0xmrpsIYQ/L+XB5N2MiQV1bz8srttPP15M93hrP+qVE8c2M/Qtr7ObvMRk0nNVMuz57pjPU11vjkF5fx2YZs4hMPsOtoIf5e7kwa1IWpsd3oc4VzpwRujHRSM9Vs6XTGTc/mrFPEr89kxaZDnCmzEBbUmt/dOpCbwjvj46mRdSn0qCmX9tlnnzm7BGWH0yXlrNh0iPjEA2zNzqelhxs3R3Zmakw3BgY1vimBmxq7gl5ExgJ/BdyAfxljXqu2PhhYDLSxtplnjFkpIt2B7cDZdwatN8bYP5Bswxjjsm9PVs7V2IYvm5Pth/NZkpjJZxuzKSwpJ/QKf16a2J+JkV1o1USnBG6M6gx6EXED3gRGA1lAsoisMMak2zR7FvjIGPOWiPQDVgLdrev2GmMiLqdIb29vcnJyaNfOdeeiUM5hjCEnJ6fOyzSV4xSXWVi55TDxiZmkHjiJp3sLxodVTio2KLit/o7XA3t69DHAHmNMBoCIJAATAdugN0Ar6+3WwCFHFhkUFERWVhbHjx935G6VAio7EkFBQc4uw+XtPV7IksRMlqVmkXemjJBAX569sS+3Dgqira+ns8tzafYEfRfgoM39LCC2WpsXgP+IyEOAL3CdzboeIrIRyAeeNcb8UP0BRGQOMAcgODj4vAI8PDzo0aOHHaUqpRqT0vIKvtlWOSXwTxk5uLcQxgy4gmmxwQx14dkiGxtHnYydAiwyxvxRRIYC74vIAOAwEGyMyRGRKGC5iPQ3xuTbbmyMmQ/Mh8rLKx1Uk1LKSQ7mFrEkKZOPUw5yorCUoLYteXJsH26P6kp7fy9nl9fs2BP02UBXm/tB1mW2ZgNjAYwxP4mINxBojDkGlFiXp4rIXqA3kIJSyqWUWypYs+MY8YmZfL/7OAKM6tuRabHBXNOrec0W2djYE/TJQC8R6UFlwE8GplZrkwmMAhaJSF/AGzguIu2BXGOMRURCgF5AhsOqV0o53eG8MyQkHWRp8kGO5BfTsZUXD1/bi8kxXenUuqWzy1PYEfTGmHIReRD4hspLJxcYY7aJyItAijFmBfAr4B0ReYzKE7NxxhgjItcAL4pIGVAB3GeMqXteWqVUo1ZRYfh+93HiEzNZvf0oBrimV3tenNifa0M7NOspgRujJjEFglKqcTheUMLHqQf5MCmTg7lnaOfryR2DuzJlcDDB7XRKYGfSKRCUUpfMmLNTAmfyn21HKLMYhoa04/+NDeX6flfobJFNgAa9UqpGp4pKWZaaxZKkTDKOn6Z1Sw+mD+3OlJhgenbQ2SKbEg16pVQVYwwbMk8Svz6TL7ccprS8gkHBbfjj7eHcGNYJb4/ap5BWjZcGvVKKguIylm/MJj4xkx1HCvDzcufO6K5MjQ2mb6dWde9ANWoa9Eo1Y1uy8liSdIDP0w5RVGqhf+dWvDppIBPCO+PrpfHgKvQnqVQzU1RazhebDhGfmMnmrDy8PVowIbwz02K7ERbUWqclcEEa9Eo1EzuPFLAk8QCfbsimoKSc3h39+M2E/twc2YXWLXVKYFemQa+UCysus/D11iPEJx4gef9JPN1acGNYJ6bGBhPdTacEbi406JVyQftOnGZJ4gGWpWZxsqiM7u18eGZcX26NCiJApwRudjTolXIRZZYKvk0/SnziAX7cUzkl8PX9OzItthtDQ9rppGLNmAa9Uk3cwdwiEpIz+Sgli+MFJXRp05InxvTh9uggOvjrJ2cpDXqlmiRLheG7HceITzzA2l2VUwJfG9qBabHduKZ3e9y0965saNAr1YQcyStmafJBliZnciivmA7+Xjw0sid3xgTTpY1OCaxqpkGvVCNXUWH4354TxCceYNX2Y1gqDFf3CuS5m/oxqm9HPHRKYFUHDXqlGqmcwhI+Ts1iSWImmblFBPh6cvfVPZgyOJjugb7OLk81IRr0SjUixhgS9+USn5jJ11sPU2YxxPYI4FfX92bsgCvwctdJxdTF06BXqhHIKyrjkw1ZxCceYO/x07TydueXQ7oxLTaYnh38nV2eauI06JVyEmMMaQdPEZ+YyRebDlFSXkFE1zb84bYwxod1pqWn9t6VY2jQK9XACkvKq6YE3n44H19PN26LCmJqbDD9O7d2dnnKBWnQK9VAtmbnsSQpk883ZnO61ELfTq14+ZYBTIzogp9OCazqkb66lKpHZ0otfLG5ckrgTQdP4eXegpvCOzMtNpiIrm10UjHVIDTolaoHu48WEJ+YyScbsigoLqdnBz+ev6kfkyKDaO2jUwKrhqVBr5SDlJSfnRI4k6R9uXi4CTcM6MS02GBiegRo7105jQa9Updp/4nTfJiUycepWeSeLqVbOx/m3RDKbVFBBPp5Obs8pTTolboUZZYKVm8/SnxiJj/sPoFbC2F0345MGxLM8CsDdUpg1aho0Ct1EbJPnWFpUiYJyQc5VlBC59be/N/o3tw5uCsdW+mUwKpx0qBXyg5FpeU89ekWvth0CAOM7NOBabHBjOjTQacEVo2eBr1SdcgpLGHWomS2ZOdxzzUh3DWkG0FtfZxdllJ206BX6gIO5JxmxoIkjuQX8/Zd0Yzu19HZJSl10eyayFpExorIThHZIyLzalgfLCLfichGEdksIuNs1j1l3W6niIxxZPFK1actWXnc+tY6Tp0pI/7uIRryqsmqs0cvIm7Am8BoIAtIFpEVxph0m2bPAh8ZY94SkX7ASqC79fZkoD/QGVglIr2NMRZHPxGlHOm/u44z94NU2vp4snR2DFe293N2SUpdMnt69DHAHmNMhjGmFEgAJlZrY4BW1tutgUPW2xOBBGNMiTFmH7DHuj+lGq1PUrOYvSiZbu18+ez+YRryqsmzZ4y+C3DQ5n4WEFutzQvAf0TkIcAXuM5m2/XVtu1S/QFEZA4wByA4ONieupVyOGMMb/13L7//eifDe7bjn7+Mwt9bpytQTZ+jPmxyCrDIGBMEjAPeFxG7922MmW+MiTbGRLdv395BJSllP0uF4fkV2/j91zuZGNGZhXExGvLKZdjTo88GutrcD7IuszUbGAtgjPlJRLyBQDu3VcqpisssPJqQxtfbjjDnmhDmjQ3Vd7Yql2JPrzsZ6CUiPUTEk8qTqyuqtckERgGISF/AGzhubTdZRLxEpAfQC0hyVPFKXa68ojKmv5vEN+lH+PX4fjw9rq+GvHI5dfbojTHlIvIg8A3gBiwwxmwTkReBFGPMCuBXwDsi8hiVJ2bjjDEG2CYiHwHpQDnwgF5xoxqLQ6fOMGNBEgdyinhjSiTjwzo7uySl6oVU5nHjER0dbVJSUpxdhnJxO47kE7cgmdMl5bw9PYphVwY6uySlLouIpBpjomtap++MVc3O+owc7nkvBR9PNz6eO5TQK1rVvZFSTZgGvWpW/r35MI8tTSO4nQ+LZ8XQpU1LZ5ekVL3ToFfNxsIf9/Hil+lEBbflXzOiaePj6eySlGoQGvTK5VVUGH739Q7e/j6DMf078tfJkXh7uDm7LKUajAa9cmml5RU8uWwTy9MOcdeQbrwwob/OH6+aHQ165bIKS8q57/1U/rfnBE+M6cP9I67UD+hWzZIGvXJJxwqKmbkwmR1HCvjDbWHcHt217o2UclEa9Mrl7D1eyIwFSeSeLuXdGdGM6NPB2SUp5VQa9MqlbMg8yexFybQQIWHOEMKC2ji7JKWcToNeuYxV6Ud58MMNdGzlzXuzYujWztfZJSnVKGjQK5eQkJTJ059tYUCX1iyIG0ygn5ezS1Kq0dCgV02aMYa/rt7NX1btZkSf9rw5dRC+XvqyVsqW/kaoJqvcUsGvP9/Kh0kHuS0qiFcnDcTDzVGfpaOU69CgV03SmVILD324gVXbj/HgyJ786vreeo28UrXQoFdNTu7pUmYtSmZz1ileunkAdw3p5uySlGrUNOhVk3Iwt4gZC5LIPnWGt34ZxZj+Vzi7JKUaPQ161WRszc5j5qJkSssriL87lujuAc4uSakmQYNeNQk/7D7Ofe+n0sbHkw/viaVnB39nl6RUk6FBrxq95RuzefzjTfTs4MeimTFc0drb2SUp1aRo0KtGyxjD299n8NpXOxgSEsD86dG08vZwdllKNTka9KpRqqgwvPhlOovW7Wd8WCf+eEc4Xu76YSHKBVnKwVIC5SWV930cf+5Jg141OsVlFn710Sb+veUws6/qwTPj+tJCPyxEOYIxYCmtDNWq7yVQXlrte8mlt6tqW9M+atiXqfi5vqDBcPcqhz9tDXrVqOSdKWPOeykk7svlmXF9ueeaEGeXpC5HRcXFB+d56+zd9kLtbbZzFHEDdy9w87R+9wJ3z2rfvcCrVeX3C7U5uw//To6rz4YGvWo0DuedIW5BMhknCvnr5AgmRnRxdklNizFQUV7PvdVi+3qpZ79XlDvu+bXwqDswPf3Ap10d4VtDwJ797u59/rLatm3RdIYSNehVo7DraAEzFiRRUFzOopkxDO8Z6OyS6nYpwwAX+2+9vb3UmoYBLovYF5QtfS4iMOsIzgu1c/OEFjqP0aXSoFdOl7Qvl7sXJ+Pl4cbSe4fQv3Prhi2gwgJFuXD6GJw+DqdPVH4vrHb/9HEoLfw5VC2ljquhtmEA28B09wbv1pcXmLbtzltns00Ld9C5g1yGBr1yqq+2HOaRpWkEtW3J4pkxdA3wccyOS0//HNJVgX02tI+du64oBzDn70PcwLe99SsQAkLAy+/84HT3vvzQbULDAKrp0aBXTrN43X5e+GIbkV3b8O6MwbT19ay9cVWv+3jNX4XHzw3zstM178fTH/ys4R0QAl1jzw1zvw4/3/duo8MFyiVo0KsGZ4zhD9/sZMHadO7o6clvRrnjnbXaZrjkxPlBXpRT8/izuFUGtG+Hn3vdvu1/DvNzvgLBo2XDP2GlnEyDXjlOhQXOnKxlfLsywCsKj3PyWBYPlObypHcJZAGLq+3H0//n3nVACHSNsQa1NczPBrdfB+11K2UHu4JeRMYCfwXcgH8ZY16rtv7PwEjrXR+ggzGmjXWdBdhiXZdpjJngiMJVAyktqiGwq499W9cVnbhgr9viE8j2fC92F4fQPXgkEaG9kKqhEpsA1163Ug5VZ9CLiBvwJjCayv5XsoisMMakn21jjHnMpv1DQKTNLs4YYyIcV7K6LBUV1l53tROU54S2ze3Swpr3c7bX7dse2naHroPPHSLxtRnrbtmW46fLmLUomfT8fF65ZQCRg4Mb9Gkr1ZzZ06OPAfYYYzIARCQBmAik19J+CvC8Y8pTdik7U8tJyePnh3lRDhjL+fuQFuBz9mRkYGV4nzdUYv3uEwie9l8ds+/EaWYsSOJ4QQnvTI/i2tCOjnvuSqk62RP0XYCDNvezgNiaGopIN6AHsMZmsbeIpADlwGvGmOU1bDcHmAMQHKw9vZ973cfPGd+uNcxr7XX7/dy7btMNukT9PLZdFeAdqnrd9THWnXbwFLMWJQPw4ZwhRHRt4/DHUEpdmKNPxk4GlhlzTpexmzEmW0RCgDUissUYs9d2I2PMfGA+QHR0dA0XNLsA2173OW/IOVFDmJ+4cK/77PBIUHTNQyVnQ/wiet314bsdx7g/fgOB/p4snhlDSHs/p9ajVHNlT9BnA11t7gdZl9VkMvCA7QJjTLb1e4aIrKVy/H7v+Zs2MRUVUHyqhitManp35QkoLah5P1W97vbQJvjnXndNlwi2DGgyV5h8lHyQpz7bQt9O/iyMi6G9v5ezS1Kq2bIn6JOBXiLSg8qAnwxMrd5IREKBtsBPNsvaAkXGmBIRCQSGA793ROH1oqz4wuPb54T5hXrd7X4e3+4SVW2oxPYywUDw9G3451mPjDH8fc0e/vjtLq7uFchbv4zCz0uv4mSyQB8AABJ8SURBVFXKmer8DTTGlIvIg8A3VF5eucAYs01EXgRSjDErrE0nAwnGGNuhl77A2yJSAbSgcoy+tpO4jmfb67bnZGVJfs378fD9+bruNl2hS+T513X72Y51N8+3s1sqDM99vpX4xEwmRXbhtVvD8HRvGv+BKOXK5Nxcdr7o6GiTkpJy8RsW5cLX884N86ITNU+TWtXrruGdk7ZvgT+7zMV63fXhTKmFhxM28m36UeaOuJInx/RBdFIspRqMiKQaY6JrWuc6/1O3cIfM9ZXh3DrIptddw5dPQLPtddeHk6dLmb04mY0HT/GbCf2ZMay7s0tSStlwnaD3bgWPbnZ2Fc1O1skiZixI4uDJM7w5dRDjBtbPJ+QopS6d6wS9anDph/KJW5hEcZmF92fFEBvSztklKaVqoEGvLsm6PSeY834q/t7uLJs7jN4d/Z1dklKqFhr06qJ9npbN4x9vIiTQj0WzBtOptU5CplRjpkGvLso732fw8srtxPQI4J3p0bRu6eHskpRSddCgV3apqDC8vHI77/5vH+MGXsGf7ojA20OvXFKqKdCgV3UqKbfw+Meb+WLTIeKGdefX4/vh1kKvkVeqqdCgVxeUX1zGve+l8lNGDvNuCOXea0L0jVBKNTEa9KpWR/OLmbEgiT3HCvnTHeFMGhTk7JKUUpdAg17VaM+xAmYsSOZUUSkLZw7m6l7tnV2SUuoSadCr86Tsz2X24hQ83Fqw9N6hDOjS2tklKaUugwa9Osc3247w8Icb6dymJYtnxhDczrkfXqKUunwa9KrKB+sP8NznWwkLasOCuMEE+Ho6uySllANo0CuMMfzxP7v4+3d7GBXagTemRuLjqS8NpVyF/jY3c2WWCp7+dAsfp2ZxZ3RXXr5lAO5u+mEhSrkSDfpm7HRJOQ8s2cDancd5ZFQvHr2ul14jr5QL0qBvpk4UljBrUTJbs/N4ddJApsQEO7skpVQ90aBvhg7knGbGgiSO5Bcz/65oruvX0dklKaXqkQZ9M7M56xQzFyZTYQzxdw8hqltbZ5eklKpnGvTNyNqdx7g/fgNtfTx5b3YMV7b3c3ZJSqkGoEHfTCxLzWLeJ5vp3dGfRTMH06GVt7NLUko1EA16F2eM4R9r9/KHb3ZyVc9A3vrlIPy99cNClGpONOhdmKXC8MKKbby//gATIzrzh9vC8XTXa+SVam406F1UcZmFRxPS+HrbEe69JoT/NzaUFvphIUo1Sxr0LuhUUSn3vJdCyoGTPDe+H7Ou6uHskpRSTqRB72KyT51hxoIkMnOKeGNKJOPDOju7JKWUk2nQu5AdR/KJW5DM6ZJyFs+KYeiV7ZxdklKqEdCgdxE/7c1hznsp+Hi58fHcoYRe0crZJSmlGgm7LsEQkbEislNE9ojIvBrW/1lE0qxfu0TklM26GSKy2/o1w5HFq0pfbj7EjAVJXNHam0/vH64hr5Q6R509ehFxA94ERgNZQLKIrDDGpJ9tY4x5zKb9Q0Ck9XYA8DwQDRgg1brtSYc+i2Zswf/28dK/04nu1pZ3pkfTxkc/LEQpdS57evQxwB5jTIYxphRIACZeoP0U4EPr7THAt8aYXGu4fwuMvZyCVaWKCsMrK7fz4pfpjOl3Be/PjtWQV0rVyJ4x+i7AQZv7WUBsTQ1FpBvQA1hzgW27XHyZylZpeQVPLtvE8rRD3DWkGy9M6I+bXiOvlKqFo0/GTgaWGWMsF7ORiMwB5gAEB+u86BdSUFzGfR+k8uOeHJ4Y04f7R1ypHxailLoge4ZusoGuNveDrMtqMpmfh23s3tYYM98YE22MiW7fvr0dJTVPx/KLufPt9azPyOX128N5YGRPDXmlVJ3sCfpkoJeI9BARTyrDfEX1RiISCrQFfrJZ/A1wvYi0FZG2wPXWZeoi7T1eyKS31rE/5zTvzojmtqggZ5eklGoi6hy6McaUi8iDVAa0G7DAGLNNRF4EUowxZ0N/MpBgjDE22+aKyEtU/rEAeNEYk+vYp+D6Ug+cZPbiZNxbCAlzhhAW1MbZJSmlmhCxyeVGITo62qSkpDi7jEbj2/SjPPThBjq28ua9WTF0a+fr7JKUUo2QiKQaY6JrWqfvjG3EPkzK5JnPtjCgS2sWxA0m0M/L2SUppZogDfpGyBjDX1bt5q+rdzOiT3venDoIXy/9USmlLo2mRyNTbqngmc+2sjTlILdHBfHKpIF4uOmHhSilLp0GfSNSVFrOg0s2smbHMR4c2ZNfXd9bL59USl02DfpGIqewhNmLU9icdYqXbh7AXUO6ObskpZSL0KBvBA7mFjF9QRKHTp3hrV9GMab/Fc4uSSnlQjTonWxrdh5xC5Mps1QQf3cs0d0DnF2SUsrFaNA70fe7jjP3g1Ta+HiSMCeWnh38nV2SUsoFadA7yWcbs3ji48307ODH4lkxdGzl7eySlFIuSoO+gRljePv7DF77agdDQ9rx9vQoWnl7OLsspZQL06BvQJYKw0tfprNo3X7Gh3Xij3eE4+Xu5uyylFIuToO+gRSXWfi/j9JYueUIs6/qwTPj+tJCPyxEKdUANOgbQN6ZMu55L4Wkfbk8e2Nf7r46xNklKaWaEQ36enY47wwzFiSx78Rp/jo5gokR+kmKSqmGpUFfj3YeKSBuYRIFxeUsnhnDsJ6Bzi5JKdUMadDXk8SMHO55LwVvDzc+unco/Tq3cnZJSqlmSoO+HqzccphHl6YR1LYli2fG0DXAx9klKaWaMQ16B1u8bj8vfLGNyK5teHfGYNr6ejq7JKVUM6dB7yDGGH7/zU7eWruX6/p25I0pkbT01GvklVLOp0HvAKXlFcz7ZDOfbsxmamwwL07oj7t+WIhSqpHQoL9MhSXlzP0glR92n+BXo3vz4LU99cNClFKNigb9ZThWUMysRclsP1zA728N447BXZ1dklJKnUeD/hLtO3Ga6QsSOVFQyjvTo7g2tKOzS1JKqRpp0F+CtIOnmLUoGYAP5wwhomsbJ1eklFK106C/SGt2HOWB+I0E+nvy3qxYegT6OrskpZS6IA36i7A0OZOnP9tK307+LIyLob2/l7NLUkqpOmnQ28EYw99W7+HPq3ZxTe/2/GPaIPy89NAppZoGTas6lFsq+PXn2/gwKZNJg7rwu1vD8NBr5JVSTYgG/QWcKbXw0IcbWbX9KPePuJInxvTRa+SVUk2OBn0tTp4uZfbiZDYePMVvJvRnxrDuzi5JKaUuiV1jECIyVkR2isgeEZlXS5s7RCRdRLaJyBKb5RYRSbN+rXBU4fXpYG4Rt/5zHVsP5fOPqYM05JVSTVqdPXoRcQPeBEYDWUCyiKwwxqTbtOkFPAUMN8acFJEONrs4Y4yJcHDd9WbboTziFiZTUmbhg9mxxPQIcHZJSil1Wezp0ccAe4wxGcaYUiABmFitzT3Am8aYkwDGmGOOLbNh/LjnBHe+vR73FsKyucM05JVSLsGeoO8CHLS5n2VdZqs30FtEfhSR9SIy1madt4ikWJffXNMDiMgca5uU48ePX9QTcJTP07KJW5hElzYt+fT+YfTu6O+UOpRSytEcdTLWHegFjACCgO9FZKAx5hTQzRiTLSIhwBoR2WKM2Wu7sTFmPjAfIDo62jioJru9830GL6/cTkyPAN6ZHk3rlh4NXYJSStUbe3r02YDttIxB1mW2soAVxpgyY8w+YBeVwY8xJtv6PQNYC0ReZs0OU1FheOnLdF5euZ0bB3bivVkxGvJKKZdjT9AnA71EpIeIeAKTgepXzyynsjePiARSOZSTISJtRcTLZvlwIJ1GoKTcwsMJG3n3f/uIG9adN6ZE4u2hnwillHI9dQ7dGGPKReRB4BvADVhgjNkmIi8CKcaYFdZ114tIOmABnjDG5IjIMOBtEamg8o/Ka7ZX6zhLfnEZc95LYX1GLk/dEMqca0L0jVBKKZclxjT4kPgFRUdHm5SUlHrb/5G8YuIWJrHnWCF/uD2MWyKD6u2xlFKqoYhIqjEmuqZ1zeqdsXuOFTD93STyzpSxcOZgru7V3tklKaVUvWs2QZ+8P5e7F6fg4daCpfcOZUCX1s4uSSmlGkSzCPqvtx7hkYSNdG7TkvdmxdA1wMfZJSmlVINx+aB/f/0Bnv98K2FBbVgQN5gAX09nl6SUUg3KZYPeGMPr/9nJm9/tZVRoB96YGomPp8s+XaWUqpVLJl+ZpYKnPt3CstQsJg/uym9vHoC7fliIUqqZcrmgP11Szv3xG/jvruM8MqoXj17XS6+RV0o1ay4V9CcKS5i1KJmt2Xm8OmkgU2KCnV2SUko5ncsEffapM0x9Zz1H84uZf1c01/Xr6OySlFKqUXCZoA/w8eTK9n78+c4IBgW3dXY5SinVaLhM0Lf0dGNB3GBnl6GUUo2OXoqilFIuToNeKaVcnAa9Ukq5OA16pZRycRr0Sinl4jTolVLKxWnQK6WUi9OgV0opF9foPjNWRI4DBy5jF4HACQeV40ha18XRui6O1nVxXLGubsaYGj8ftdEF/eUSkZTaPiDXmbSui6N1XRyt6+I0t7p06EYppVycBr1SSrk4Vwz6+c4uoBZa18XRui6O1nVxmlVdLjdGr5RS6lyu2KNXSillQ4NeKaVcXJMJehEZKyI7RWSPiMyrYb2XiCy1rk8Uke42656yLt8pImMauK7/E5F0EdksIqtFpJvNOouIpFm/VjRwXXEictzm8e+2WTdDRHZbv2Y0cF1/tqlpl4icsllXn8drgYgcE5GttawXEfmbte7NIjLIZl19Hq+66ppmrWeLiKwTkXCbdfuty9NEJKWB6xohInk2P6/nbNZd8DVQz3U9YVPTVutrKsC6rj6PV1cR+c6aBdtE5JEa2tTfa8wY0+i/ADdgLxACeAKbgH7V2twP/NN6ezKw1Hq7n7W9F9DDuh+3BqxrJOBjvT33bF3W+4VOPF5xwN9r2DYAyLB+b2u93bah6qrW/iFgQX0fL+u+rwEGAVtrWT8O+AoQYAiQWN/Hy866hp19POCGs3VZ7+8HAp10vEYAX17ua8DRdVVrexOwpoGOVydgkPW2P7Crht/JenuNNZUefQywxxiTYYwpBRKAidXaTAQWW28vA0aJiFiXJxhjSowx+4A91v01SF3GmO+MMUXWu+uBIAc99mXVdQFjgG+NMbnGmJPAt8BYJ9U1BfjQQY99QcaY74HcCzSZCLxnKq0H2ohIJ+r3eNVZlzFmnfVxoeFeX/Ycr9pczmvT0XU15OvrsDFmg/V2AbAd6FKtWb29xppK0HcBDtrcz+L8g1TVxhhTDuQB7ezctj7rsjWbyr/YZ3mLSIqIrBeRmx1U08XUdav1X8RlItL1Iretz7qwDnH1ANbYLK6v42WP2mqvz+N1saq/vgzwHxFJFZE5TqhnqIhsEpGvRKS/dVmjOF4i4kNlWH5is7hBjpdUDitHAonVVtXba8xlPhy8sRORXwLRwC9sFnczxmSLSAiwRkS2GGP2NlBJXwAfGmNKROReKv8buraBHtsek4FlxhiLzTJnHq9GTURGUhn0V9ksvsp6vDoA34rIDmuPtyFsoPLnVSgi44DlQK8Gemx73AT8aIyx7f3X+/ESET8q/7g8aozJd+S+L6Sp9Oizga4294Osy2psIyLuQGsgx85t67MuROQ64BlggjGm5OxyY0y29XsGsJbKv/INUpcxJsemln8BUfZuW5912ZhMtX+r6/F42aO22uvzeNlFRMKo/BlONMbknF1uc7yOAZ/huCHLOhlj8o0xhdbbKwEPEQmkERwvqwu9vurleImIB5UhH2+M+bSGJvX3GquPEw+O/qLyP48MKv+VP3sCp3+1Ng9w7snYj6y3+3PuydgMHHcy1p66Iqk8+dSr2vK2gJf1diCwGwedlLKzrk42t28B1pufT/zss9bX1no7oKHqsrYLpfLEmDTE8bJ5jO7UfnLxRs49UZZU38fLzrqCqTzvNKzacl/A3+b2OmBsA9Z1xdmfH5WBmWk9dna9BuqrLuv61lSO4/s21PGyPvf3gL9coE29vcYcdnDr+4vKM9K7qAzNZ6zLXqSylwzgDXxsfdEnASE22z5j3W4ncEMD17UKOAqkWb9WWJcPA7ZYX+hbgNkNXNerwDbr438HhNpsO8t6HPcAMxuyLuv9F4DXqm1X38frQ+AwUEblGOhs4D7gPut6Ad601r0FiG6g41VXXf8CTtq8vlKsy0Osx2qT9ef8TAPX9aDN62s9Nn+IanoNNFRd1jZxVF6gYbtdfR+vq6g8B7DZ5mc1rqFeYzoFglJKubimMkavlFLqEmnQK6WUi9OgV0opF6dBr5RSLk6DXimlXJwGvVJKuTgNeqWUcnH/HxEbD6z04CM5AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gla90dBFOko0"
      },
      "source": [
        "model.evaluate(val_X,val_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_v5db5FQOoMZ"
      },
      "source": [
        "### References\r\n",
        "\r\n",
        "#University of Turku, Deep Learning in Human Language Technology lectures"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-zVq-NPR0G9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}