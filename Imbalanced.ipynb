{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Imbalanced.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOoX7mgkKAni"
      },
      "source": [
        "# Mount the Google Drive. Import all the necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Brq5L8ll8r9C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "3a1d184b-fc50-4cfa-8a76-acfc1f15b80d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moWJCids8tj0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "81f94a1d-d1a4-4a65-bbbd-0f1c6c1a819d"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25Wz8CfX82Mi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "8c380867-d870-4f17-abfc-efba8bc9fce7"
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "\n",
        "print(\"tensorflow version : \", tf.__version__)\n",
        "print(\"tensorflow_hub version : \", hub.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensorflow version :  1.15.2\n",
            "tensorflow_hub version :  0.9.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZBzAKxG9Khq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "c3fac190-d4a5-4cb5-e20f-d227117b5595"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "    print('We will use the GPU:', device_name)\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "We will use the GPU: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InskaHEQ9NlR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4a2217a8-6bf6-4416-cb8d-c91b94390247"
      },
      "source": [
        "# Set the output directory for saving model file\n",
        "OUTPUT_DIR = '/GD/My Drive/Colab Notebooks/BERT/bert_imbalanced'\n",
        "\n",
        "#@markdown Whether or not to clear/delete the directory and create a new one\n",
        "DO_DELETE = False #@param {type:\"boolean\"}\n",
        "\n",
        "if DO_DELETE:\n",
        "  try:\n",
        "    tf.gfile.DeleteRecursively(OUTPUT_DIR)\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
        "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Model output directory: /GD/My Drive/Colab Notebooks/BERT/bert_imbalanced *****\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHwHpNS6LJwd"
      },
      "source": [
        "# Read the Training and Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHeDRfS29hBn"
      },
      "source": [
        "train = pd.read_csv('/content/drive/My Drive/Colab Notebooks/train_file.txt', sep='{}{}{}', engine = 'python')\n",
        "test = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/test_file.txt\", sep= '{}{}{}', engine = 'python')\n",
        "\n",
        "#from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, val =  train,test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrC_ejGf97FO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "4038d364-0f2b-4904-802b-e80314e0cbac"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>__label__ob</td>\n",
              "      <td>Friends, are we ready to stop pretending that ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>__label__ob</td>\n",
              "      <td>A new set of Ten Commandments for 2009  There ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>__label__ob</td>\n",
              "      <td>Post navigation  What gets you on the go? Incr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>__label__ob</td>\n",
              "      <td>Aaronovitch Takes On The BNP  David Aaronovitc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>__label__ob</td>\n",
              "      <td>The Church of England's General Synod votes on...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Label                                               Text\n",
              "0  __label__ob  Friends, are we ready to stop pretending that ...\n",
              "1  __label__ob  A new set of Ten Commandments for 2009  There ...\n",
              "2  __label__ob  Post navigation  What gets you on the go? Incr...\n",
              "3  __label__ob  Aaronovitch Takes On The BNP  David Aaronovitc...\n",
              "4  __label__ob  The Church of England's General Synod votes on..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCeKDwh6QXKg"
      },
      "source": [
        "# Label Encoding All the 26 Labels and Then Map Them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwGUGFem999n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "6976e14e-7ee7-471d-cadf-5bf4a6cf9242"
      },
      "source": [
        "label_encode = {}\n",
        "for i, v  in enumerate(train['Label'].unique()):\n",
        "  label_encode[v] = i\n",
        "label_encode"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'__label__av': 20,\n",
              " '__label__df': 17,\n",
              " '__label__dp': 23,\n",
              " '__label__ds': 9,\n",
              " '__label__dt': 7,\n",
              " '__label__en': 21,\n",
              " '__label__fi': 22,\n",
              " '__label__fs': 18,\n",
              " '__label__ha': 15,\n",
              " '__label__ht': 25,\n",
              " '__label__ib': 5,\n",
              " '__label__it': 10,\n",
              " '__label__ne': 2,\n",
              " '__label__ob': 0,\n",
              " '__label__pb': 3,\n",
              " '__label__po': 14,\n",
              " '__label__qa': 11,\n",
              " '__label__ra': 8,\n",
              " '__label__re': 19,\n",
              " '__label__rs': 13,\n",
              " '__label__rv': 6,\n",
              " '__label__sl': 24,\n",
              " '__label__sr': 16,\n",
              " '__label__ss': 1,\n",
              " '__label__tb': 12,\n",
              " '__label__tv': 4}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QcBJbEyQ2R8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "ea1e444e-6077-4781-f116-6f5e4df26e7a"
      },
      "source": [
        "train['Label_enc'] = train['Label'].map(label_encode)\n",
        "val['Label_enc'] = val['Label'].map(label_encode)\n",
        "val.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Text</th>\n",
              "      <th>Label_enc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>__label__ob</td>\n",
              "      <td>Just another UBC Blogs site  Main menu  Post n...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>__label__ob</td>\n",
              "      <td>Why getting Australians into mining jobs doesn...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>__label__ob</td>\n",
              "      <td>When people see the real Obama in his complete...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>__label__ob</td>\n",
              "      <td>Could we have a Corporate-free Olympics? Yes w...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>__label__ob</td>\n",
              "      <td>Is Obama trying to create a crisis?  And if so...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Label                                               Text  Label_enc\n",
              "0  __label__ob  Just another UBC Blogs site  Main menu  Post n...          0\n",
              "1  __label__ob  Why getting Australians into mining jobs doesn...          0\n",
              "2  __label__ob  When people see the real Obama in his complete...          0\n",
              "3  __label__ob  Could we have a Corporate-free Olympics? Yes w...          0\n",
              "4  __label__ob  Is Obama trying to create a crisis?  And if so...          0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQ4Oca3uQ91O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "bad2a083-3ca7-4067-a516-6de5ab1bc1ff"
      },
      "source": [
        "print(\"Training Set Shape :\", train.shape)\n",
        "print(\"Test Set Shape :\", val.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Set Shape : (17588, 3)\n",
            "Test Set Shape : (2210, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8VEk_s6RAwr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "7c963c28-d069-4bf7-a80e-41e513dc54f4"
      },
      "source": [
        "train['Label_enc'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2     5577\n",
              "16    1711\n",
              "0     1445\n",
              "17    1268\n",
              "3     1203\n",
              "7     1108\n",
              "6      802\n",
              "11     638\n",
              "25     586\n",
              "9      482\n",
              "24     369\n",
              "21     326\n",
              "13     323\n",
              "8      294\n",
              "5      236\n",
              "20     222\n",
              "23     213\n",
              "10     193\n",
              "15     145\n",
              "1      129\n",
              "12      90\n",
              "19      89\n",
              "22      76\n",
              "14      38\n",
              "18      16\n",
              "4        9\n",
              "Name: Label_enc, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3AfIPeBRJo6"
      },
      "source": [
        "# Shuffle the Dataset\n",
        "\n",
        "Shuffling helps model not to get biased and each datapoint creates independent change in the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0RJ8i24RDYU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "264728e5-ade1-42f8-d6ac-ff3f170e99ee"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "\n",
        "train = shuffle(train)\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Text</th>\n",
              "      <th>Label_enc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6365</th>\n",
              "      <td>__label__ne</td>\n",
              "      <td>New report published by GPs into the effects o...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3560</th>\n",
              "      <td>__label__ne</td>\n",
              "      <td>A military judge said accused Fort Hood gunman...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17170</th>\n",
              "      <td>__label__ht</td>\n",
              "      <td>How to Deal With Social Media Marketing Pet Pe...</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11719</th>\n",
              "      <td>__label__qa</td>\n",
              "      <td>Other Answers (4)  depends on the situation. F...</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6100</th>\n",
              "      <td>__label__ne</td>\n",
              "      <td>Women spend 3,276 hours getting ready  Women s...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Label  ... Label_enc\n",
              "6365   __label__ne  ...         2\n",
              "3560   __label__ne  ...         2\n",
              "17170  __label__ht  ...        25\n",
              "11719  __label__qa  ...        11\n",
              "6100   __label__ne  ...         2\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PolKWIX2R1uX"
      },
      "source": [
        "# Running BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Brm8KL4lRem-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "279e59cb-ec2c-4c71-db9f-3be8133bd708"
      },
      "source": [
        "#Installing BERT module\n",
        "!pip install bert-tensorflow\n",
        "\n",
        "#Importing BERT modules\n",
        "import bert\n",
        "from bert import run_classifier\n",
        "from bert import optimization\n",
        "from bert import tokenization"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/16/0f9376af49c6adcfbaf2470a8f500105a74dd803aa54ac0110af445837b5/bert_tensorflow-1.0.4-py2.py3-none-any.whl (64kB)\n",
            "\r\u001b[K     |█████                           | 10kB 26.6MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 20kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 30kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 40kB 3.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 51kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 61kB 3.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 3.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow) (1.15.0)\n",
            "Installing collected packages: bert-tensorflow\n",
            "Successfully installed bert-tensorflow-1.0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47AvKGTMRwFr"
      },
      "source": [
        "DATA_COLUMN = 'Text'\n",
        "LABEL_COLUMN = 'Label_enc'\n",
        "\n",
        "train_InputExamples = train.apply(lambda x: bert.run_classifier.InputExample(guid=None,\n",
        "                                                                   text_a = x[DATA_COLUMN], \n",
        "                                                                   text_b = None, \n",
        "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
        "\n",
        "val_InputExamples = val.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n",
        "                                                                   text_a = x[DATA_COLUMN], \n",
        "                                                                   text_b = None, \n",
        "                                                                   label = x[LABEL_COLUMN]), axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aymdhzIHIMqZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "df13edb1-3ad5-4c19-f331-2b8cce44f1e1"
      },
      "source": [
        "val.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Text</th>\n",
              "      <th>Label_enc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>__label__ob</td>\n",
              "      <td>Just another UBC Blogs site  Main menu  Post n...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>__label__ob</td>\n",
              "      <td>Why getting Australians into mining jobs doesn...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>__label__ob</td>\n",
              "      <td>When people see the real Obama in his complete...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>__label__ob</td>\n",
              "      <td>Could we have a Corporate-free Olympics? Yes w...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>__label__ob</td>\n",
              "      <td>Is Obama trying to create a crisis?  And if so...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Label                                               Text  Label_enc\n",
              "0  __label__ob  Just another UBC Blogs site  Main menu  Post n...          0\n",
              "1  __label__ob  Why getting Australians into mining jobs doesn...          0\n",
              "2  __label__ob  When people see the real Obama in his complete...          0\n",
              "3  __label__ob  Could we have a Corporate-free Olympics? Yes w...          0\n",
              "4  __label__ob  Is Obama trying to create a crisis?  And if so...          0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQM7AEeeSH9k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "46a921bd-b03a-450c-8cc8-8f1006ea2fcd"
      },
      "source": [
        "train_InputExamples"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6365     <bert.run_classifier.InputExample object at 0x...\n",
              "3560     <bert.run_classifier.InputExample object at 0x...\n",
              "17170    <bert.run_classifier.InputExample object at 0x...\n",
              "11719    <bert.run_classifier.InputExample object at 0x...\n",
              "6100     <bert.run_classifier.InputExample object at 0x...\n",
              "                               ...                        \n",
              "8013     <bert.run_classifier.InputExample object at 0x...\n",
              "16918    <bert.run_classifier.InputExample object at 0x...\n",
              "4136     <bert.run_classifier.InputExample object at 0x...\n",
              "794      <bert.run_classifier.InputExample object at 0x...\n",
              "913      <bert.run_classifier.InputExample object at 0x...\n",
              "Length: 17588, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uF75ZqTSJ77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "cdfcf159-1890-4906-c7c6-e065f3b668a6"
      },
      "source": [
        "print(\"Row 0 - guid of training set : \", train_InputExamples.iloc[0].guid)\n",
        "print(\"\\n__________\\nRow 0 - text_a of training set : \", train_InputExamples.iloc[0].text_a)\n",
        "print(\"\\n__________\\nRow 0 - text_b of training set : \", train_InputExamples.iloc[0].text_b)\n",
        "print(\"\\n__________\\nRow 0 - label of training set : \", train_InputExamples.iloc[0].label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Row 0 - guid of training set :  None\n",
            "\n",
            "__________\n",
            "Row 0 - text_a of training set :  New report published by GPs into the effects of current austerity measures  Concerns have been raised in several quarters about the consequences of the Government's welfare reforms and other austerity measures, which have been implemented since October 2010. These concerns include the negative impact that cuts in benefits are having on some of society's most vulnerable individuals and families. GPs and primary healthcare professionals are at the frontline in responding to the needs of these people.  A new report published by GPs,'GPs at the Deep End', comments on the effects of current austerity measures on the most deprived GP practices in Scotland. 'GPs at the Deep End' work in 100 general practices serving the most socio-economically deprived populations in Scotland. This report draws on the recent experiences of Deep End practices, as they were asked to reflect on the effects of austerity measures on patients and on patient care. Responses included general comments and individual case studies. The report makes for grim reading. It describes the direct and indirect consequences of austerity policies on patient health and on the systems that are in place to support health and wellbeing. The case studies are a graphic illustration of the strain these systems are already under; and more importantly, the strain that the most vulnerable -- the elderly living in fuel poverty or the homeless mother and her child -- are experiencing right now.\n",
            "\n",
            "__________\n",
            "Row 0 - text_b of training set :  None\n",
            "\n",
            "__________\n",
            "Row 0 - label of training set :  2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIYTYkUcSWU3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "8bc82d9f-57ce-425b-c14d-672121f2cfa4"
      },
      "source": [
        "# This is a path to an uncased (all lowercase) version of BERT\n",
        "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
        "\n",
        "def create_tokenizer_from_hub_module():\n",
        "  \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
        "  with tf.Graph().as_default():\n",
        "    bert_module = hub.Module(BERT_MODEL_HUB)\n",
        "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
        "    with tf.Session() as sess:\n",
        "      vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
        "                                            tokenization_info[\"do_lower_case\"]])\n",
        "      \n",
        "  return bert.tokenization.FullTokenizer(\n",
        "      vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
        "\n",
        "tokenizer = create_tokenizer_from_hub_module()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1QdTvNCSZo1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "bd08f95e-fd8e-4468-9dd1-9dcde9271dda"
      },
      "source": [
        "#Here is what the tokenised sample of the first training set observation looks like\n",
        "print(tokenizer.tokenize(train_InputExamples.iloc[0].text_a))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnparsedFlagAccessError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnparsedFlagAccessError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-d5fd91c1d54b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Here is what the tokenised sample of the first training set observation looks like\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_InputExamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/bert/tokenization.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    190\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0msplit_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mpreserve_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0msplit_tokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/bert/tokenization.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0msplit_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0morig_tokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m       \u001b[0;32mif\u001b[0m \u001b[0mpreserve_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0msplit_tokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/bert/tokenization.py\u001b[0m in \u001b[0;36mpreserve_token\u001b[0;34m(token, vocab)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpreserve_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m   \u001b[0;34m\"\"\"Returns True if the token should forgo tokenization and be preserved.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreserve_unused_tokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/absl/flags/_flagvalues.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0;31m# get too much noise.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0m_exceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnparsedFlagAccessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnparsedFlagAccessError\u001b[0m: Trying to access flag --preserve_unused_tokens before flags were parsed."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYDp6w8pattc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNKfJLrMGzlU"
      },
      "source": [
        "label_list = train['Label_enc'].unique()\n",
        "# We'll set sequences to be at most 128 tokens long.\n",
        "MAX_SEQ_LENGTH = 128\n",
        "\n",
        "# Convert our train and validation features to InputFeatures that BERT understands.\n",
        "train_features = bert.run_classifier.convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "\n",
        "val_features = bert.run_classifier.convert_examples_to_features(val_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62Kc7CX-G1l3"
      },
      "source": [
        "val_InputExamples.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vcTyZrJL1cH"
      },
      "source": [
        "train_InputExamples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ef-4HiNIL3AC"
      },
      "source": [
        "val.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPnlmEAML5sM"
      },
      "source": [
        "#Example on first observation in the training set\n",
        "print(\"Sentence : \", train_InputExamples.iloc[0].text_a)\n",
        "print(\"-\"*30)\n",
        "print(\"Tokens : \", tokenizer.tokenize(train_InputExamples.iloc[0].text_a))\n",
        "print(\"-\"*30)\n",
        "print(\"Input IDs : \", train_features[0].input_ids)\n",
        "print(\"-\"*30)\n",
        "print(\"Input Masks : \", train_features[0].input_mask)\n",
        "print(\"-\"*30)\n",
        "print(\"Segment IDs : \", train_features[0].segment_ids)\n",
        "print('\\n\\n')\n",
        "print('Label ID:',train_features[-1].label_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtRcX0tMMC1m"
      },
      "source": [
        "\n",
        "def create_model(is_predicting, input_ids, input_mask, segment_ids, labels, num_labels):    \n",
        "    bert_module = hub.Module(BERT_MODEL_HUB, trainable=True)\n",
        "    bert_inputs = dict(input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids)\n",
        "    bert_outputs = bert_module(inputs=bert_inputs, signature=\"tokens\", as_dict=True)\n",
        "    output_layer = bert_outputs[\"pooled_output\"] # sequence_outputs as another option\n",
        "    hidden_size = output_layer.shape[-1].value\n",
        "\n",
        "    # Create our own layer to tune for classification.\n",
        "    output_weights = tf.get_variable(\"output_weights\", [num_labels, hidden_size], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "\n",
        "    output_bias = tf.get_variable(\"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
        "\n",
        "    with tf.variable_scope(\"loss\"):\n",
        "\n",
        "        output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
        "\n",
        "        logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
        "        logits = tf.nn.bias_add(logits, output_bias)\n",
        "        log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
        "\n",
        "        # Convert labels into one-hot encoding\n",
        "        one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
        "\n",
        "        predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
        "        # If we're predicting, we want predicted labels and the probabiltiies.\n",
        "        if is_predicting:\n",
        "            return (predicted_labels, log_probs)\n",
        "\n",
        "        # If we're train/eval, compute loss between predicted and actual label\n",
        "        per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
        "        loss = tf.reduce_mean(per_example_loss)\n",
        "        return (loss, predicted_labels, log_probs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8mqxJJfMGLC"
      },
      "source": [
        "#A function that adapts our model to work for training, evaluation, and prediction.\n",
        "\n",
        "# model_fn_builder actually creates our model function\n",
        "# using the passed parameters for num_labels, learning_rate, etc.\n",
        "def model_fn_builder(num_labels, learning_rate, num_train_steps, num_warmup_steps):\n",
        "    \n",
        "    \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
        "    def model_fn(features, labels, mode, params):\n",
        "        # pylint: disable=unused-argument\n",
        "        \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
        "        input_ids = features[\"input_ids\"]\n",
        "        input_mask = features[\"input_mask\"]\n",
        "        segment_ids = features[\"segment_ids\"]\n",
        "        label_ids = features[\"label_ids\"]\n",
        "\n",
        "        is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
        "    \n",
        "        # TRAIN and EVAL. \n",
        "        if not is_predicting:\n",
        "              (loss, predicted_labels, log_probs) = create_model(is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
        "\n",
        "              train_op = bert.optimization.create_optimizer(loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
        "\n",
        "              # Calculate evaluation metrics. \n",
        "              def metric_fn(label_ids, predicted_labels):\n",
        "\n",
        "                    accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n",
        "                    auc = tf.metrics.auc(label_ids, predicted_labels)\n",
        "                    predicted_labels = predicted_labels\n",
        "                    # f1_score = tf.contrib.metrics.f1_score(label_ids, predicted_labels)\n",
        "                    # recall = tf.metrics.recall(label_ids, predicted_labels)\n",
        "                    # precision = tf.metrics.precision(label_ids, predicted_labels)\n",
        "                    # true_pos = tf.metrics.true_positives(label_ids, predicted_labels)\n",
        "                    # true_neg = tf.metrics.true_negatives(label_ids, predicted_labels)   \n",
        "                    # false_pos = tf.metrics.false_positives(label_ids, predicted_labels)  \n",
        "                    # false_neg = tf.metrics.false_negatives(label_ids,  predicted_labels)\n",
        "\n",
        "                    return {\n",
        "                        \"eval_accuracy\": accuracy,\n",
        "                        #\"f1_score\":f1_score,\n",
        "                        # \"recall\":recall,\n",
        "                        # \"precision\":precision,\n",
        "                        # \"true_positives\": true_pos,\n",
        "                        # \"true_negatives\": true_neg,\n",
        "                        # \"false_positives\": false_pos,\n",
        "                        # \"false_negatives\": false_neg, \n",
        "                        #\"predicted_labels\": (predicted_labels)\n",
        "                        }\n",
        "                \n",
        "              eval_metrics = metric_fn(label_ids, predicted_labels)\n",
        "\n",
        "              if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "                      return tf.estimator.EstimatorSpec(mode=mode,loss=loss,train_op=train_op)\n",
        "              else:\n",
        "                    return tf.estimator.EstimatorSpec(mode=mode,  loss=loss, eval_metric_ops=eval_metrics)\n",
        "        else:\n",
        "            (predicted_labels, log_probs) = create_model(is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
        "            predictions = {'probabilities': log_probs,'labels': predicted_labels}\n",
        "            return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
        "\n",
        "    # Return the actual model function in the closure\n",
        "    return model_fn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5A4ikFaMNGJ"
      },
      "source": [
        "# Compute train and warmup steps from batch size\n",
        "# These hyperparameters are copied from this colab notebook (https://colab.sandbox.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb)\n",
        "BATCH_SIZE = 20\n",
        "LEARNING_RATE = 2e-5\n",
        "NUM_TRAIN_EPOCHS = 2.0\n",
        "# Warmup is a period of time where hte learning rate \n",
        "# is small and gradually increases--usually helps training.\n",
        "WARMUP_PROPORTION = 0.1\n",
        "# Model configs\n",
        "SAVE_CHECKPOINTS_STEPS = 500\n",
        "SAVE_SUMMARY_STEPS = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0VxTRW8MTWo"
      },
      "source": [
        "# Compute # train and warmup steps from batch size\n",
        "num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
        "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfC7UlrHMVvp"
      },
      "source": [
        "# Specify outpit directory and number of checkpoint steps to save\n",
        "run_config = tf.estimator.RunConfig(\n",
        "    model_dir='/content/drive/My Drive/Colab Notebooks/BERT/bert_imbalanced',\n",
        "    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
        "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mH3_iA09Mal4"
      },
      "source": [
        "model_fn = model_fn_builder(\n",
        "  num_labels=len(label_list),\n",
        "  learning_rate=LEARNING_RATE,\n",
        "  num_train_steps=num_train_steps,\n",
        "  num_warmup_steps=num_warmup_steps)\n",
        "\n",
        "#metric_fn = model_fn(features , labels , mode , params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpM1girfzRYe"
      },
      "source": [
        "###**TensorFlow Estimators**\n",
        "The Estimator object wraps a model which is specified by a model_fn, which, given inputs and a number of other parameters, returns the ops necessary to perform training, evaluation, or predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dqC89hRMcqR"
      },
      "source": [
        "estimator = tf.estimator.Estimator(\n",
        "  model_fn=model_fn,\n",
        "  config=run_config,\n",
        "  params={\"batch_size\": BATCH_SIZE})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OEFoixAMeH2"
      },
      "source": [
        "# Create an input function for training. drop_remainder = True for using TPUs.\n",
        "train_input_fn = bert.run_classifier.input_fn_builder(\n",
        "    features=train_features,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=True,\n",
        "    drop_remainder=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9D1d1UzAMgil"
      },
      "source": [
        "\n",
        "len(train_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Kh5H8o9MjEn"
      },
      "source": [
        "%%time\n",
        "print(f'Beginning Training!')\n",
        "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v041Z5mgMlN1"
      },
      "source": [
        "test_input_fn = run_classifier.input_fn_builder(\n",
        "    features=val_features,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=False,\n",
        "    drop_remainder=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWHvlFA2Mnzu"
      },
      "source": [
        "#evaluate on test dataset\n",
        "estimator.evaluate(input_fn=test_input_fn, steps=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSKgyYIPU84S"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjHRryjBI0_9"
      },
      "source": [
        "preds_train = estimator.predict(input_fn=train_input_fn)\n",
        "preds_train_label = []\n",
        "for i in (preds_train):\n",
        "  preds_train_label.append(i['labels'])\n",
        "  #print(i)\n",
        "  #break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYUZDucQMpar"
      },
      "source": [
        "preds = estimator.predict(input_fn=test_input_fn)\n",
        "pred_label = []\n",
        "for i in  (preds):\n",
        "  pred_label.append(i['labels'])\n",
        "  # print(i['labels'])\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8nN3FhNHxT7"
      },
      "source": [
        "#print(pred_label)\n",
        "print(val['Label_enc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpySMH3DlNsy"
      },
      "source": [
        "orig_label = val['Label_enc'].tolist()\n",
        "print(orig_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amjVC6cbVueI"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "y_true = orig_label\n",
        "y_pred = pred_label\n",
        "print(classification_report(y_true, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvXKIJ608Zv2"
      },
      "source": [
        "print(y_true)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMGVd4i2VwCK"
      },
      "source": [
        "print(y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1F8wuYXS8cic"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLF16g1Xc82B"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}