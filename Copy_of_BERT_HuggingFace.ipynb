{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of BERT_HuggingFace.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "PdC0h-cVb5Mh"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTdoo4yF0z7E",
        "outputId": "9f489428-2174-4419-a360-5772451953ee"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QV3aGrCp034m",
        "outputId": "9e8789b6-5577-4fc1-bca3-da696c852901"
      },
      "source": [
        "!pip install torch"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.7.0+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch) (0.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "7H-mEyAjQm-N",
        "outputId": "0072dd09-4c18-409d-b6c0-451777901a0f"
      },
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "torch.cuda.memory_summary(device=None, abbreviated=False)\n"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |    2154 MB |    6484 MB |   74358 GB |   74356 GB |\\n|       from large pool |    2152 MB |    6481 MB |   74337 GB |   74335 GB |\\n|       from small pool |       2 MB |      21 MB |      21 GB |      21 GB |\\n|---------------------------------------------------------------------------|\\n| Active memory         |    2154 MB |    6484 MB |   74358 GB |   74356 GB |\\n|       from large pool |    2152 MB |    6481 MB |   74337 GB |   74335 GB |\\n|       from small pool |       2 MB |      21 MB |      21 GB |      21 GB |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |    2238 MB |    6704 MB |    6704 MB |    4466 MB |\\n|       from large pool |    2234 MB |    6676 MB |    6676 MB |    4442 MB |\\n|       from small pool |       4 MB |      28 MB |      28 MB |      24 MB |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |   85247 KB |  239171 KB |   23833 GB |   23833 GB |\\n|       from large pool |   83968 KB |  238592 KB |   23812 GB |   23811 GB |\\n|       from small pool |    1279 KB |    7220 KB |      21 GB |      21 GB |\\n|---------------------------------------------------------------------------|\\n| Allocations           |    1009    |    1265    |    7803 K  |    7802 K  |\\n|       from large pool |     375    |     571    |    3925 K  |    3924 K  |\\n|       from small pool |     634    |     837    |    3877 K  |    3877 K  |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |    1009    |    1265    |    7803 K  |    7802 K  |\\n|       from large pool |     375    |     571    |    3925 K  |    3924 K  |\\n|       from small pool |     634    |     837    |    3877 K  |    3877 K  |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |     131    |     268    |     268    |     137    |\\n|       from large pool |     129    |     254    |     254    |     125    |\\n|       from small pool |       2    |      14    |      14    |      12    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |      58    |      71    |    3124 K  |    3124 K  |\\n|       from large pool |      43    |      49    |    1607 K  |    1607 K  |\\n|       from small pool |      15    |      26    |    1517 K  |    1517 K  |\\n|===========================================================================|\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1VVKk67IWWn"
      },
      "source": [
        ""
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMtL0ckQ5caX",
        "outputId": "90d8f3df-babe-4fea-d563-b6ff88b9e0f0"
      },
      "source": [
        "!pip install transformers==3.0.0"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers==3.0.0 in /usr/local/lib/python3.6/dist-packages (3.0.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.0) (0.1.95)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.0) (0.0.43)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.0) (4.41.1)\n",
            "Requirement already satisfied: tokenizers==0.8.0-rc4 in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.0) (0.8.0rc4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.0) (20.8)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.0) (2019.12.20)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.0) (0.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.0) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.0) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.0) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.0.0) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.0.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.0.0) (1.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.0.0) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.0.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.0.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.0.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.0.0) (2020.12.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ff2f8k6F2K_2"
      },
      "source": [
        "from transformers import XLNetConfig, XLNetTokenizer, XLNetForSequenceClassification\n",
        "from transformers import BertTokenizer, BertModel\n"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHOYS7rG5Zt8"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "train = pd.read_csv('/content/drive/My Drive/Colab Notebooks/train_file.txt', sep='{}{}{}', engine = 'python')\n",
        "test = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/test_file.txt\", sep= '{}{}{}', engine = 'python')\n",
        "devset = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/devset.txt\", sep= '{}{}{}', engine = 'python')\n",
        "#train_inputs, validation_inputs, train_labels, validation_labels = train_test_split()\n",
        "#from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, val =  train,test"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "mC-mMsys_Ell",
        "outputId": "558fa83c-2841-4991-8479-53af6ba2d9fc"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "\n",
        "train = shuffle(train)\n",
        "train.head()"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3827</th>\n",
              "      <td>__label__ne</td>\n",
              "      <td>Wolfgang Krauel is new co-head of the global I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1350</th>\n",
              "      <td>__label__ob</td>\n",
              "      <td>Editor's Note: Building on Mark Glanville's Ol...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6510</th>\n",
              "      <td>__label__ne</td>\n",
              "      <td>Mafia issues strenuous News International deni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13701</th>\n",
              "      <td>__label__sr</td>\n",
              "      <td>In less than 7 days Tom Cleverley was given a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2281</th>\n",
              "      <td>__label__ne</td>\n",
              "      <td>But what the 41-year-old English actor came up...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Label                                               Text\n",
              "3827   __label__ne  Wolfgang Krauel is new co-head of the global I...\n",
              "1350   __label__ob  Editor's Note: Building on Mark Glanville's Ol...\n",
              "6510   __label__ne  Mafia issues strenuous News International deni...\n",
              "13701  __label__sr  In less than 7 days Tom Cleverley was given a ...\n",
              "2281   __label__ne  But what the 41-year-old English actor came up..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKCkR8OkA-Gk",
        "outputId": "85cfe2d6-1ff0-4f2d-ec65-5565dc773936"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "labels =train['Label'].values\n",
        "label_encoder = LabelEncoder()    # Turns class labels into integers\n",
        "Y = label_encoder.fit_transform(labels)\n",
        "labels_dev=devset['Label'].values\n",
        "\n",
        "# Take note of how many unique labels there are in the data\n",
        "num_labels = len(set(Y))\n",
        "\n",
        "\n",
        "# Print out some examples\n",
        "print('Number of unique labels:', num_labels)\n",
        "print(type(labels), labels[:10])\n",
        "print(type(Y), Y[:10])\n",
        "print('\\n')\n",
        "print(labels_dev[:10])"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of unique labels: 26\n",
            "<class 'numpy.ndarray'> ['__label__ne' '__label__ob' '__label__ne' '__label__sr' '__label__ne'\n",
            " '__label__ht' '__label__rs' '__label__ra' '__label__ob' '__label__rs']\n",
            "<class 'numpy.ndarray'> [12 13 12 22 12  9 19 17 13 19]\n",
            "\n",
            "\n",
            "['__label__ht' '__label__ht' '__label__ht' '__label__ht' '__label__ht'\n",
            " '__label__ht' '__label__ht' '__label__ht' '__label__ht' '__label__ht']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvJBt7MQRbNk"
      },
      "source": [
        ""
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkzTNYewDAKN"
      },
      "source": [
        "Y_val = label_encoder.fit_transform(test['Label'].values)"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bS64SQIKDEcD",
        "outputId": "34c3886c-3a40-4e2b-b33e-b3bf56011d74"
      },
      "source": [
        "Y_val"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([13, 13, 13, ...,  9,  9,  9])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "iRle8Oj3DHSC",
        "outputId": "8aaf79c5-f110-4cd2-fcb3-dcd11297f7e7"
      },
      "source": [
        "\n",
        "# Get sentence data\n",
        "sents = train.Text.to_list()\n",
        "sents[0]"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Wolfgang Krauel is new co-head of the global Insurance practice at Linklaters  Share this  Wolfgang Krauel is new co-head of the global Insurance practice at Linklaters  16 April 2008  With immediate effect, Dr Wolfgang Krauel is the new head of the Insurance practice in Germany and new co-head of the global Insurance practice at Linklaters. 45-year-old partner Wolfgang Krauel has specialised experience in stock corporation law and M&A transactions. In recent years, he mainly advised on financial and insurance industry issues and has developed a specific expertise in this market segment.  Linklaters combines its sector-specific competences in 20 global sector groups, such as automotive, energy and utilities or healthcare. Lawyers with expertise in various fields of law co-operate in teams and provide advice based on their comprehensive industry-related know-how to the relevant clients.  The German Insurance core team provides comprehensive advice to market participants on complex civil and tax law issues, particularly regarding M&A/corporate, regulatory law, law on insurance contracts and capital market products. The team is led by Wolfgang Krauel as well as by Andreas Steck (regulatory law) and Dr Gunbritt Kammerer-Galahn (M&A transactions and German and European insurance law).  In Germany, Linklaters most recently advised inter alia AXA on the take-over of the legal protection insurance portfolio of DBV Winterthur by ROLAND and Zurich Group on the acquisition of Real Garant Versicherung AG.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2mLv0B3DXDA",
        "outputId": "a75c1329-f4f0-4e2d-b74d-cef47a5cf82c"
      },
      "source": [
        "labels = train.Label.to_list()\n",
        "print(labels[0])"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__label__ne\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeITJ0DSDZum"
      },
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqPkvbQpFc3c",
        "outputId": "d95ebf1f-345d-4a74-9c08-52e34c09f9ee"
      },
      "source": [
        "n_gpu"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lz6gPqqDJcmj"
      },
      "source": [
        "### Bert Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qIl1-yvFeMG"
      },
      "source": [
        "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
        "import logging\n",
        "#logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "# Load pre-trained model tokenizer (vocabulary)\n",
        "tokenizer_bert = BertTokenizer.from_pretrained('bert-base-uncased', output_hidden_states = True)"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eMKiLrXGgdo"
      },
      "source": [
        "### Tokenization using XLNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3grhQzzHY5KO",
        "outputId": "8032318d-dcd5-44bd-9839-7eae8059fbdc"
      },
      "source": [
        "list(tokenizer_bert.vocab.keys())[5000:5020]"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['knight',\n",
              " 'lap',\n",
              " 'survey',\n",
              " 'ma',\n",
              " '##ow',\n",
              " 'noise',\n",
              " 'billy',\n",
              " '##ium',\n",
              " 'shooting',\n",
              " 'guide',\n",
              " 'bedroom',\n",
              " 'priest',\n",
              " 'resistance',\n",
              " 'motor',\n",
              " 'homes',\n",
              " 'sounded',\n",
              " 'giant',\n",
              " '##mer',\n",
              " '150',\n",
              " 'scenes']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWp7tTttGbKP",
        "outputId": "937066c9-b547-4e39-da69-d88fc33e5381"
      },
      "source": [
        "!pip install sentencepiece\n",
        "vocabulary = '/content/drive/My Drive/Colab Notebooks/xlnet-base-cased-spiece.model'\n"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (0.1.95)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgcAUOTgGn2A"
      },
      "source": [
        "max_len  = 256"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BswrMpy2GsZM"
      },
      "source": [
        "# With cased model, set do_lower_case = False\n",
        "tokenizer_xlnet = XLNetTokenizer(vocab_file=vocabulary,do_lower_case=True)"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCRtEf1LGyfK",
        "outputId": "15c809ae-bf5a-4175-b932-c287f630022f"
      },
      "source": [
        "var = tokenizer_bert(\"I'm doing NLP thesis\")\n",
        "print(var['input_ids'])\n",
        "print(var['token_type_ids'])\n",
        "print(var['attention_mask'])\n",
        "print(tokenizer_bert.tokenize(\"I'm doing NLP thesis\"))\n",
        "print(tokenizer_bert.encode('_thesis'))\n",
        "print(tokenizer_bert.decode(101))\n",
        "print(tokenizer_bert.decode(102))"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[101, 1045, 1005, 1049, 2725, 17953, 2361, 9459, 102]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "['i', \"'\", 'm', 'doing', 'nl', '##p', 'thesis']\n",
            "[101, 1035, 9459, 102]\n",
            "[ C L S ]\n",
            "[ S E P ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3s_vRruHFNS",
        "outputId": "4537fdc6-78a1-4d2c-ead6-ab6308b4fb08"
      },
      "source": [
        "tokenizer_bert.encode('word')"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[101, 2773, 102]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiW8FPVIHsEz",
        "outputId": "cc2ec17b-fac1-4f49-e16a-4e0cbb0345f9"
      },
      "source": [
        "tokenizer_xlnet.encode('word')"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1139, 4, 3]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edIgy3fmHy0N"
      },
      "source": [
        "### BERT Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eHPrQKdHt2k",
        "outputId": "a93cb62f-633f-4992-a781-51d3d6ffab4b"
      },
      "source": [
        "var = tokenizer_bert(['This is great world.','World is good.'], add_special_tokens= True, max_length=20,  padding= 'max_length', return_attention_mask=True )\n",
        "var"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [[101, 2023, 2003, 2307, 2088, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2088, 2003, 2204, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "231gC7G1JoxJ"
      },
      "source": [
        "tokenized_text_bert = tokenizer_bert(list(train.Text.values), \n",
        "                                     add_special_tokens= True,\n",
        "                                     max_length=256,  \n",
        "                                     padding= 'max_length', \n",
        "                                     return_attention_mask=True,\n",
        "                                     return_tensors='pt', \n",
        "                                     truncation=True )"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIyOHcoIsxtU",
        "outputId": "7ec06396-6766-40ad-b015-bab35f7201dc"
      },
      "source": [
        "tokenized_text_xl = tokenizer_xlnet( vocabulary, max_length=256,add_special_tokens =True , padding= 'max_length', return_tensors='pt',truncation=True )\n",
        "tokenized_text_xl.keys()"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLTfWEA3SG1-"
      },
      "source": [
        "tokenizedtext_bert_test = tokenizer_bert(list(test.Text.values), \n",
        "                                     add_special_tokens= True,\n",
        "                                     max_length=256,  \n",
        "                                     padding= 'max_length', \n",
        "                                     return_attention_mask=True,\n",
        "                                     return_tensors='pt', \n",
        "                                     truncation=True \n",
        "    \n",
        ")"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WROl8wjES5DU"
      },
      "source": [
        "# train.Text.values[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRsGwDgrTDou"
      },
      "source": [
        "\n",
        "#print((tokenized_text['input_ids'][:2]))\n",
        "tokenized_text_bert.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-eRBKFUNZJD",
        "outputId": "298cd15b-4acd-4910-84dd-5510e5b63539"
      },
      "source": [
        "input_ids = tokenized_text_bert['input_ids']\n",
        "attention_masks = tokenized_text_bert['attention_mask']\n",
        "Y [:10]\n"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([12, 13, 12, 22, 12,  9, 19, 17, 13, 19])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gC-6nUr2Sb2C"
      },
      "source": [
        "inputid_test = tokenizedtext_bert_test['input_ids']\n",
        "attentionmask_test = tokenizedtext_bert_test['attention_mask']\n",
        "Y_val = torch.Tensor(Y_val)"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWKUVPERDdrl"
      },
      "source": [
        "# from transformers import BertTokenizer\n",
        "\n",
        "# # Load the BERT tokenizer.\n",
        "# print('Loading BERT tokenizer...')\n",
        "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "# max_len = 0\n",
        "\n",
        "# # For every sentence...\n",
        "# for sent in sentences:\n",
        "\n",
        "#     # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "#     input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "\n",
        "#     # Update the maximum sentence length.\n",
        "#     max_len = max(max_len, len(input_ids))\n",
        "\n",
        "# print('Max sentence length: ', max_len)"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSojfbvNU-l2"
      },
      "source": [
        "#tokenized_text['token_type_ids'][:2]"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTI4OGrGban5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68e6d739-2af7-4b45-c9a9-311dae97d350"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 26, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    \n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=26, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlNLMKhxfYPd",
        "outputId": "6e887f68-0f31-407b-fa2b-c7ef096a40b5"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{} {}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{} {}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{} {}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight (2, 768)\n",
            "bert.embeddings.LayerNorm.weight (768,)\n",
            "bert.embeddings.LayerNorm.bias (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight (768, 768)\n",
            "bert.pooler.dense.bias (768,)\n",
            "classifier.weight (26, 768)\n",
            "classifier.bias (26,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzR2VKYisskN"
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgya1C45QdWG",
        "outputId": "9eb2180a-d874-4179-dcc2-c5df8ba599a5"
      },
      "source": [
        "Y = torch.tensor(Y)\n",
        "#Y_val = torch.tensor(Y_val)\n",
        "Y"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([12, 13, 12,  ..., 12, 13, 18])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnhyNvwqCoui",
        "outputId": "b7030a6e-90a3-4f29-8381-09b4322eaaae"
      },
      "source": [
        "Y_val = torch.tensor(Y_val, dtype=torch.long)\n",
        "Y_val"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([13, 13, 13,  ...,  9,  9,  9])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgHkjb3RANPM"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "train_dataset = TensorDataset(input_ids, attention_masks, Y ) #labels = Y\n",
        "val_dataset = TensorDataset(inputid_test,attentionmask_test,Y_val)"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9TJIgSdQ8co",
        "outputId": "49253d60-03aa-43fa-dfa1-ff9051a27057"
      },
      "source": [
        "train_dataset"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataset.TensorDataset at 0x7fc788b9ceb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "It7joUSR9EWt"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "#Batch size of 16 or 32 is ideal.\n",
        "batch_size = 16\n",
        "\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLOMvjQ8ff5z",
        "outputId": "29a494ce-36ec-4139-b796-c7018afb29ba"
      },
      "source": [
        "for batch in validation_dataloader:\n",
        "  print((batch[2].to(device)))\n",
        "  break"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13],\n",
            "       device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S20RgSHDIqgH",
        "outputId": "7875d1e7-56ba-48ca-f213-925520e715aa"
      },
      "source": [
        "for batch in train_dataloader:\n",
        "  print((batch[2].to(device)))\n",
        "  break"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 9, 14,  1,  9, 12, 12, 13, 10, 16, 11, 16, 12, 12,  5, 12, 12],\n",
            "       device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQ26wPBn15Gz"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "\n",
        "epochs = 4\n",
        "batch_size = 16\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HARjQ0ub1-Mz"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbW-2yNSy-K3"
      },
      "source": [
        ""
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DPChyj5vIKw",
        "outputId": "0026667a-0cd6-40e2-9bd1-aee7b9f05818"
      },
      "source": [
        "import numpy as np\n",
        "a  = np.array([[0., 0.03,.01, 0., 0.02,.1,0.0, 0.5,.2,.1], [0., 0.03,.01, 0., 0.02,.1,0.0, 0.5,.2,.1], [0., 0.03,.01, 0., 0.02,.1,0.0, 0.5,.2,.1],[0., 0.03,.01, 0., 0.02,.1,0.0, 0.5,.2,.1]])\n",
        "a"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.  , 0.03, 0.01, 0.  , 0.02, 0.1 , 0.  , 0.5 , 0.2 , 0.1 ],\n",
              "       [0.  , 0.03, 0.01, 0.  , 0.02, 0.1 , 0.  , 0.5 , 0.2 , 0.1 ],\n",
              "       [0.  , 0.03, 0.01, 0.  , 0.02, 0.1 , 0.  , 0.5 , 0.2 , 0.1 ],\n",
              "       [0.  , 0.03, 0.01, 0.  , 0.02, 0.1 , 0.  , 0.5 , 0.2 , 0.1 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aF15qyKwKZm"
      },
      "source": [
        "#conf(np.argmax(a), truelabe)"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jvw9WFGT2DOO"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oC2OLL1iZ4_-"
      },
      "source": [
        "def wipe_memory(self): # DOES WORK\n",
        "    self._optimizer_to(torch.device('cpu'))\n",
        "    del self.optimizer\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "def _optimizer_to(self, device):\n",
        "    for param in self.optimizer.state.values():\n",
        "        # Not sure there are any global tensors in the state dict\n",
        "        if isinstance(param, torch.Tensor):\n",
        "            param.data = param.data.to(device)\n",
        "            if param._grad is not None:\n",
        "                param._grad.data = param._grad.data.to(device)\n",
        "        elif isinstance(param, dict):\n",
        "            for subparam in param.values():\n",
        "                if isinstance(subparam, torch.Tensor):\n",
        "                    subparam.data = subparam.data.to(device)\n",
        "                    if subparam._grad is not None:\n",
        "                        subparam._grad.data = subparam._grad.data.to(device)"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVCkzWE82IMx",
        "outputId": "77740091-366b-4f1f-aa13-61cc31b3b324"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. \n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "      \n",
        "\n",
        "        # Progress update every 100 batches.\n",
        "        if step % 100 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. After unpacking, we copy\n",
        "        # the tensor to the GPU as well using .to()\n",
        "        \n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #  0 for input id, 1 for attention mask and 2 for labels\n",
        "        \n",
        "        if torch.cuda.is_available():\n",
        "          b_input_ids = batch[0].to(device)\n",
        "          b_input_mask = batch[1].to(device)\n",
        "          b_labels = batch[2].to(device)\n",
        "        else:\n",
        "          torch.cuda.empty_cache()\n",
        "\n",
        "        # we clear previously calculated gradients before a backward pass.\n",
        "        \n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # We can get logit, output before activation\n",
        "         \n",
        "        if torch.cuda.is_available():\n",
        "          loss, logits = model(b_input_ids, \n",
        "                              token_type_ids=None, \n",
        "                              attention_mask=b_input_mask, \n",
        "                              labels=b_labels)\n",
        "        else:\n",
        "          torch.cuda.empty_cache()\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. \n",
        "        total_train_loss += loss.item() # .item() returns the python value from the tensor\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0 to help prevent exploding gradient\n",
        "         \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient. This \n",
        "        # is for how parameters are modified based on different parameters\n",
        "         \n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode \n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    predictions = [] #store prediction\n",
        "    true_labels = []\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. After unpacking, we copy\n",
        "        # the tensor to the GPU as well using .to()\n",
        "        \n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #  0 for input id, 1 for attention mask and 2 for labels\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        " \n",
        "        \n",
        "        # We dont need to compute graph for forward pass\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # Get logit, output prior to activation\n",
        "            if torch.cuda.is_available():\n",
        "              (loss, logits) = model(b_input_ids, \n",
        "              token_type_ids=None,  # Segment ids, to differentiate 2 sentences which we dont need\n",
        "              attention_mask=b_input_mask,\n",
        "              labels=b_labels)\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        #collect predictions\n",
        "        # \n",
        "        pred = np.argmax(logits, 1)\n",
        "        predictions.append(pred)\n",
        "        #prediction.append(logits)\n",
        "        true_labels.append(label_ids)\n",
        "\n",
        "      \n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch   100  of  1,100.    Elapsed: 0:00:25.\n",
            "  Batch   200  of  1,100.    Elapsed: 0:00:51.\n",
            "  Batch   300  of  1,100.    Elapsed: 0:01:17.\n",
            "  Batch   400  of  1,100.    Elapsed: 0:01:42.\n",
            "  Batch   500  of  1,100.    Elapsed: 0:02:08.\n",
            "  Batch   600  of  1,100.    Elapsed: 0:02:34.\n",
            "  Batch   700  of  1,100.    Elapsed: 0:02:59.\n",
            "  Batch   800  of  1,100.    Elapsed: 0:03:25.\n",
            "  Batch   900  of  1,100.    Elapsed: 0:03:51.\n",
            "  Batch 1,000  of  1,100.    Elapsed: 0:04:17.\n",
            "\n",
            "  Average training loss: 1.26\n",
            "  Training epcoh took: 0:04:42\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.74\n",
            "  Validation Loss: 0.93\n",
            "  Validation took: 0:00:10\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch   100  of  1,100.    Elapsed: 0:00:26.\n",
            "  Batch   200  of  1,100.    Elapsed: 0:00:51.\n",
            "  Batch   300  of  1,100.    Elapsed: 0:01:17.\n",
            "  Batch   400  of  1,100.    Elapsed: 0:01:43.\n",
            "  Batch   500  of  1,100.    Elapsed: 0:02:08.\n",
            "  Batch   600  of  1,100.    Elapsed: 0:02:34.\n",
            "  Batch   700  of  1,100.    Elapsed: 0:03:00.\n",
            "  Batch   800  of  1,100.    Elapsed: 0:03:26.\n",
            "  Batch   900  of  1,100.    Elapsed: 0:03:51.\n",
            "  Batch 1,000  of  1,100.    Elapsed: 0:04:17.\n",
            "\n",
            "  Average training loss: 0.67\n",
            "  Training epcoh took: 0:04:43\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.77\n",
            "  Validation Loss: 0.83\n",
            "  Validation took: 0:00:10\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch   100  of  1,100.    Elapsed: 0:00:26.\n",
            "  Batch   200  of  1,100.    Elapsed: 0:00:51.\n",
            "  Batch   300  of  1,100.    Elapsed: 0:01:17.\n",
            "  Batch   400  of  1,100.    Elapsed: 0:01:43.\n",
            "  Batch   500  of  1,100.    Elapsed: 0:02:08.\n",
            "  Batch   600  of  1,100.    Elapsed: 0:02:34.\n",
            "  Batch   700  of  1,100.    Elapsed: 0:03:00.\n",
            "  Batch   800  of  1,100.    Elapsed: 0:03:25.\n",
            "  Batch   900  of  1,100.    Elapsed: 0:03:51.\n",
            "  Batch 1,000  of  1,100.    Elapsed: 0:04:17.\n",
            "\n",
            "  Average training loss: 0.42\n",
            "  Training epcoh took: 0:04:42\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.76\n",
            "  Validation Loss: 0.86\n",
            "  Validation took: 0:00:10\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch   100  of  1,100.    Elapsed: 0:00:26.\n",
            "  Batch   200  of  1,100.    Elapsed: 0:00:51.\n",
            "  Batch   300  of  1,100.    Elapsed: 0:01:17.\n",
            "  Batch   400  of  1,100.    Elapsed: 0:01:43.\n",
            "  Batch   500  of  1,100.    Elapsed: 0:02:08.\n",
            "  Batch   600  of  1,100.    Elapsed: 0:02:34.\n",
            "  Batch   700  of  1,100.    Elapsed: 0:03:00.\n",
            "  Batch   800  of  1,100.    Elapsed: 0:03:26.\n",
            "  Batch   900  of  1,100.    Elapsed: 0:03:51.\n",
            "  Batch 1,000  of  1,100.    Elapsed: 0:04:17.\n",
            "\n",
            "  Average training loss: 0.29\n",
            "  Training epcoh took: 0:04:43\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.77\n",
            "  Validation Loss: 0.91\n",
            "  Validation took: 0:00:10\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:19:30 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "DTIrQas82MUY",
        "outputId": "0c5b97f4-8603-4b36-d124-a41afca2c447"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.26</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0:04:42</td>\n",
              "      <td>0:00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.67</td>\n",
              "      <td>0.83</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0:04:43</td>\n",
              "      <td>0:00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.42</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0:04:42</td>\n",
              "      <td>0:00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.29</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0:04:43</td>\n",
              "      <td>0:00:10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               1.26         0.93           0.74       0:04:42         0:00:10\n",
              "2               0.67         0.83           0.77       0:04:43         0:00:10\n",
              "3               0.42         0.86           0.76       0:04:42         0:00:10\n",
              "4               0.29         0.91           0.77       0:04:43         0:00:10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "YG9bnIFZ2PNf",
        "outputId": "e3cb6052-b8f6-407c-fdca-e82d61992e29"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuUAAAGaCAYAAACopj13AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3hUZdoG8Ht6yqSTZkLHhBZCQEAERUog9BYSFgwqKIIUhVUBy1r2A11AQUBgBVYUKUJCJ/SiIgLSQUILHdJIr9O/P5IMGSYJk5DkzIT7d117wZw558wzY97lzjvPeY/IYDAYQEREREREghELXQARERER0dOOoZyIiIiISGAM5UREREREAmMoJyIiIiISGEM5EREREZHAGMqJiIiIiATGUE5Etdbdu3cRGBiIhQsXVvoc06dPR2BgYBVWVXuV9XkHBgZi+vTpFp1j4cKFCAwMxN27d6u8vo0bNyIwMBDHjh2r8nMTET0pqdAFENHToyLhdv/+/fD396/GamxPXl4eli5ditjYWCQnJ8Pd3R1t27bF22+/jcaNG1t0jsmTJ2P37t3YvHkzmjVrVuo+BoMB3bt3R1ZWFg4fPgw7O7uqfBvV6tixYzh+/DheffVVODs7C12Ombt376J79+4YOXIk/vWvfwldDhFZEYZyIqoxs2fPNnl88uRJ/PLLL4iMjETbtm1NnnN3d3/i1/Pz88O5c+cgkUgqfY5///vf+Pzzz5+4lqrw8ccfY8eOHejXrx/at2+PlJQUHDhwAGfPnrU4lIeHh2P37t2IiYnBxx9/XOo+R48exb179xAZGVklgfzcuXMQi2vmi9njx49j0aJFGDx4sFkoHzhwIPr27QuZTFYjtRARVQRDORHVmIEDB5o81ul0+OWXX9C6dWuz5x6Vk5MDpVJZodcTiURQKBQVrrMkawlw+fn52LVrFzp37oyvv/7auH3ixIlQq9UWn6dz587w9fXFtm3b8MEHH0Aul5vts3HjRgCFAb4qPOl/g6oikUie6Bc0IqLqxJ5yIrI63bp1Q1RUFC5evIgxY8agbdu2GDBgAIDCcD5v3jwMGzYMHTp0QMuWLREaGoq5c+ciPz/f5Dyl9TiX3Hbw4EEMHToUQUFB6Ny5M/7zn/9Aq9WanKO0nvLibdnZ2fj000/RsWNHBAUFYfjw4Th79qzZ+0lPT8eMGTPQoUMHhISEYNSoUbh48SKioqLQrVs3iz4TkUgEkUhU6i8JpQXrsojFYgwePBgZGRk4cOCA2fM5OTnYs2cPAgIC0KpVqwp93mUpradcr9fjv//9L7p164agoCD069cPW7duLfX4+Ph4fPbZZ+jbty9CQkIQHByMIUOGYMOGDSb7TZ8+HYsWLQIAdO/eHYGBgSb//cvqKU9LS8Pnn3+OLl26oGXLlujSpQs+//xzpKenm+xXfPyff/6JFStWoEePHmjZsiV69eqFTZs2WfRZVMSlS5cwYcIEdOjQAUFBQejTpw+WLVsGnU5nsl9CQgJmzJiBrl27omXLlujYsSOGDx9uUpNer8fKlSvRv39/hISEoE2bNujVqxc+/PBDaDSaKq+diCqOM+VEZJXu37+PV199FWFhYejZsyfy8vIAAElJSYiOjkbPnj3Rr18/SKVSHD9+HMuXL0dcXBxWrFhh0fl//fVXrFmzBsOHD8fQoUOxf/9+/O9//4OLiwvGjRtn0TnGjBkDd3d3TJgwARkZGfjhhx8wduxY7N+/3zirr1ar8frrryMuLg5DhgxBUFAQLl++jNdffx0uLi4Wfx52dnYYNGgQYmJisH37dvTr18/iYx81ZMgQLFmyBBs3bkRYWJjJczt27EBBQQGGDh0KoOo+70d9+eWX+Omnn9CuXTu89tprSE1NxRdffIG6deua7Xv8+HGcOHECL7/8Mvz9/Y3fGnz88cdIS0vDW2+9BQCIjIxETk4O9u7dixkzZsDNzQ1A+dcyZGdn4x//+Adu3bqFoUOHonnz5oiLi8PatWtx9OhRbNiwwewbmnnz5qGgoACRkZGQy+VYu3Ytpk+fjnr16pm1YVXW+fPnERUVBalUipEjR6JOnTo4ePAg5s6di0uXLhm/LdFqtXj99deRlJSEESNGoEGDBsjJycHly5dx4sQJDB48GACwZMkSLFiwAF27dsXw4cMhkUhw9+5dHDhwAGq12mq+ESJ6qhmIiAQSExNjCAgIMMTExJhs79q1qyEgIMCwfv16s2NUKpVBrVabbZ83b54hICDAcPbsWeO2O3fuGAICAgwLFiww2xYcHGy4c+eOcbterzf07dvX0KlTJ5PzTps2zRAQEFDqtk8//dRke2xsrCEgIMCwdu1a47aff/7ZEBAQYFi8eLHJvsXbu3btavZeSpOdnW148803DS1btjQ0b97csGPHDouOK8uoUaMMzZo1MyQlJZlsj4iIMLRo0cKQmppqMBie/PM2GAyGgIAAw7Rp04yP4+PjDYGBgYZRo0YZtFqtcfuFCxcMgYGBhoCAAJP/Nrm5uWavr9PpDK+88oqhTZs2JvUtWLDA7PhixT9vR48eNW775ptvDAEBAYaff/7ZZN/i/z7z5s0zO37gwIEGlUpl3J6YmGho0aKFYcqUKWav+ajiz+jzzz8vd7/IyEhDs2bNDHFxccZter3eMHnyZENAQIDhyJEjBoPBYIiLizMEBAQYvv/++3LPN2jQIEPv3r0fWx8RCYftK0RklVxdXTFkyBCz7XK53Dirp9VqkZmZibS0NLzwwgsAUGr7SGm6d+9usrqLSCRChw4dkJKSgtzcXIvO8dprr5k8fv755wEAt27dMm47ePAgJBIJRo0aZbLvsGHD4OTkZNHr6PV6vPPOO7h06RJ27tyJl156Ce+99x62bdtmst8nn3yCFi1aWNRjHh4eDp1Oh82bNxu3xcfH48yZM+jWrZvxQtuq+rxL2r9/PwwGA15//XWTHu8WLVqgU6dOZvs7ODgY/65SqZCeno6MjAx06tQJOTk5uH79eoVrKLZ37164u7sjMjLSZHtkZCTc3d2xb98+s2NGjBhh0jLk7e2Nhg0b4ubNm5Wuo6TU1FScPn0a3bp1Q9OmTY3bRSIRxo8fb6wbgPFn6NixY0hNTS3znEqlEklJSThx4kSV1EhEVY/tK0RklerWrVvmRXmrV6/GunXrcO3aNej1epPnMjMzLT7/o1xdXQEAGRkZcHR0rPA5itslMjIyjNvu3r0LLy8vs/PJ5XL4+/sjKyvrsa+zf/9+HD58GHPmzIG/vz++/fZbTJw4ER988AG0Wq2xReHy5csICgqyqMe8Z8+ecHZ2xsaNGzF27FgAQExMDAAYW1eKVcXnXdKdO3cAAI0aNTJ7rnHjxjh8+LDJttzcXCxatAg7d+5EQkKC2TGWfIZluXv3Llq2bAmp1PSfQ6lUigYNGuDixYtmx5T1s3Pv3r1K1/FoTQDQpEkTs+caNWoEsVhs/Az9/Pwwbtw4fP/99+jcuTOaNWuG559/HmFhYWjVqpXxuKlTp2LChAkYOXIkvLy80L59e7z88svo1atXha5JIKLqw1BORFbJ3t6+1O0//PADvvrqK3Tu3BmjRo2Cl5cXZDIZkpKSMH36dBgMBovOX94qHE96DkuPt1TxhYnt2rUDUBjoFy1ahPHjx2PGjBnQarVo2rQpzp49i5kzZ1p0ToVCgX79+mHNmjU4deoUgoODsXXrVvj4+ODFF1807ldVn/eT+Oc//4lDhw4hIiIC7dq1g6urKyQSCX799VesXLnS7BeF6lZTyztaasqUKQgPD8ehQ4dw4sQJREdHY8WKFXjjjTfw/vvvAwBCQkKwd+9eHD58GMeOHcOxY8ewfft2LFmyBGvWrDH+QkpEwmEoJyKbsmXLFvj5+WHZsmUm4ei3334TsKqy+fn54c8//0Rubq7JbLlGo8Hdu3ctusFN8fu8d+8efH19ARQG88WLF2PcuHH45JNP4Ofnh4CAAAwaNMji2sLDw7FmzRps3LgRmZmZSElJwbhx40w+1+r4vItnmq9fv4569eqZPBcfH2/yOCsrC4cOHcLAgQPxxRdfmDx35MgRs3OLRKIK13Ljxg1otVqT2XKtVoubN2+WOite3Yrbqq5du2b23PXr16HX683qqlu3LqKiohAVFQWVSoUxY8Zg+fLlGD16NDw8PAAAjo6O6NWrF3r16gWg8BuQL774AtHR0XjjjTeq+V0R0eNY16/7RESPIRaLIRKJTGZotVotli1bJmBVZevWrRt0Oh1++uknk+3r169Hdna2Refo0qULgMJVP0r2iysUCnzzzTdwdnbG3bt30atXL7M2jPK0aNECzZo1Q2xsLFavXg2RSGS2Nnl1fN7dunWDSCTCDz/8YLK8399//20WtIt/EXh0Rj45OdlsSUTgYf+5pW01PXr0QFpamtm51q9fj7S0NPTo0cOi81QlDw8PhISE4ODBg7hy5Ypxu8FgwPfffw8ACA0NBVC4esyjSxoqFApja1Dx55CWlmb2Oi1atDDZh4iExZlyIrIpYWFh+Prrr/Hmm28iNDQUOTk52L59e4XCaE0aNmwY1q1bh/nz5+P27dvGJRF37dqF+vXrm62LXppOnTohPDwc0dHR6Nu3LwYOHAgfHx/cuXMHW7ZsAVAYsL777js0btwYvXv3tri+8PBw/Pvf/8bvv/+O9u3bm83AVsfn3bhxY4wcORI///wzXn31VfTs2ROpqalYvXo1mjZtatLHrVQq0alTJ2zduhV2dnYICgrCvXv38Msvv8Df39+kfx8AgoODAQBz585F//79oVAo8OyzzyIgIKDUWt544w3s2rULX3zxBS5evIhmzZohLi4O0dHRaNiwYbXNIF+4cAGLFy822y6VSjF27Fh89NFHiIqKwsiRIzFixAh4enri4MGDOHz4MPr164eOHTsCKGxt+uSTT9CzZ080bNgQjo6OuHDhAqKjoxEcHGwM53369EHr1q3RqlUreHl5ISUlBevXr4dMJkPfvn2r5T0SUcVY579iRERlGDNmDAwGA6KjozFz5kx4enqid+/eGDp0KPr06SN0eWbkcjl+/PFHzJ49G/v378fOnTvRqlUrrFy5Eh999BEKCgosOs/MmTPRvn17rFu3DitWrIBGo4Gfnx/CwsIwevRoyOVyREZG4v3334eTkxM6d+5s0Xn79++P2bNnQ6VSmV3gCVTf5/3RRx+hTp06WL9+PWbPno0GDRrgX//6F27dumV2ceWcOXPw9ddf48CBA9i0aRMaNGiAKVOmQCqVYsaMGSb7tm3bFu+99x7WrVuHTz75BFqtFhMnTiwzlDs5OWHt2rVYsGABDhw4gI0bN8LDwwPDhw/HpEmTKnwXWUudPXu21JVr5HI5xo4di6CgIKxbtw4LFizA2rVrkZeXh7p16+K9997D6NGjjfsHBgYiNDQUx48fx7Zt26DX6+Hr64u33nrLZL/Ro0fj119/xapVq5CdnQ0PDw8EBwfjrbfeMlnhhYiEIzLUxFU6RERkQqfT4fnnn0erVq0qfQMeIiKqPdhTTkRUzUqbDV+3bh2ysrJKXZebiIiePmxfISKqZh9//DHUajVCQkIgl8tx+vRpbN++HfXr10dERITQ5RERkRVg+woRUTXbvHkzVq9ejZs3byIvLw8eHh7o0qUL3nnnHdSpU0fo8oiIyAowlBMRERERCYw95UREREREAmMoJyIiIiISGC/0LJKengu9vmY7eTw8lEhNzanR1ySyRRwrRJbhWCGyjFBjRSwWwc3NsdTnGMqL6PWGGg/lxa9LRI/HsUJkGY4VIstY21hh+woRERERkcAYyomIiIiIBMZQTkREREQkMIZyIiIiIiKBMZQTEREREQmMq68QERERlSM/Pxc5OZnQ6TRCl0JVJDlZDL1eX2Xnk0hkUCpdYG9f+nKHlmAoJyIiIiqDRqNGdnY6XF3rQCZTQCQSCV0SVQGpVAyttmpCucFggEajQkbGA0ilMshk8kqdh+0rRERERGXIzs6AUukCudyOgZxKJRKJIJfbwdHRBTk5GZU+D0M5ERERURm0WjUUCnuhyyAbYGdnD41GXenj2b4igD//TsTGX+ORlqWCu7MCQ7o0RscWPkKXRURERI/Q63UQiyVCl0E2QCyWQK/XVfp4hvIa9uffifhx5yWoi/qYUrNU+HHnJQBgMCciIrJCbFshSzzpzwnbV2rYxl/jjYG8mFqrx8Zf4wWqiIiIiIiExlBew1KzVBXaTkRERGRrJk4ci4kTx9b4sbaM7Ss1zMNZUWoAd3KQCVANERERPU06d37Oov02bNgKX99nqrkaKomhvIYN6dLYpKccAEQAcvI0+ON8AjoF+QpXHBEREdVqn3zyhcnj9evXIikpAZMmTTXZ7urq9kSvM2/ed4Ica8sYymtY8cWcJVdf6fdCA/x1KRkrdsQhPVuFvh3r86ISIiIiqnK9evUxeXzo0H5kZmaYbX9UQUEB7OzsLH4dmazyHQBPcqwtYygXQMcWPujYwgeenk5ISckGAHQK8sX/YuOw8bfrSM9RYWSPAIjFDOZERERUsyZOHIucnBx88MGHWLhwHi5fvoSRI0dhzJi38Pvvh7B16yZcuXIZWVmZ8PT0Qp8+/REV9TokEonJOQBg0aLvAQCnTp3A5MnjMHPmbNy4cR2bN8cgKysTQUHBeP/9D+HvX7dKjgWAmJj1WLduNVJTH6Bx48aYOHEKli1bYnJOa8RQbiWkEjHe6NccrkoFdh27jcwcNcb2bw65jGujEhER1SbF9ytJzVLBw0rvV5KRkY4PPpiCnj3DEBbWF97ehfXFxm6Hvb0DIiNHwsHBHidPnsDy5UuRm5uLCRPeeex5f/xxBcRiCUaMGIXs7CysXbsKn3/+MZYt+7FKjt20KRrz5s1G69ZtEBn5DyQkJGDGjPfg5OQET0+vyn8gNYCh3IqIRSJEdG0CN6UC6/ZfxdxfzmDy0FZQ2j+dX+MQERHVNrZyv5IHD1Iwffon6NdvoMn2zz77PygUD9tYBg0Kx5w5s7Bp0wa8+eZ4yOXycs+r1Wrxv//9CKm0MII6O7vg22/n4vr1a2jUqMkTHavRaLB8+RK0aBGE+fMXG/dr0uRZzJz5GUM5VVxou7pwUcqxfPtFfPnzSUyNaA0PF8v7uIiIiKj6/HE+AYfPJVTq2Pj7mdDqDCbb1Fo9foiNw29n7lfoXJ1b+VbbAhF2dnYIC+trtr1kIM/Ly4VarUFwcAi2bNmIW7du4tlnA8o9b9++A4xhGQCCg1sDAO7fv/fYUP64Yy9duojMzEy8/fZgk/1CQ8OwYME35Z7bGjCUW6n2zbzh7CDHwo3nMXPVCUyNaA1/L6XQZREREdETeDSQP267UDw9vUyCbbHr1+OxbNkSnDr1F3Jzc02ey83Neex5i9tgijk5OQMAsrOzn/jYxMTCX5Qe7TGXSqXw9bX+1e0Yyq1Y0/pumDGyDeZtOIsvV5/EpCGt0LT+ky1RRERERE+mU1DlZ6jfX/xHqfcr8XBWYNrINk9aWpUpOSNeLDs7G5MmjYWDgxJjxoyDn58/5HI5rly5hCVLFkKv15dyJlNicenXyhkMj/+l5EmOtQW8o6eV8/dS4qOotnBzssM368/geFyS0CURERFRJQ3p0hhyqWn8kkvFGNKlsUAVWe706ZPIzMzERx99ioiIf6BTpxfRrl0H44y10Hx8Cn9Runv3jsl2rVaLhITKtRvVJIZyG+DubIfpI9ugoa8zlm75G3v+uvP4g4iIiMjqdGzhg1d7N4WHswJA4Qz5q72bWtVFnmURiwtjY8mZaY1Gg02bNghVkommTZvDxcUFW7duglarNW7fu3cXsrOzBKzMMmxfsRFKexneG94a32+9iHX7ryIjW4Xwro0h5k2GiIiIbErx/UpsTVBQKzg5OWPmzM8QHh4JkUiE3btjYS3dIzKZDKNHj8W8eXPw7rtvo2vX7khISMDOndvg5+dv9TdmFHSmPDk5GXPnzkVUVBRCQkIQGBiIY8eOPfY4vV6PmJgYjBs3Dl26dEHr1q3Rr18/LF26FGq1ugYqF4ZMKsH4QS3RrY0fdh2/jeXbLkKre3z/FhEREdGTcnFxxezZ8+DhUQfLli3B2rU/47nnOuDttycLXZrR0KGRePfd95CYmIDvvvsWZ8+exldffQOl0glyuULo8solMgjYHX/s2DGMGjUK9evXh7u7O06fPo2ffvoJHTp0KPe43NxctGnTBq1bt8bLL78MDw8PnD59Gps3b0aHDh2wcuXKCteSmpoDvb5mP4qSd/SsCIPBgNijtxDz63U0q++GiUOCYK/glx5Ue1V2rBA9bThWql5i4i34+NQXugx6Anq9Hv36haJLl66YNu1jAIBUKoZWW/UTm4/7eRGLRfDwKH01PUGTXIsWLXD06FG4ublh3759mDBhgkXHyWQyrF27Fm3aPLxKOSIiAn5+fli4cCGOHTv22GBvy0QiEfp2bABXpQIrd17CV6tPYUpEMFyV1v0bIBEREVF1UqlUUChM89CuXTuQlZWJkJC2AlVlGUHbV5RKJdzcKr7En1wuNwnkxUJDQwEA8fHxT1ybLegU5It3wlshOT0fM386iYTU3McfRERERFRLnTt3BqNHv4KffvofNm+OwezZM/Gf//wfGjVqjK5dewhdXrlq1eorDx48AIBKBX1b1bKRB6aNDIFGq8OsVSdx7V6m0CURERERCeKZZ/xQp44noqN/wfz5c3D48G8IC+uLb79dAplMJnR55apVjcjLly+Hk5MTOnfuLHQpNaqBjzM+HPUcvvnlDOasPY1xA1sg5FlPocsiIiIiqlF+fv6YPXue0GVUSq0J5UuXLsWRI0fwxRdfwMnJqcLHl9V0X908PStea1nn+ebdLvh8+VF8t/E8xg8NRljHBlVybiJrUFVjhai241ipWsnJYkiltaqxgIpUx39XsVhc6TFYK0J5bGws5s+fj8jISERGRlbqHLa0+kp5pg4LxpItF/Bd9FncScjEwM4NrX5dTqLH4YoSRJbhWKl6er2+WlbpIGFV1+orer2+3DFY3uorNv+r3x9//IEPPvgAXbt2xaeffip0OYJTyCWYNDQInVv5YusfN7Fy5yXo9Pw/EyIiIiJrZtMz5WfPnsXEiRMRFBSEefPmQSKRCF2SVZCIxXi9d1O4KRXYduQmMnPVGD+wJRRyfj5ERERE1sgmZspv376N27dvm2yLj4/H2LFj4efnh6VLl8LOzk6g6qyTSCTC4JcaYVSvQJy/norZa08jK6/23u2UiIiIyJYJPlO+ePFiAA/XFt+yZQtOnjwJZ2dnvPLKKwCA1157DQBw4MABAEBOTg7GjBmDrKwsjBkzBocOHTI5Z2BgIJo2bVozb8DKvRziBxdHOZZu/RtfrjqJKZGt4eVqL3RZRERERFSC4KH822+/NXkcExMDAPDz8zOG8kdlZGQgISEBAPD111+bPT9x4kSG8hJCAjzx/vAQfBt9FrN+OoF3I4LRwMdZ6LKIiIiIqIjIYDDU7JIjVqq2rL5SnoTUXHzzy1nkFGgwYXBLtGzoUWOvTfQkuKIEkWU4VqpeYuIt+PjUF7oMqxYbuw2zZn2ODRu2wtf3GQBAeHh/hIS0xUcffVbhY5/UqVMnMHnyOCxYsBRt2jxX6j7VtfrK435eavXqK2Q5Xw9HfBjVFl6u9vh2wzn8cT5B6JKIiIiohn3wwRT06NEZ+fn5Ze4zdepE9OrVBSqVqgYrq5h9+3Zj/fo1QpdRZRjKnzJuTgpMG9EGAXVdsWJHHHb8eRP8soSIiOjpERraCwUFBTh8+NdSn09PT8PJk3/hpZe6QqFQVOo11qyJwbRpHz9JmY+1f/8erF+/1mx769ZtsH//H2jduk21vn5VYyh/CjnYSTElIhgdmnsj5tfrWLP3ao237hAREZEwXnzxZdjbO2Dfvt2lPn/gwD7odDr07BlW6deQy+WQSoW5dFEsFkOhUEAstq2YK/iFniQMqUSMN/s3h6tSjt3H7yAjV4Wx/ZtDJuVa5kRERLWZnZ0dXnyxCw4e3IesrCw4O5su/rBv3254eHigbt36mDv3K5w8eRxJSUmws7NDmzbPYcKEdx7b/11aT/n16/GYP38OLlw4DxcXFwwcOAR16niaHfv774ewdesmXLlyGVlZmfD09EKfPv0RFfW68Z40EyeOxZkzpwAAnTsX9o37+PgiOnpbmT3l+/fvwc8/r8StWzfh6OiIF154EePHT4arq6txn4kTxyInJwf/+tcX+Oab2YiL+xtOTs4YNmw4Ro58tWIfdAUxlD/FxCIRIrs9CzelAusOXMPXuWcwKbwVHO1kQpdGRERUax1PPIWt8buQrsqAm8IVAxqHob1PzbZahIaGYc+enTh0aD8GDBhs3J6YmIALF84hPHw44uL+xoUL59CjRy94enohIeE+Nm+OwaRJb+HnnzdU6B4xqakPMHnyOOj1erzyyquws7PH1q2bSm2PiY3dDnt7B0RGjoSDgz1OnjyB5cuXIjc3FxMmvAMAePXV0cjPz0dSUgImTZoKALC3dyjz9YsvKG3RIgjjx0/GgwdJ2LDhF8TF/Y1ly34yqSMrKxP//OdkdO3aHd2798TBg/uwZMlCNGrUBB07drL4PVcUQzmhZ/t6cHVSYPn2i/jy51OYGhEMd2fejImIiKiqHU88hTWXYqDRawAA6aoMrLlUuBx0TQbzdu06wNXVDfv27TYJ5fv27YbBYEBoaC80btwEXbv2MDmuU6eXMG7c6zh0aD/Cwvpa/HqrV/+IzMwMLF++CoGBhctW9+7dD//4x2CzfT/77P+gUDzMIYMGhWPOnFnYtGkD3nxzPORyOdq1ex4bN25AZmYGevXqU+5ra7VaLFmyEE2aBGDhwv8WtdaI8eyzTfHZZx9h27ZNCA8fbtw/OTkJn376fwgNLWzf6ddvIMLD+2HHji0M5VT92jfzhpODHIs2nsPMVScxJSIY/p6lL9lDRET0NDuWcBJ/JvxVqWNvZN6G1qA12abRa7A6LhpH7h+v0Lk6+rZDB9+2lapDKpWiW7ce2Lw5Bg8ePECdOnUAAPv27YG/f100b97SZH+tVovc3Bz4+9eFUumEK1cuVSiU//nnHwgKCjYGcgBwc/0oIQgAACAASURBVHNDaGhvbNq0wWTfkoE8Ly8XarUGwcEh2LJlI27duolnnw2o0Hu9dOki0tPTjIG+WLduofjuu29x5MgfJqFcqVSiR49exscymQzNmrXA/fv3KvS6FcVQTkbN6rth+si2mLf+DL78+RQmDw1CYD03ocsiIiKqNR4N5I/bXp1CQ8OwceMGHDiwBxERI3Dz5g1cu3YFr7/+JgBApSrAqlUrERu7DSkpySarteXk5FTotZKSEhEUFGy2vV498zW9r1+Px7JlS3Dq1F/Izc01eS43t2KvCxS25JT2WmKxGP7+dZGUZLpEtJeXN0Qikck2JydnxMdfq/BrVwRDOZmo66XER1HP4Zv1Z/D1L2fwZv8WaNfUS+iyiIiIrEYH37aVnqH++I9ZSFdlmG13U7ji3TbjnrS0CgkKCoavrx/27t2FiIgR2Lt3FwAY2zbmzZuD2NhtGDbsH2jZMghKpRKACJ999mG1LaecnZ2NSZPGwsFBiTFjxsHPzx9yuRxXrlzCkiULoddX/Q1/HiUWl77oRXUvIc1QTmY8XOww45W2WBBzDks3X0BGj2cR+lxdocsiIiKyeQMah5n0lAOATCzDgMaVX37wSfTo0ROrVv2Au3fvYP/+PQgMbGacUS7uG580aYpxf5VKVeFZcgDw9vbB3bt3zLbfvn3L5PHp0yeRmZmJmTPnmKwznpBwv5SzikrZZs7Hx9f4WiXPaTAYcPfuHTRs2Nii81Q321rAkWqM0l6G9yJbIyTAE2v3XcWGg9eg502GiIiInkh7nzYY0XQo3BSFy/C5KVwxounQGl99pVjPnr0BAIsWzcPdu3dM1iYvbcY4JuYX6HS6Cr9Ox46dcP78WVy+fMm4LT09HXv37jTZr3ht8ZKz0hqNxqzvHADs7e0t+gWhadPmcHNzx+bN0dBoHv4ydPDgfqSkJOOFF6rv4s2K4Ew5lUkuk+DtQS2xet8V7Dx2G+k5Kozu0wxSCX+XIyIiqqz2Pm0EC+GPatiwEZo0CcDhw79BLBaje/eHFzi+8EJn7N4dC0dHJRo0aIi//z6PEyeOw8XFpcKvM2LEq9i9OxZTp05AePhwKBR22Lp1E7y9fZGTc9W4X1BQKzg5OWPmzM8QHh4JkUiE3btjUdq8YGBgU+zZsxMLF36Dpk2bw97eAZ07v2S2n1QqxfjxkzBr1ueYNOkt9OjREykpydiwYR0aNWqM/v3NV4ARAkM5lUssFuGV0AC4KRXY+Nt1ZOWqMWFwEOwV/NEhIiKqDXr2DMO1a1cQEtLWuAoLALzzznsQi8XYu3cnVCo1goKCMX/+d5g6dVKFX6NOnTpYsOC/mDdvNlatWmly86Cvvvq3cT8XF1fMnj0PixbNx7JlS+Dk5IyePXvjuefaY+rUiSbnHDhwKK5cuYTY2O345Zc18PHxLTWUA0CfPv0hl8uxevWP+O67b+Ho6IjQ0DCMGzep1LXShSAyVHfXuo1ITc2p8VvNe3o6ISUlu0Zf80kcPpeAlTsvwd/LEVOGBcNFaR0/xFT72dpYIRIKx0rVS0y8BR8f8xVCyLZJpWJotVV/0ejjfl7EYhE8PEpfcpp9CGSxzq188c6wVkhKy8fMVSeRmJYndElEREREtQJDOVVIUCMPfDAiBCqNDrNWnUT8vUyhSyIiIiKyeQzlVGENfZ3xYVRbOCikmLP2NM5cfSB0SUREREQ2jaGcKsXbzQEfRrXFM3UcsXDjOfx2trT1Q4mIiIjIEgzlVGnOjnJ8MCIELRt6YOXOS9hy+Ea13+2KiIiIqDZiKKcnYieXYtLQIHQK8sGWwzfw465L0NXALXCJiIiIahMuNk1PTCoRY3SfZnBzUmD7kVvIzFFj3KCWUMjM7wRGREREROY4U05VQiQSYchLjRHVMwDnrqdiztrTyM5TC10WERHRE2NrJlniSX9OGMqpSnVt448Jg4NwJzkHs1adREpGvtAlERERVZpEIoVGw0kmejyNRg2JpPJNKAzlVOXaBHjiveGtkZOvwcxVJ3ErkXeXIyIi26RUuiIjIwVqtYoz5lQqg8EAtVqFjIwUKJWulT6PyMCfMABAamoO9Pqa/Shq++2Q7z/Ixbz1Z5BToMXEwUFo0dBd6JLIRtX2sUJUVThWqkd+fi5ycjKg02mFLoWqiFgshr4KF6aQSKRQKl1hb+/4mNcVwcNDWepzDOVFGMqrR3q2CvPWn0VCai5G92mGji19hC6JbNDTMFaIqgLHCpFlhBor5YVytq9QtXJzUmD6yDZ41t8Fy7ZfxM6jt/j1HxEREdEjGMqp2jnYSTElojXaN/PChkPxWLvvao1/K0FERERkzbhOOdUImVSMsQNawFWpwJ6/7iAjR4U3+zeHTMq1zImIiIgYyqnGiEUiDO/+LNycFPjlwDVk553FpKFBcLCTCV0aERERkaDYvkI1rlf7ehg7oDmu3cvElz+fQlpWgdAlEREREQmKoZwE8XxzH0yNCEZqVgFmrjqJeyk5QpdEREREJBiGchJMswbumD6yDfQGA778+RSu3MkQuiQiIiIiQTCUk6DqeTvho6i2cHaUY+66MzhxKVnokoiIiIhqHEM5Ca6Oiz0+jGqLBj5OWLL5AvafvCt0SUREREQ1iqGcrILSXob3hrdG62frYPXeK4g+FM+bDBEREdFTg6GcrIZcJsGEwUF4OcQPsUdvYfn2OGh1eqHLIiIiIqp2XKecrIpYLEJUzwC4KeXY9PsNZOWp8faglrBX8EeViIiIai/OlJPVEYlE6N+pIV7v3RRxN9Mxe81pZOaohC6LiIiIqNowlJPVejH4GUwOD0JCWi5mrjqJpLQ8oUsiIiIiqhYM5WTVWjWugw/+0QYFah1mrjqJ6/ezhC6JiIiIqMoxlJPVa/SMMz4a1Rb2Cglmrz2Fs9ceCF0SERERUZViKCeb4O3mgA+jnoOvhyMWxpzHb2fvC10SERERUZVhKCeb4eIox7QRIWjewA0rd17C1sM3uJY5ERER1QoM5WRT7ORSTA5vhRda+mDz4Rv4afdl6PRcy5yIiIhsGxd/JpsjlYgxpm8zuDkpsOPPW8jMUeOtgS2gkEmELo2IiIioUjhTTjZJJBJhaJfGGBkagLPXHmDuutPIydcIXRYRERFRpQgaypOTkzF37lxERUUhJCQEgYGBOHbsmMXHx8fHY8yYMQgJCUH79u0xbdo0pKWlVWPFZG26t/XH24Nb4lZiDmatOokHGflCl0RERERUYYKG8hs3bmDZsmVISkpCYGBghY5NTEzEyJEjcefOHUyZMgWjR4/GwYMHMWbMGGg0nDF9mrQN9MJ7w1sjK1eNmatO4nZSttAlEREREVWIoKG8RYsWOHr0KPbs2YM33nijQscuXboUKpUKq1atwqhRozBu3DjMnz8fFy9exJYtW6qpYrJWAXVdMSOqLSQSEb5afQoXb/IbEyIiIrIdgoZypVIJNze3Sh27Z88edOvWDd7e3sZtL7zwAho0aICdO3dWVYlkQ/zqOOLDV9rCw8UO89afxdG/E4UuiYiIiMgiNnmhZ1JSElJTU9GyZUuz51q1aoW4uDgBqiJr4O5shxkj2+BZfxd8v+0idh27zbXMiYiIyOrZZChPTk4GAHh6epo95+npidTUVOh0upoui6yEg50MUyJao11TL6w/eA3r9l+DnsGciIiIrJhNrlOuUqkAAHK53Ow5hUIBACgoKICjo6PF5/TwUFZNcRXk6ekkyOs+DT4e8zxWbL2Arb9fR75Gh6kj2kAm5VrmtopjhcgyHCtElrG2sWKTobw4eKvVarPnigO7nZ1dhc6ZmpoDvb5mZ1M9PZ2QksKVQqrTwBfqw04qxvqD1/AgPQ8ThwTBwU4mdFlUQRwrRJbhWCGyjFBjRSwWlTkRbJPtK15eXgCAlJQUs+dSUlLg4eEBiYQzolR4k6GwDvXwZv/muHo3E1+tPoX0bJXQZRERERGZsMlQ7u3tDXd3d1y4cMHsuXPnzqFZs2YCVEXWrGMLH7wbEYwHmQWYueoE7j3IFbokIiIiIiObCOW3b9/G7du3Tbb17NkTBw4cQFJSknHbn3/+iZs3byIsLKymSyQb0KKBO6aPbAOdzoAvV53ElTsZQpdEREREBAAQGQReL27x4sUAgPj4eGzfvh1Dhw6Fv78/nJ2d8corrwAAunXrBgA4cOCA8biEhAQMGjQIrq6ueOWVV5CXl4cVK1bA19cXGzZsKPUi0PKwp/zp8SAjH9+sP4sHmQV4a0BztA30ErokegyOFSLLcKwQWcYae8oFD+WBgYGlbvfz8zOG8NJCOQBcvXoVX331FU6ePAmZTIaXX34ZM2bMgLu7e4XrYCh/umTnqbEg+hyu38/CyJ4B6NbGX+iSqBwcK0SW4VghsgxDuRVjKH/6qDQ6/HfL3zhz7QH6dqyPIS81gkgkErosKgXHCpFlOFaILGONodwmesqJqoNCJsGEIS3xUvAz2PHnLfxvRxy0Or3QZREREdFTyCbXKSeqKhKxGK+GBcLdWYHNv99AZq4abw9uCTs5hwYRERHVHM6U01NPJBJhQKeGeK13U1y8mY7/rDmNzFzzG1MRERERVReGcqIiLwU/g4lDg5DwIBezVp1AUnqe0CURERHRU4KhnKiE1k3q4P0RIchX6TBr1Ulcv58ldElERET0FGAoJ3pE42dc8GFUWyhkEsxeewrn4h8IXRIRERHVcgzlRKXwcXfAR1Ft4evuiAXR5/H7uftCl0RERES1GEM5URlclAp8MCIEzRq44YfYS9j2xw1wWX8iIiKqDgzlROWwV0jxTngrdGzhg02/38CqPVdq/CZTREREVPtxMWYBHE88ha3xu5ChyoCrwhUDGoehvU8bocuiMkglYrzRrxncnBSIPXoLmTkqvDWgBeQyidClERERUS3BmfIadjzxFNZcikG6KgMGAOmqDKy5FIPjiaeELo3KIRKJEP5yY4wMDcCZqw8wd90Z5ORrhC6LiIiIagmG8hq2NX4XNHrTMKfRa7Alfif7lW1A97b+GD+oJW4mZuPLn0/iQWa+0CURERFRLcD2lRqWrsoodXuGKhPv//4pvB284OPgBR/Hwv95O3ihjr07xCL+/mQtnmvqBScHGRbGnMfMVScxZVgw6nk7CV0WERER2TCG8hrmpnAtNZg7SO3xnHdrJOYm42LaZRxNPGF8TiqWwsu+TmFQd3gY1r0cPCGXyGqyfCoSWM8NM15pg2/Wn8VXq09h0pAgNGvgLnRZREREZKNEBvZMAABSU3NqZFWN4p7yki0sMrEMI5oONbnYM0+Tj8S8ZCTmJiOp6M/EvGSk5qfBgMI6RRDBw86tMKQ7esHHwdsY3B1k9tX+XghIyyrAvPVnkZiWhzf6NUeH5t5Cl1QreXo6ISUlW+gyiKwexwqRZYQaK2KxCB4eylKfYygvUlOhHHiy1Vc0Og2S8x8gMTfJGNQTc5ORnP8AWr3WuJ+z3AneDp7wcfQ2aYdxkTtDJBJV11t7KuUVaLAg5jyu3MlAZLcm6NW+ntAl1ToMGkSW4VghsgxDuRWryVBerCp/IPQGPVLz05GY9zCsJxX9ma8tMO5nJ7GDt6Pnw6DuUDjLXsfOHRIxl/irLI1Wh2XbLuLE5RT0bFcXEd2aQMxffqoMgwaRZThWiMon9LLUDOUWsPVQXhaDwYAsdfbDoF7cCpObjEx1lnE/qUgCT4c6j4R1b3izb91ier0Ba/dfxf6Td9G+mRfG9G0OmZQX6FYFBg0iy3CsEJXN0hbi6lReKOeFnrWcSCSCi8IZLgpnBLo3MXkuX5uPxNyUErPqSbibcx9nUi6Y9K2727k9Mrte2LvuKHMQ4i1ZLbFYhBE9noW7swIbDsYjK1eNiUNawcGOw4yIiEhIGr0WW+JjS12Wemv8Lqu4iSPTwlPMXmqPhi710NDFtAdao9ciJe9BUb/6w3aYq+nx0JToW3eSKUtcZPpwht1V4fLU9q2LRCL07lAfro4K/C82Dl+tPoUpEcFwc1IIXRoREZHNMxgMKNCpkKvJQ64mt+jPPOSU+LtxuzYPOepc5GrzoNapyzxnWctV1zSGcjIjE0vxjNIHzyh9TLbrDXqkFaSb9ayfSjqLPO3Dm+goJPLC9dYfCet17D2emr71ji194Owox6JN5zFr1QlMiWiNZ+o4Cl0WERGR1dAb9CWC9MMwbRKwtabhO1eTB51BV+Y5HaT2cJQ5wFHmCGe5E55x9Cl67ID9t38zySvF3BSu1fk2Lcae8iK1tae8JhgMBmRrcoy96iUDe4Yq07ifpGTfuoNn4Qx70ZrrColcwHdQfW4lZmPehrPQ6fSYHN4Kz/pbx8C3NbVlrBBVN44VEopapzENz0VhOkedh1xtrln4ztHkIb+UgFxMIpIYw3RxyFYW/ekoc4Cj1Hy7g8y+3JstWntPOUN5EYby6pGvLUByXorJ8o2JeUl4kJ8GvUFv3M/dzs1sRRgfRy8oZbY/u5yckY95v5xBWrYKbw1ogTYBnkKXZHOehrFCVBU4VuhJGQwG5GsLioK1aZh+OINtvv3RXu2SFBK5WZhWyh2L/u5oEr6VRY8VEkW1tMJy9RUbwFBes0r2rSeZzK6nmAxspczxYStMiXYYN4WrTfWtZ+ep8W30OdxIyMIrPQPRNcRP6JJsytM8VogqgmOFStLpdUUz1uW0hzwasrV5JpNmJYkggoOsqD1E6mgSokvOaJcM2A4yB8jE1tctbY3rlFvfp0RPhfL61tMLMh7OqhcF9jPJ55GrzTPuJ5fIC1tgHLzhU2JlGE/7OlbZt+7kIMf7w0OwdMsFrNp9GenZBRj8YiOb+sWCiIiEYTAYoNY/0h5SZsAuek6bZ3KfkkdJxdISLSAO8HH0Nm0PKaVtxF5qV257CD0ZhnKyKmKRGB727vCwd0cLj6bG7QaDATmaXLOe9WsZ1/FX0imT4z3t65hdZOrl4Ak7qbAroCjkEkwcGoRVuy9j+5FbyMhWY1RYIKQS/h8cEdHTQm/QF7WHlN5nbd6XXbit5Opnj7KT2JkEaU8HjxIz2KW1hzhCLpZxYsjKMJSTTRCJRHCSK+EkV+JZt0YmzxVoVQ9vipSXjKSiHvbzDy6afAXnpnA17VkvCu1O8tK/RqoOErEYr4Y1hZuTHbYcvoHMXDXGD2oBOzmHIhGRrdHqtaW3gJScwTa7yDHPeC+QR4lF4qLVQwqDtLudG+o5+Zu3hzzSl22N3xBTxTEJkM2zkypQ37ku6jvXNdmu1WvxID/1kYtMk/HH/WNQl+hbd5Q5GAN6yaUc3excq+VrOpFIhIGdG8JVKcdPuy9j9prTeHdYMJwda+cKNERE1s5gMEBlXPu6xMy1trTA/fDvBTpVmeeUiWUmQfoZpa9p/7XUtAdbKXOEnVTB9pCnGC/0LMILPZ8ehX3rmYWz6yV615PykpGjyTXuJxfL4F28dGPRXUwL+9Y9IK2ii1bOXH2ApVsuwFWpwNTIYHi58S6ppeFYIbIMx0rh/8fnafKNfdWFs9Ylw3TpFzlqy1n72t649nVxoHaEUv7wYkfz/msHyGvpUr+1hTVe6MlQXoShnAAgR5378E6mecVhPQVpBenGfcQiMerYuz8M6sZZdk/YSe0q/Jrx9zLxbfQ5iETAu8OC0dDXuSrfUq3AsUJkmdo2VjQ6jUlfdU6pK4aYhuw8bX657SElW0CUModH+q5LrhxStPa11J7tIbUQQ7kVYyin8qh0amPfelKJdpjk/AcmfeuuChfzVhhHLzjJlOVeUJOQmot5688iO0+Dtwe3RFAjj5p4WzaDY4XIMtY6Vh7eGj23lJlr85CdU3SRY3m3RpdL5CWCdekXNZacuXaUOcKumta+JtvDUG7FGMqpMnR6HVLyU00uNC1uhVGV+MfEQWpfykWm3nAv0beekaPC/PVnce9BLl7r3RSdgnyFeltWh2OFyDI1MVZ0eh3ytPnlzFybBuvi7eWuff1oe0g5M9fF/dgyiaxa3yfVbgzlVoyhnKqSwWBAhiqzRFBPKlrKMQXZmhzjfjKxFF4OD9dZd5fXwYEjGbh2XYchLzZB3471OasDjhWix6nsXQqLb41e6sy1tvRbpJd3a3Sp8dboZd1QpsTMtdQBjvLC9hBe3Eg1jaHcijGUU03J0eQiKTcFiXlJJuuupxVkPOyDNIigV9nDQ14Hbes3gq/yYTuMfSX61m0dxwpR2Y4nnMSayxtN7oYsFUnwvG87eDt6lnuL9PJujW4nUZQ/c212i3RHKCRyTiSQTWAot2IM5SQ0tU6NpLwUJOUmIyE3GSdvXUdSXgrE9nmA6OHXvi5yZ2Ov+sP+dW84y8vvW7dlHCtUm+gNeqh1ahToVFDp1FBpVVDpVKU+Nt1WfIzK5HF5M9dAYXuI6ax10aohcgcoS1k9pPjvVbXKFJE1ssZQzhFHZCXkEjnqOvmhrpMfAKB/Y2DviTtYt+8y6tWXIuwlN2Rq0grbYfKScSzhpMkaufZS+6Kedc8SdzP1hoe9G78aJnoCWr22MAAXhWWVrkRALidQFx+jLvlYpyr34sVHycQyKCRy2EkUUEgVUEgUcJQ6wF3hanz8690/yjx+9ouf8dboRDaCoZzIioU+VxcujnIs334RW2PzMTWiIzwaFLavGAwGZKqzjOusF/eu/516CUcTThjPUbJvveSdTL3s6/BCKap1DAYD1HpNYTAumk0u/HuB8e8VDdjlrV9dkggiKCQK2EkVUEjkUEgK/3S1cyn6u8IsYNsVb5MqTPeRKiAXyy1aiu9cyt9IV2WYbXdTuMJRxnsfENkKtq8UYfsKWbPLt9OxIOY8FDIxpkS0Rl2v0r/6KpanySsK6YW960lFwT21IN3Yty6CCB727iVm1R8u4Wgvta+Jt2UxjpXaS6fXlQjLRYFYW6JNo5QQXTJslzymeN+y1qh+lFQsfRiSHwnExY9NA3YpjyUKKKSF55CJZYK0kB1PPIU1l2JM+sNlYhlGNB1q0cWeRE8ja2xfYSgvwlBO1u5ucg7mbTiLArUWE4e0QrP6bhU+h1qnQXJeysM7mRZdZJqcl2IyG+gidzJeWFpydt1F7ixI6OBYsQ4GgwEavbbUsFx6+8bjA7ZGr7X49YvDcPHsskKqMA3UUssCdvE+temGMJVdfYXoacVQbsUYyskWpGUV4Jv1Z5Gcnoc3+jVH+2beVXJevUGPB/lpD9dbL7HmeoGuwLifvdSuMKyXmFX3dvBEHXuPau1Z5VipHL1B/3BGuZQLBUv2OZvvU0rA1qnLXGv6UWKR+GFAlpZo05AoIDcLyPJH2jnMA7ZcImNftAU4Vogsw1BuxRjKyVbkFmiwMPocrtzNxPDuz6Jnu7rV9lomfetF66wX/pmETPXDn12pSAIvB0+TWXUfBy94OXhCXgV960/LWNHqtSatGKWHZfPHZR2jLme5u0fJxTJjgDZp6XjksZ0F+yikCkhFklq7GpA1e1rGCtGTssZQzgs9iWyMo50M/xzeGt9vu4h1+68iPbsAw7o2gbgaApBIJIKrwgWuChc0dX/W5Lk8Tb7ZnUzvZN/DmeTzpn3rdm5FM+peJks5Otj4BWgGg6FoFloNla6gnIsHH+19fiRQa1XG5fF0Fbig0OzCQIkCbkUXFJYZqEvtjy7cxlloIiJhMZQT2SCZVILxA1tizb4r2H38DjJz1BjdtxmkkpoLVg4yezR0qY+GLvVNtmt0GiTnPzDpWU/MS8al9GvQlugfdpIri2bVvU3aYUr2rVdln2zhBYXmgdjkgkFtiUBdWsAuEaorekGhsU2jKAzbS+3gqnApfeWNx6zOIRNLOQtNRFTLMJQT2SixWISRoQFwc1Ig5tfryMxVY+KQINgrhB3WMokMfkpf+Cl9TbbrDXqk5qcb72SalJeCxNxknEg6Y3LzEzuJAt4OXpCKJLiZfRu6oh7mdFUGVsdtwM2sO6irfOZh33O5AfthS4fWwgsKC5e1k5v1ObvInaCQ1HnsjLPdI2G6tl1QSERE1aNKesq1Wi3279+PzMxMdO3aFZ6enlVRW41iTznZsj/OJ2Dlzkt4po4jpkQEw1WpELokixkMBmSpc5BUFNaLW2GupMdbNBMtEUmKLh4sJRCXefFgaUvc2UEhkfOCQrJp/HeFyDLW2FNe4VA+e/ZsHDt2DDExMQAK/0EdNWoUTpw4AYPBAFdXV6xfvx716tV78sprEEM52boL11Px3aYLUNrLMDUyGL4ejkKX9EQmHPigzOe+6DjDGLB5K3Cih/jvCpFlrDGUV3g66Pfff8dzzz1nfHzgwAH89ddfGDNmDL7++msAwPfff1/JUomoslo28sC0kSHQaHWYteokrt3NFLqkJ+KmcC1zu4e9G5QyRwZyIiKqNSocyhMTE1G//sMLuw4ePAh/f3+899576Nu3L4YPH44///zTonOp1WrMmTMHnTt3RqtWrRAREWHxsUeOHEFUVBQ6dOiAdu3aITIyErGxsRV9O0S1SgMfZ3w46jk42sswZ91pnL6aInRJlTagcRhkYtPlFGViGQY0DhOoIiIioupT4VCu0WgglT6cnTp27BheeOEF4+O6desiJcWyIDB9+nT8+OOPGDBgAD766COIxWK8+eabOH36dLnHHTx4EKNHj4ZWq8WkSZPwzjvvQCwWY8qUKdiwYUNF3xJRreLlao8Po9rC31OJRRvP49Dpe0KXVCntfdpgRNOhcFO4QoTCGXLeNpyIiGqrCn/36+Pjg9OnTyMiIgJXr17FnTt3MHnyZOPzqampcHB4/PrD586dw44dOzBjxgy89tprAIBBgwahX79+mDt3LlavXl3msatXr4anpyd+/PFHyOVyAEBERAS6d++OLVu2YNiwYRV9W0S1irODHB/8IwRLtlzAT7svIz1bhUEvNrS5ZfTa+7RBe5827JMlIqJar8KhvG/fvli8eDHS0tJw9epVKJVKdOnSxfh8XFycRRd57tq1CzKZzCRAKxQK0IjYTgAAIABJREFUhIeHY968eUhOToaXl1epx+bk5MDFxcUYyAFALpfDxcUFCoXtrDpBVJ0UcgkmDQ3Cj7suY9uRm8jIUWFUWCAkYq4sQkREZG0q/K/zW2+9hcGDB+PMmTMQiUT4z3/+A2dnZwBAdnY2Dhw4gI4dOz72PHFxcWjYsCEcHU1XiGjVqhUMBgPi4uLKPLZ9+/a4evUq5s+fj9u3b+P27duYP38+bt68idGjR1f0LRHVWhKxGK/3booBnRrg93MJWBhzHiq1ZXeNJCIioppT4ZlyuVyOWbNmlfqco6MjDh8+DDs7u8eeJyUlBd7e3mbbi9c4T05OLvPYcePG4fbt21i6dCmWLFkCAHBwcMDixYvRqVMnS94G0VNDJBJh0IuN4KpUYNWey5i99jTeGdYKzg7yxx9MRERENaJK1xPTarVwcnKyaN+CggLIZDKz7cXtJyqVqsxj5XI5GjRogLCwMISGhkKn02H9+vV49913sXLlSrRq1arCtZe1ZmR18/S07PMielLDejZF3WdcMGfVCcxecxqfj+0IHxtay5xjhcgyHCtElrG2sVLhUP7rr7/i3LlzmDRpknHb6tWr8fXXX6OgoAC9e/fGV199VWrgLsnOzg4ajcZse3EYL683/N///jfOnz+P6OhoiIv6Y3v37o1+/fph1qxZWLduXUXfFm8eRE+Fxt5KvDc8BN9Gn8U/5/+KdyOC0cDHWeiyHotjhcgyHCtElqkVNw9asWIFrl+/bnwcHx+PWbNmwcvLCy+88AJiY2PLXTmlmKenZ6ktKsXLKZZ1kadarUZ0dDRefvllYyAHAJlMhhdffBHnz5+HVqut6Nsiemo08XfBh1FtIZNK8J/Vp3HheqrQJRERET31KhzKr1+/jpYtWxofx8bGQqFQIDo6GsuXL0efPn2wefPmx56nadOmuHHjBnJzc022nz171vh8aTIyMqDVaqHTmV+sptVqodVqYTDU7Iw3ka3x9XDEh1Ft4eVmj2+jz+GP8wlCl0RERPRUq3Aoz8zMhJubm/HxkSNH8Pzzz0OpLJyKb9++Pe7evfvY84SFhUGj0Zjc7EetVmPjxo1o06aN8SLQ+/fvIz4+3riPh4cHnJ2dsXfvXpP2l9zcXBw8eBABAQGPbZ0hIsDNSYHpI9sgoK4rVuyIw44/b/IXWiIiIoFUuKfczc0N9+/fB1C4Xvj58+cxdepU4/NlzWI/Kjg4GGFhYZg7dy5SUlJQr149bNq0Cffv38eXX35p3G/atGk4fvw4Ll++DACQSCQYPXo05s+fj8jISAwYMAB6vR7R0dFITEzEtGnTKvqWiJ5a9goppkQEY8WOOMT8eh3p2SqM6BEAsdi2bjJERERk6yocylu3bo1169ahSZMm+O2336DT6fDSSy8Zn79161aZ/eCPmj17NubPn48tW7YgMzMTgYGB+P7779G2bdtyjxs/fjz8/f3x008/4bvvvoNarUZgYCAWLVqE0NDQir4loqeaVCLGm/2bw02pwK7jt5GZq8bY/s0hk0qELo2IiOipITJU8Pvqa9euYdSoUUhLSwMADB482DizbTAY0L17d3To0MFkttsWcPUVImDPX3ewbv9VBPi7YFJ4KzjaWUcrGMcKkWU4VogsY42rr1R4prxJkyaIjY3FqVOn4OTkhHbt2hmfy8rKwquvvooOHTpUvloiEkzPdnXhqpRj+faL+PLnU5gaEQx358ffDIyIiIieTIVnymsrzpQTPRR3Kx2LNp6DnVyKKcOC4f//7d17eNT1mffxz8xkMjlNzpNMIEeSkECGQziauPUEWFZFLEppFdTW0na13YqX3dX22l7XbrdP+3Sth7JaLXa3wPJsqxhEaT2DoiaKghyGBJCQAIFMMgRCEnJO5vkjYSQN1kCT/CbJ+/WPF9/fzOQe9et8/Oae+5dgzM21zmOvAAPDXgEGZlSclJ937NgxvfXWWzp+/LgkKSUlRfPmzVNqaurlviSAADEpLUYP3TFTjz23Wz/fsEv/eOsU5aTGfPETAQDAZbmsk/LHH39ca9as6TdlxWw26zvf+Y5+8IMfDFqBw4WTcqC/urOtevS53fLWt2jlojzNzh3Yl7gHG3sFGBj2CjAwo+KkfOPGjXr66aeVn5+vb33rW8rOzpYkffrpp/rd736np59+WikpKVqyZMnfVjUAw8VFhejh5TP16xf26ukX3aqfn60Fs1KMLgsAgFHnkk/KlyxZIqvVqg0bNigoqG+m7+zs1B133KGOjg4VFRUNaqFDjZNy4PO1d3Tpty+XatchrxbOTdVt12TKbBq+WebsFWBg2CvAwATiSfkl39GzvLxcN9xwQ79ALklBQUG64YYb+tyBE8DIF2y16N5bXLp2xni9+uExPbulVJ1d3UaXBQDAqHHJ7StWq1XNzc2fe/3cuXPc5h4Yhcxmk5YvmKiYCJuKth9Rw7l23feVKQq1Xfb3xQEAQK9LPimfMmWK/vjHP+rUqVP9rtXV1em5557TtGnTBqU4AIHFZDLppsJ0ffOGSTpwtF7/d8MunW1qM7osAABGvEvuKf/oo4909913Kzw8XLfeequysrIk9dzps6ioSOfOndPvf/97zZo1a0gKHir0lAOXZt+ROj21yS17mFWrvjpNSXHhQ/az2CvAwLBXgIEJxJ7yyxqJuHXrVv30pz9VdXV1n/Vx48bpJz/5ia655prLKtRIhHLg0lVUN+jx5/fI55N+cNtUZY6PGpKfw14BBoa9AgzMqAnlktTd3S23262qqipJPTcPysvL03PPPad169bpz3/+8+VXbABCOXB5as8069E/7lF9U5u+u9il6dnxg/4z2CvAwLBXgIEJxFB+2d/QMpvNmjp1qqZOndpn/cyZM6qoqLjclwUwwiTEhOlHK2bq8ef3aHXRXt355RxdPX280WUBADCiXPIXPQHgL0WGB+ufbs+XKyNOa189qBffPaLL/CUcAABjEqEcwKAICQ7S92+dor+bkqSX3q/U2lcPqKubWeYAAAwEA4YBDJogi1nfuCFX0fZgbSk+qrNN7fruYpdswRajSwMAIKBxUg5gUJlMJi25KlMrrp+ovUfq9B9/+ESNze1GlwUAQEAb0En5f//3fw/4BXft2nXZxQAYPa6dkayoCJueeWm//s/6nXpg2XQ5okONLgsAgIA0oJGIubm5l/aiJpPKysouuygjMBIRGBqfVtXr1xv3ymIxa9XSaUpz2i/5NdgrwMCwV4CBGbEjEdetWzeoBQEYO7KTo/Xw8pl67Lnd+sX/26XvfWWK8jJijS4LAICActk3DxptOCkHhtaZxjY99tweVded0zdvmKQCl3PAz2WvAAPDXgEGJhBPyvmiJ4BhEWO36aE7Zig7OUprtpTqlQ+OMsscAIBehHIAwyYsJEirvjpdcyYl6Pm3y/W/b3467L+hAgAgEDGnHMCwsgaZ9e2b8xQdYdPrHx1XfVObVi6aLGsQs8wBAGMXoRzAsDObTPravGzF2G3649bDamjeo3+8dYrCQqxGlwYAgCFoXwFgmC/PSdV3bs5T+Ymz+vn/7NLphlajSwIAwBCEcgCGmjs5UQ98dZrqGlr1s/U7VeVtMrokAACGHaEcgOEmpcfqoTtmqNvn0y/+Z5cOHjtjdEkAAAwrQjmAgJCaaNePV8xUVESwfvXHPfr4QK3RJQEAMGz4oieAgBEfFaqHl8/Urzfu1W9edOuKvEQdOl6v0w1tio20acnVmSrIG/hNhwAAGCk4KQcQUCJCrXrwa9OVmhihkv01qmtok09SXUOb1r5yQCX7PUaXCADAoCOUAwg4wVaLGls6+q23d3ar6J1yAyoCAGBoEcoBBKTTDW0XXa9raNPZpotfAwBgpKKnHEBAiou0qe5zgvkDT76vvIxYFbqcys92yGblbqAAgJGNUA4gIC25OlNrXzmg9s5u/1pwkFk3/12GWto6VbLfo9++VKqQYItm5jhU6EpSTmq0zCaTgVUDAHB5COUAAtL5KStF75RfdPrKV66aoIPH6lXi9ujjg7V6f59HsZE2FeQ5VZDn1Lj4cCPLBwDgkph8Pp/P6CICQV1dk7q7h/dvhcNhl9fbOKw/ExiJvmivtHV06ZNPvSpx18hdUSefT0p32lXgcmrupERFhgcPY7WAcfhcAQbGqL1iNpsUFxdx0WuE8l6EciBwXcpeOdvUpg9La1Ts9uhYbZPMJpOmTIhVgcup/Ox4WYPoP8foxecKMDCBGMppXwEwqkRF2HT9nFRdPydVVd4mlbg9Ktnv0Z7yOoXagjQ7t6f/PCs5iv5zAEDAIJQDGLWSHRFaem2Wbr06U2XHzqh4n0cfltZq+55qxUeFqCDPqUKXU4mxYUaXCgAY4wjlAEY9s9mkvPRY5aXHqrW9U7sOeVXi9mhLcaVeLq7UhHGRKnQ5NWdSoiJCrUaXCwAYg+gp70VPORC4hmqvnGls0welHhW7PTrhPSeL2aSpmXEqdDk1NTNe1iDur4aRhc8VYGDoKQeAABJjt+nv56Zp4ZxUHa9tUrHbow9Ka/TJp6cUHhKk2ZMSVZjnVOb4SJnoPwcADCFCOYAxz2QyKTXRrtREu5Zem6nSyjMqdntUvK9ab39yQgnRoSpwOVXgciohOtTocgEAoxChHAAuYDGbNWVCnKZMiFNLW6d2HvSq2F2tl96r0Ob3KpSVHKVCl1OzcxMUHkL/OQBgcNBT3oueciBwBcJeqTvb6u8/r65rVpDFpOlZ8SpwOTVlQpyCLPSfw3iBsFeAkYCecgAYoeKiQnRjQbpuuCJNlZ5Glbg9+rCsRh8f9Coi1Kq5kxJV4HIqI8lO/zkA4JIZGsrb29v1xBNPaPPmzWpoaFBubq5WrVqlgoKCAT3/5Zdf1tq1a3X48GEFBwdr4sSJ+qd/+idNnTp1iCsHMFaZTCZlJEUqIylSX70uS+6K0ypxe/TOnpN6a1eVnLFhPf3neYmKj6L/HAAwMIaG8oceekivv/667rzzTqWlpWnTpk1auXKl1q9fr/z8/L/63Mcee0zPPvusbr75Zi1btkzNzc06cOCAvF7vMFUPYKwLspg1PSte07Pi1dzaoY8PelXs9mjT9iPatP2IclKiVeByalZOgsJC+MUkAODzGdZTvnfvXi1dulQPP/yw7r77bklSW1ubbrrpJiUkJGjDhg2f+9xdu3bp9ttv1+rVq7VgwYJBqYeeciBwjbS94q1v0Qf7e/rPa860yBpkVn52vApdTuVlxMpipv8cQ2Ok7RXAKPSUX+DVV1+V1WrV0qVL/Ws2m0233XabHnvsMdXW1iohIeGiz123bp2mTJmiBQsWqLu7Wy0tLQoPDx+u0gHgr3JEh2rRlRm6qTBdR6obVOz2aEdpjXaU1SoyzKq5k50qdDmVmhhB/zkAQJKBobysrEwZGRn9wvTUqVPl8/lUVlb2uaG8pKREN954ox599FGtX79ezc3NGj9+vO6//37dfPPNw1E+AHwhk8mkzHFRyhwXpa/Py9be8jqVuD3a9kmV3vj4uMbFh6vQ5dQVkxMVGxlidLkAAAMZFsq9Xq8SExP7rTscDklSbW3tRZ939uxZ1dfX609/+pMsFosefPBBRUdHa8OGDfrhD3+o0NDQQWtpAYDBEmQxa8ZEh2ZMdKippUMfHahVidujjW+X64W3y5WbFqNCl1MzJjoUaqP/HADGGsP+y9/a2iqrtf+NN2w2m6Se/vKLaW5uliTV19frueee07Rp0yRJCxYs0IIFC/Tkk09eVij/vP6eoeZw2A35ucBIM5r2ikNSRmqsvnp9rk6eatLbO6u0bedx/e5PZfqfNw6pwJWka2elaFq2QxYz7S24NKNprwBDKdD2imGhPCQkRB0dHf3Wz4fx8+H8L51fT05O9gdySQoODtaXv/xlrVu3TufOnbvkHnO+6AkErtG8V6ySFswYr/n543T4xFmVuD3asd+jt3dVKSoiWFdMTlShK0kpCcYcHGBkGc17BRhMfNHzAg6H46ItKudHGn5eP3l0dLSCg4MVHx/f71p8fLx8Pp+ampr44ieAEcVkMik7OVrZydH6+vxs7Tlcp2K3R29+XKXXdhxXsiOip/88L1HRERc/tAAAjFyGhfLc3FytX7++36n2nj17/Ncvxmw2a9KkSaqpqel3zePxyGKxKCoqamiKBoBhYA2yaFZugmblJqixuV07ympV7PbouW2H9fzbh5WXHqsCl1Mzsh2yBVuMLhcAMAgMG5a7cOFCdXR06Pnnn/evtbe3q6ioSDNmzPB/CfTkyZMqLy/v99zq6mq9//77/rWmpia98sorys/PV0gIUwwAjA72sGDNm5msf7lrln62cq5uLEhTdV2z1rxcqvv/8z39bkupyipPq9uYW04AAAaJYTcPkqQf/OAHeuutt3TXXXcpNTVVmzZtktvt1tq1azVz5kxJ0ooVK7Rjxw4dPHjQ/7yWlhYtWbJENTU1uvvuuxUZGakXXnhBFRUVfZ57KegpBwIXe6Wvbp9Pnx6vV7Hbo48P1qqlrUsxdpuuyEtUYZ5T4x30n49V7BVgYAKxp9zQUN7W1qbHH39cL7/8ss6ePaucnBw98MADKiws9D/mYqFc6uk9/+Uvf6l33nlHra2tysvL0wMPPKDZs2dfVi2EciBwsVc+X3tHl3YfPqVit0fuIz0n5mmJdhW6nJo7OVGR4cFGl4hhxF4BBoZQHsAI5UDgYq8MzNlz7dpRWqNit0dHaxplNpnkmhCrQpdT07PiFWyl/3y0Y68AAxOIoZw7VADAKBEVHqwFs1O0YHaKTnibVLzfow/21+jpzfsVarNoVk6CCl1OZadEy2xi/jkABBJCOQCMQuMdEVp6TZZuvSpTB46d6Zl/fqBW7+6tVlxkiApciSrIcyopjvGxABAICOUAMIqZzSZNTo/V5PRYLW/v0q5PvSpxe/SnkqPaUnxUGUmRKnQ5NWdSguxh9J8DgFHoKe9FTzkQuNgrg6++qU0f7K9RyX6Pjtc2yWI2acqEOBW6nJqWFS9rkGETc/E3YK8AA0NPOQAgIERH2LRwbqoWzk3V8domlbg9Kin1aPfhUwqzBWnOpAQVuJzKGh8lE/3nADDkCOUAMMalJEQo5bos3XZNpkqPnlax26Pi/R69vfukEqJDe+afu5xKiAkzulQAGLUI5QAAST2/VnVlxMmVEaeWtk7tOuRVsdujl9+v1EvvVyprfJQKXE7Nzk1QRKjV6HIBYFShp7wXPeVA4GKvGOt0Q6s+6J1/fvLUOQVZTJqWGa8Cl1NTM+MUZKH/PFCwV4CBoaccADDixEaG6IYr0vT3c1N1rKZJxW6PPiz1aOchryJCrZo9qWf++YSkSPrPAeAyEcoBAANiMpmU5rQrzWnXV6/L1P6Knv7z9/ZWa9uuE0qMDVNhXs/88/joUKPLBYARhVAOALhkFrNZUzPjNTUzXs2tndp5sFbFbo82vVuhTe9WaGJKtApdTs3KSVBYCB81APBF6CnvRU85ELjYKyPHqbMt+mB/T/+553Szgixm5Wf39J+7MmLpPx9i7BVgYOgpBwCMavFRobqpMF03FqSp0tOo4n0efVhWo48O1MoeZtXcSYkqnOJUWqKd/nMAuAChHAAw6EwmkzKSIpWRFKll87K070idStwevb37hN7cWaWkuDAVupwqyHMqNjLE6HIBwHCEcgDAkOppYXEoP9uhc60d+uhArUrcHr3wzhEVvXNEOanRKnQlaWaOQ6E2PpYAjE30lPeipxwIXOyV0am2vkUfuD0qdntUW9+i4CCzZkx0qMDl1OT0GFnM9J9fKvYKMDD0lAMA0CshOlQ3/12GFl2ZrvKTDSp2e/RRWY0+KK1RVHiw5k5OVKHLqdREu9GlAsCQI5QDAAxlMpmUNT5KWeOj9PV52dpbfkrFbo/e2lml1z86rmRHuApcTl0x2akYu83ocgFgSBDKAQABwxpk1sycBM3MSVBTS4d2lNWoxO3R89vKtfHtck1Oi1GhK0kzJjpkC7YYXS4ADBpCOQAgIEWEWnXdjGRdNyNZntPNKnF7VLLfozVbSmWzWjQzp6f/fFJqjMxmxisCGNkI5QCAgOeMDdNXrpqgxV/K0OGqsz395wd67iIaY7fpismJKnA5ley4+BeoACDQMX2lF9NXgMDFXsHFdHR2affhOhXvq5a74rS6un1KTYxQYZ5TcycnKipi7PWfs1eAgWH6CgAAg8QaZNHs3ATNzk1QQ3O7dpTWqNjt0R+2HtZz28qVlxGrQpdT+dnxCrbSfw4gsBHKAQAjXmRYsObPStH8WSk6eeqcSvb39J8/89J+hQRbNCsnQYUupyamRstsov8cQOAhlAMARpVx8eG69epMfeWqCTp4rF4lbo8+Plir9/ZVKy7SpivynCp0OZUUF250qQDgR095L3rKgcDFXsHfqq2jS5986lWJu0buijr5fFJGkl0FeU7NmZyoyLBgo0scFOwVYGACsaecUN6LUA4ELvYKBtPZpjZ92Nt/fqy2SRazSVMmxKnA5dT0rDhZg0Zu/zl7BRiYQAzltK8AAMaUqAibrp+TquvnpKrK2+Sff7778CmF2oI0O7en/zw7OUom+s8BDBNOyntxUg4ELvYKhlp3t09lx86oeJ9Huw551dbRpfioEBX09p8nxoYZXeKAsFeAgeGkHACAAGQ2m5SXHqu89Fi1tndq1yGvStwebSmu1MvFlcocF6lCl1OzJyUqItRqdLkARiFOyntxUg4ELvYKjHKmsU0flHpU7PbohPecLGaTpmXFqyDPqamZcbIGmY0usQ/2CjAwnJQDADCCxNht+vu5aVo4J1XHa5tU7Pbog9Ia7TrkVXhIkOZMSlSBy6nMcZH0nwP4mxDKAQD4AiaTSamJdqUm2rX02kyVVp5Rsduj9/dVa9snJ5QQE6rCPKeucDmVEB1qdLkARiBCOQAAl8BiNmvKhDhNmRCnlrZO7TzoVbG7Wpvfq9CL71UoOzmqp/88N0FhIfSfAxgYesp70VMOBC72CkaCurOt/v7z6rpmBVnMmp4Vp0JXklwTYhVkGfr+c/YKMDD0lAMAMErFRYXoxoJ03XBFmio9jSpxe/RhWY0+PuhVRKhVcycnqtDlVLrTTv85gH4I5QAADCKTyaSMpEhlJEXqq9dlyV1xWiVuj97ZfVJv7axSUlyYCvKcKshzKi4qxOhyAQQIQjkAAEOkp4UlXtOz4tXc2qGPD3pV7PaoaPsRFW0/otzUaBXkOTUrN0GhNj6SgbGMnvJe9JQDgYu9gtHGW9+iD/b39J/XnGmRNcis/Ox4FbqSlJcRI4v58vrP2SvAwNBTDgAA5IgO1aIrM3RTYbqOVDeo2O3RjtIa7SirVWR4sK6YnKiCPKdSEyPoPwfGCEI5AAAGMZlMyhwXpcxxUfr6vGztLa9Tidujrbuq9PpHxzXeEd4z/zzPqRi7zehyAQwhQjkAAAEgyGLWjIkOzZjoUFNLhz46UKsSt0fPv12ujW+Xa1J6jArynJqZ41BIMB/fwGhDT3kvesqBwMVewVhWc6ZZJW6PSvZ75K1vVbDVrJkTHSp0JWlSWozMZpNK9ntU9E65Tje0KTbSpiVXZ6ogz2l06UDACsSeckJ5L0I5ELjYK4Dk8/l0+MRZlbg92lFWq+a2TkVHBCs1MUJllfXq6Or2PzY4yKy7/j6XYA58jkAM5fz+CwCAEcBkMik7OVrZydH6+vxs7Tlcp2K3R7sPn+r32PbObhW9U04oB0aQob/nLwAAGFTWIItm5SboH2+b+rmPqWto0zMv7ddrO47p4LEzamnrHMYKAVwqTsoBABjB4iJtqmto67duDTLr06p6fVhaI0kySXLGhSndGan0JLsynJFKSYyQzWoZ5ooBXIyhoby9vV1PPPGENm/erIaGBuXm5mrVqlUqKCi4pNdZuXKltm/frjvvvFM//vGPh6haAAACz5KrM7X2lQNq77x4T/nZc+066mlQZXWjKj2NKq08rZL9HkmS2WTSuPjPgnq6M1IpCeGyBhHUgeFmaCh/6KGH9Prrr+vOO+9UWlqaNm3apJUrV2r9+vXKz88f0Gu8/fbb+vjjj4e4UgAAAtP5vvHPm74SFR6sqZnxmpoZ73/OmcY2VV4Q1HcfPqX39lVLkixmk8Y7wpWRFKl0Z09QH+8IV5CFjldgKBk2fWXv3r1aunSpHn74Yd19992SpLa2Nt10001KSEjQhg0bvvA12tvbtWjRIi1atEirV6/+m07Kmb4CBC72CjAwl7tXfD6fTjf0BnVPoyqre/56rrWnDz3IYlZKQkTvaXpP60tSfJgsZoI6Riamr1zg1VdfldVq1dKlS/1rNptNt912mx577DHV1tYqISHhr77GunXr1NraqnvuuUerV68e6pIBABiVTCaT4qJCFBcVopk5PZ+9Pp9P3rOt/oBeWd2gD/Z7tG3XCUk9LTKpiT0h/XzrizM2TGazyci3AoxYhoXysrIyZWRkKDw8vM/61KlT5fP5VFZW9ldDudfr1VNPPaWf/OQnCg0NHepyAQAYU0wmkxKiQ5UQHao5kxIlSd0+n2rPtPQJ6u/urdabO6skSbZgi9IuCOoZzkg5YkJlNhHUgS9iWCj3er1KTEzst+5wOCRJtbW1f/X5jz76qDIyMrR48eIhqQ8AAPRlNpnkjA2TMzZMV/T2rHd3+1R9uvmzoO5p0LZPTqjjo54vnobagnp70+1K7+1Tj48KkYmgDvRhWChvbW2V1Wrtt26z2ST19Jd/nr179+rFF1/U+vXrB21Tf15/z1BzOOyG/FxgpGGvAANjxF5JTIzU9Emf3aios6tbx2sadfh4vT6tqtfh4/V64+MqdfbeddQeZlVWcrSyUqKVnRKtrOQYxUcT1DG8Au1zxbBQHhISoo6Ojn7r58P4+XD+l3w+n372s5/p+uuv16xZswatHr7oCQQu9gowMIG0VyKsZk2fEKvpE2Il9QT1Km9T78SXnsmljnzgAAASdElEQVQvew+fUlfvZ29kmNV/kn5+RGN0xMWzAPC34oueF3A4HBdtUfF6vZL0uf3kb7zxhvbu3atVq1apqqqqz7WmpiZVVVUpPj5eISEhg180AAC4LEEWc0/YdkZKGi9Jau/o0vELg7qnUfuO1On8XLjoiOA+M9TTnXZFhgcb9yaAIWRYKM/NzdX69et17ty5Pl/23LNnj//6xZw8eVLd3d266667+l0rKipSUVGR1qxZo6uuumpoCgcAAIMi2GpR5rgoZY6L8q+1tXfpWG1jn6C+5/Apnf9ddlykrU9QT3PaFRHavx0WGGkMC+ULFy7Uf/3Xf+n555/3zylvb29XUVGRZsyY4f8S6MmTJ9XS0qLMzExJ0nXXXafk5OR+r3fffffp2muv1W233aa8vLxhex8AAGDw2IItyk6OVnZytH+tpa1Tx2oaVXFBUN95yOu/7ogO6RvUE+0KCzH0/ojAJTPs39hp06Zp4cKFeuSRR+T1epWamqpNmzbp5MmT+vnPf+5/3D//8z9rx44dOnjwoCQpNTVVqampF33NlJQUzZ8/f1jqBwAAwyPUFqSc1BjlpMb41861duiop9E/mrGiukEfHfisLTYxNkwZF0x9SU2MUEgwQR2By9B/O3/5y1/q8ccf1+bNm3X27Fnl5OTot7/9rWbOnGlkWQAAIMCFh1g1OT1Wk9Nj/WuNze066mlURW9QP3i8Xh+U1kiSTJKS4sP7jGdMSYiQzWox6B0AfZl8Pt/wjhwJUExfAQIXewUYGPZKf2eb2nrnp/eeqHsa1XCuXVLP3PVx8eG9NzrqCerJjghZg8wGV42hxvQVAACAYRQVYdO0LJumZcVL6hmtXN/U7g/olZ4G7f70lN7bWy1JsphNSnZE9Pan9/Soj3eEK8hCUMfQIpQDAIAxw2QyKcZuU4zdofyJPXcR9/l8qmto7Z340hPUPyqr1Tu7T0rqGeeYkvBZUM9wRiopPkwWM0Edg4dQDgAAxjSTyaT4qFDFR4VqVm7PfVJ8Pp+89S29bS89Qb3E7dG2XSckScFBZqUmnu9P7zlRd8aGyWzmrqS4PIRyAACAv2AymZQQE6aEmDDNmdQzprnb51PN6eY+QX373pN6c2e3pJ5xjmmJdmUkfXZX0oToUJlMBHV8MUI5AADAAJhNJiXFhSspLlwFeU5JUne3T9V15/rMUH9r5wl1dh2X1DPO8fxpekbvXUnjokII6uiHUA4AAHCZzGaTxjsiNN4Rob+bmiRJ6uzq1slT5/pMfHl9x3F19U55iwi19ml7SXfaFWO3EdTHOEI5AADAIAqy9PSbpybaddW0cZKkjs5uVXmb/EG90tOoP5ccU3fvZOrI8OA+M9QznHZFRdiMfBsYZoRyAACAIWYNMisjKVIZSZFS/nhJUntHl47X9g3q+47U6fwdZGLstj5BPc1pV2RYsIHvAkOJUA4AAGCAYKtFmeOjlDk+yr/W2t6pYzVN/tGMldWN+uTTU/7rcZEhn81QT+ppfQkPsRpRPgYZoRwAACBAhAQHaWJKtCamRPvXmls7daymsU9Q33nQ67+eEB3apz89zWlXqI2IN9LwTwwAACCAhYUEKTctRrlpMf61ppYOHa35rO2l/ESDdpTV+q87Y8P6BvVEu2zBFiPKxwARygEAAEaYiFCr8tJjlZce619raG7X0Qv60w8eq9cH+2skSSaTNC4uvE/bS0pChIKtBPVAQSgHAAAYBSLDgjVlQpymTIjzr9U3tfX7Iun7bo+knrnr4x19g3qyI0LWILNRb2FMI5QDAACMUtERNk3Psml6Vrwkyefz6UxjW5/+9F2HvHp3b7UkyWI2KTkhQhkXBPVx8eEKshDUhxqhHAAAYIwwmUyKjQxRbGSIZkx0SOoJ6nVnW1XpaVRFb1D/sKxWb+8+Ken83PWI3vGMkUpPsmtcXLjMZm52NJgI5QAAAGOYyWRSfHSo4qNDNSs3QZLU7fPJW9+iyupGVfS2vrzv9mjrrhOSpGBrzw2S0p12ZfQG9cTYMJm5K+llI5QDAACgD7PJpMSYMCXGhGnu5ERJUne3T57Tzf62l0pPo7bvPqk3O6skSSHBlj6n6elOuxzRoTIR1AeEUA4AAIAvZDabNC4+XOPiw1XoSpIkdXV3q/pUc0/bi6dRldWNenNnlTq7uiVJYbagPqMZ05PsiosMIahfBKEcAAAAl8ViNis5IULJCRH60tSetc6ubp3wnus5Ue8N6q/tOKaubp+knnGO54P6+S+URkcEj/mgTigHAADAoAmymJXWe2fRq3vXOjq7VOU9p8rqBlX0BvU/VxxVt68nqEeFB/cZzZieFKmo8GDj3oQBCOUAAAAYUtYgizKSIpWRFKlre9faOrp0vLbJP0O90tOoveV18vVej7Hb/AE9ozfk28NGb1AnlAMAAGDY2awWZY2PUtb4KP9aa3unjtV8FtQrPI365NNT/uvxUSF9TtTTnHaFh1iNKH/QEcoBAAAQEEKCgzQxJVoTU6L9a82tnTpa03jB1JcGfXzQ67+eEBPqn/qSkWRXaqJdobaLR9yS/R4VvVOu0w1tio20acnVmSrIcw75+xoIQjkAAAACVlhIkCalxWhSWox/ramlQ0cvuCtp+Ymz2lFWK0kySXLGhfUZz5iaYNeuT71a+8oBtXf2TIapa2jT2lcOSFJABHNCOQAAAEaUiFCr8jJilZcR619rONfe25veE9TLjp5Ryf4aSZLJ1DN7/fwEmPPaO7tV9E45oRwAAAAYDJHhwZqaGaepmXH+tTONbf4T9Zfer7zo8+oa2oapwr+OUA4AAIBRKcZuU4zdpunZ8Xp/X/VFA3hcpM2AyvozG10AAAAAMNSWXJ2p4KC+0Tc4yKwlV2caVFFfnJQDAABg1DvfN870FQAAAMBABXlOFeQ55XDY5fU2Gl1OH7SvAAAAAAYjlAMAAAAGI5QDAAAABiOUAwAAAAYjlAMAAAAGI5QDAAAABiOUAwAAAAYjlAMAAAAGI5QDAAAABuOOnr3MZtOY+rnASMNeAQaGvQIMjBF75a/9TJPP5/MNYy0AAAAA/gLtKwAAAIDBCOUAAACAwQjlAAAAgMEI5QAAAIDBCOUAAACAwQjlAAAAgMEI5QAAAIDBCOUAAACAwQjlAAAAgMEI5QAAAIDBgowuYKypra3VunXrtGfPHrndbjU3N2vdunWaO3eu0aUBAWPv3r3atGmTPvzwQ508eVLR0dHKz8/X/fffr7S0NKPLAwLGvn379PTTT6u0tFR1dXWy2+3Kzc3VfffdpxkzZhhdHhDQ1qxZo0ceeUS5ubnavHmz0eUQyodbRUWF1qxZo7S0NOXk5OiTTz4xuiQg4Dz77LPatWuXFi5cqJycHHm9Xm3YsEG33HKLNm7cqMzMTKNLBALC8ePH1dXVpaVLl8rhcKixsVEvv/yyli9frjVr1ujKK680ukQgIHm9Xv3mN79RWFiY0aX4mXw+n8/oIsaSpqYmdXR0KCYmRm+++abuu+8+TsqBv7Br1y65XC4FBwf71yorK7Vo0SLdeOON+sUvfmFgdUBga2lp0fz58+VyufTMM88YXQ4QkB566CGdPHlSPp9PDQ0NAXFSTk/5MIuIiFBMTIzRZQABbcaMGX0CuSSlp6crOztb5eXlBlUFjAyhoaGKjY1VQ0OD0aUAAWnv3r166aWX9PDDDxtdSh+EcgAjgs/n06lTp/ifWuAimpqadPr0aR05ckSPPvqoDh06pIKCAqPLAgKOz+fTT3/6U91yyy2aNGmS0eX0QU85gBHhpZdeUk1NjVatWmV0KUDA+dGPfqTXXntNkmS1WvW1r31N3/3udw2uCgg8L774og4fPqwnn3zS6FL6IZQDCHjl5eX6t3/7N82cOVOLFy82uhwg4Nx3331atmyZPB6PNm/erPb2dnV0dPRrAwPGsqamJv3qV7/St7/9bSUkJBhdTj+0rwAIaF6vV9/5zncUFRWlJ554QmYz/9kC/lJOTo6uvPJK3Xrrrfrd736n/fv3B1y/LGC03/zmN7JarfrGN75hdCkXxacbgIDV2NiolStXqrGxUc8++6wcDofRJQEBz2q1at68eXr99dfV2tpqdDlAQKitrdXatWt1++2369SpU6qqqlJVVZXa2trU0dGhqqoqnT171tAaaV8BEJDa2tr03e9+V5WVlfr973+vCRMmGF0SMGK0trbK5/Pp3LlzCgkJMbocwHB1dXXq6OjQI488okceeaTf9Xnz5mnlypV68MEHDaiuB6EcQMDp6urS/fffr927d+upp57S9OnTjS4JCEinT59WbGxsn7Wmpia99tprSkpKUlxcnEGVAYElOTn5ol/ufPzxx9Xc3Kwf/ehHSk9PH/7CLkAoN8BTTz0lSf55y5s3b9bOnTsVGRmp5cuXG1kaEBB+8YtfaOvWrbr22mtVX1/f56YO4eHhmj9/voHVAYHj/vvvl81mU35+vhwOh6qrq1VUVCSPx6NHH33U6PKAgGG32y/62bF27VpZLJaA+Fzhjp4GyMnJuej6+PHjtXXr1mGuBgg8K1as0I4dOy56jX0CfGbjxo3avHmzDh8+rIaGBtntdk2fPl3f/OY3NWfOHKPLAwLeihUrAuaOnoRyAAAAwGBMXwEAAAAMRigHAAAADEYoBwAAAAxGKAcAAAAMRigHAAAADEYoBwAAAAxGKAcAAAAMRigHABhmxYoVuu6664wuAwAMF2R0AQCAwfXhhx/qzjvv/NzrFotFpaWlw1gRAOCLEMoBYJS66aabdNVVV/VbN5v5JSkABBpCOQCMUpMnT9bixYuNLgMAMAAclwDAGFVVVaWcnBytXr1aW7Zs0aJFizRlyhRdc801Wr16tTo7O/s958CBA7rvvvs0d+5cTZkyRTfccIPWrFmjrq6ufo/1er3693//d82bN08ul0sFBQX6xje+offff7/fY2tqavTAAw9o9uzZmjZtmu655x5VVFQMyfsGgEDESTkAjFItLS06ffp0v/Xg4GBFRET4/7x161YdP35cd9xxh+Lj47V161b953/+p06ePKmf//zn/sft27dPK1asUFBQkP+x27Zt0yOPPKIDBw7oV7/6lf+xVVVV+vrXv666ujotXrxYLpdLLS0t2rNnj4qLi3XllVf6H9vc3Kzly5dr2rRpWrVqlaqqqrRu3Trde++92rJliywWyxD9HQKAwEEoB4BRavXq1Vq9enW/9WuuuUbPPPOM/88HDhzQxo0blZeXJ0lavny5vve976moqEjLli3T9OnTJUk/+9nP1N7erj/84Q/Kzc31P/b+++/Xli1bdNttt6mgoECS9K//+q+qra3Vs88+qy996Ut9fn53d3efP585c0b33HOPVq5c6V+LjY3Vf/zHf6i4uLjf8wFgNCKUA8AotWzZMi1cuLDfemxsbJ8/FxYW+gO5JJlMJn3rW9/Sm2++qTfeeEPTp09XXV2dPvnkEy1YsMAfyM8/9h/+4R/06quv6o033lBBQYHq6+v17rvv6ktf+tJFA/VfftHUbDb3mxZzxRVXSJKOHj1KKAcwJhDKAWCUSktLU2Fh4Rc+LjMzs99aVlaWJOn48eOSetpRLly/0IQJE2Q2m/2PPXbsmHw+nyZPnjygOhMSEmSz2fqsRUdHS5Lq6+sH9BoAMNLxRU8AgKH+Ws+4z+cbxkoAwDiEcgAY48rLy/utHT58WJKUkpIiSUpOTu6zfqEjR46ou7vb/9jU1FSZTCaVlZUNVckAMOoQygFgjCsuLtb+/fv9f/b5fHr22WclSfPnz5ckxcXFKT8/X9u2bdOhQ4f6PPa3v/2tJGnBggWSelpPrrrqKm3fvl3FxcX9fh6n3wDQHz3lADBKlZaWavPmzRe9dj5sS1Jubq7uuusu3XHHHXI4HHrrrbdUXFysxYsXKz8/3/+4H//4x1qxYoXuuOMO3X777XI4HNq2bZvee+893XTTTf7JK5L0L//yLyotLdXKlSt1yy23KC8vT21tbdqzZ4/Gjx+vH/7wh0P3xgFgBCKUA8AotWXLFm3ZsuWi115//XV/L/d1112njIwMPfPMM6qoqFBcXJzuvfde3XvvvX2eM2XKFP3hD3/Qr3/9a/3v//6vmpublZKSogcffFDf/OY3+zw2JSVFL7zwgp588klt375dmzdvVmRkpHJzc7Vs2bKhecMAMIKZfPweEQDGpKqqKs2bN0/f+9739P3vf9/ocgBgTKOnHAAAADAYoRwAAAAwGKEcAAAAMBg95QAAAIDBOCkHAAAADEYoBwAAAAxGKAcAAAAMRigHAAAADEYoBwAAAAxGKAcAAAAM9v8BWX60iOZfuYAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znqIQ1EO2TSM",
        "outputId": "4cb68f8a-0f08-4c41-9a7a-9148244091fc"
      },
      "source": [
        "# Testing on val set\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "total_eval_accuracy = 0\n",
        "total_eval_loss = 0\n",
        "nb_eval_steps = 0\n",
        "prediction = [] #store prediction\n",
        "\n",
        "# Evaluate data for one epoch\n",
        "for batch in validation_dataloader:\n",
        "    \n",
        "    # Unpack this training batch from our dataloader. After unpacking, we copy\n",
        "    # the tensor to the GPU as well using .to()\n",
        "        \n",
        "    # `batch` contains three pytorch tensors:\n",
        "    #  0 for input id, 1 for attention mask and 2 for labels\n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_labels = batch[2].to(device)\n",
        "\n",
        "    \n",
        "    # Tell pytorch not to bother with constructing the compute graph during\n",
        "    # the forward pass, since this is only needed for backprop (training).\n",
        "    with torch.no_grad():        \n",
        "\n",
        "        # Forward pass, calculate logit predictions.\n",
        "        \n",
        "        (loss, logits) = model(b_input_ids, \n",
        "                                token_type_ids=None, \n",
        "                                attention_mask=b_input_mask,\n",
        "                                labels=b_labels)\n",
        "        \n",
        "    # Accumulate the validation loss.\n",
        "    total_eval_loss += loss.item()\n",
        "\n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    #collect predictions\n",
        "    # \n",
        "    pred = np.argmax(logits, 1)\n",
        "    prediction.append(pred)\n",
        "\n",
        "    # Calculate the accuracy for this batch of test sentences, and\n",
        "    # accumulate it over all batches.\n",
        "    total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "    \n",
        "\n",
        "# Report the final accuracy for this validation run.\n",
        "avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "# # Calculate the average loss over all of the batches.\n",
        "# avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "\n",
        "# # Measure how long the validation run took.\n",
        "# validation_time = format_time(time.time() - t0)\n",
        "\n",
        "print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "\n",
        "#print('Positive samples: %d of %d (%.2f%%)' % (train.label.sum(), len(train.label), (train.label.sum() / len(train.label) * 100.0)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.75\n",
            "  Validation Loss: 0.96\n",
            "  Validation took: 0:00:18\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbFE4FNli5YF"
      },
      "source": [
        "print('Positive samples: %d of %d (%.2f%%)' % (Y.sum(), len(Y), (Y.sum() / len(Y) * 100.0)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "KGFSsPwihqz5",
        "outputId": "3d3e4ef3-1f6b-46e4-d17f-514d46bfae51"
      },
      "source": [
        "# import os\n",
        "\n",
        "# # Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "# output_dir = '/content/drive/My Drive/Colab Notebooks/BERT/'\n",
        "\n",
        "# # Create output directory if needed\n",
        "# if not os.path.exists(output_dir):\n",
        "#     os.makedirs(output_dir)\n",
        "\n",
        "# print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# # Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# # They can then be reloaded using `from_pretrained()`\n",
        "# model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "# model_to_save.save_pretrained(output_dir)\n",
        "# tokenizer_bert.save_pretrained(output_dir)\n",
        "\n",
        "# # Good practice: save your training arguments together with the trained model\n",
        "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to /content/drive/My Drive/Colab Notebooks/BERT/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-e17725766e74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Good practice: save your training arguments together with the trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'training_args.bin'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1eRRA_e9h7N"
      },
      "source": [
        "from numpy import loadtxt\n",
        "from keras.models import load_model\n",
        " \n",
        "# load model\n",
        "model = load_model('./model_save/saved_model.pb')\n",
        "# summarize model.\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7W9B49HcIrH5"
      },
      "source": [
        "import os\n",
        "os.getcwd()\n",
        "\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHnJluvF7BDl"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "#flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "flat_true_labels = [item for sublist in true_labels for item in sublist]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yiFkZ1iRhxuf",
        "outputId": "74e3fbcf-d472-4fd6-bb05-5db7d736ebfd"
      },
      "source": [
        "len(flat_predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2210"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hbg517R6hzP7",
        "outputId": "bd36cdaa-d543-4e48-b490-384c9337241e"
      },
      "source": [
        "len(flat_true_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2210"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uk-GrzKxh01C",
        "outputId": "c62c1b9a-be21-4291-812a-76c4607f9956"
      },
      "source": [
        "%matplotlib inline\r\n",
        "print(classification_report(flat_true_labels, flat_predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.43      0.52      0.47        31\n",
            "           1       0.88      0.71      0.79       180\n",
            "           2       0.83      0.63      0.72        30\n",
            "           3       0.53      0.67      0.59        69\n",
            "           4       0.56      0.59      0.58       150\n",
            "           5       0.85      0.87      0.86        46\n",
            "           6       1.00      0.40      0.57        10\n",
            "           7       0.00      0.00      0.00         2\n",
            "           8       0.64      0.45      0.53        20\n",
            "           9       0.72      0.77      0.74        83\n",
            "          10       0.11      0.06      0.08        33\n",
            "          11       0.85      0.63      0.72        27\n",
            "          12       0.90      0.79      0.84       614\n",
            "          13       0.60      0.68      0.63       188\n",
            "          14       0.59      0.72      0.65       138\n",
            "          15       0.00      0.00      0.00         5\n",
            "          16       0.76      0.85      0.80        91\n",
            "          17       0.95      0.98      0.96        41\n",
            "          18       0.65      0.92      0.76        12\n",
            "          19       0.79      0.80      0.80        46\n",
            "          20       0.73      0.81      0.77        83\n",
            "          21       0.91      1.00      0.95        52\n",
            "          22       0.82      0.97      0.89       229\n",
            "          23       0.69      0.53      0.60        17\n",
            "          24       0.14      0.08      0.11        12\n",
            "          25       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.75      2210\n",
            "   macro avg       0.61      0.59      0.59      2210\n",
            "weighted avg       0.76      0.75      0.75      2210\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytaJht6giGoD",
        "outputId": "ec0237e0-31da-47e0-bcf2-56679be6ca2f"
      },
      "source": [
        "from sklearn.metrics import f1_score\r\n",
        "f1_score(flat_true_labels, flat_predictions, average='micro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7515837104072398"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkEqcbHxg1oi",
        "outputId": "e0f95710-5c37-44ca-af1c-c67e51d47d16"
      },
      "source": [
        "f1_score(flat_true_labels, flat_predictions, average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5923448863368601"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8lL2wK8scI1",
        "outputId": "c80630c2-8f97-405b-9c8c-8466bc8401e9"
      },
      "source": [
        "f1_score(flat_true_labels, flat_predictions, average='weighted')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7494168659778776"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzoI1QUYsyBH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}