{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERTBalanced_keras.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-v82rA5qF1eA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1052dae-20e1-4cf0-926c-01d7909cdd45"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCE9CLR6F23W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a200eefa-bfe2-48e8-a282-a9db4df69a05"
      },
      "source": [
        "!pip install keras-bert"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras-bert in /usr/local/lib/python3.6/dist-packages (0.86.0)\n",
            "Requirement already satisfied: keras-transformer>=0.38.0 in /usr/local/lib/python3.6/dist-packages (from keras-bert) (0.38.0)\n",
            "Requirement already satisfied: Keras>=2.4.3 in /usr/local/lib/python3.6/dist-packages (from keras-bert) (2.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-bert) (1.18.5)\n",
            "Requirement already satisfied: keras-position-wise-feed-forward>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from keras-transformer>=0.38.0->keras-bert) (0.6.0)\n",
            "Requirement already satisfied: keras-layer-normalization>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from keras-transformer>=0.38.0->keras-bert) (0.14.0)\n",
            "Requirement already satisfied: keras-embed-sim>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from keras-transformer>=0.38.0->keras-bert) (0.8.0)\n",
            "Requirement already satisfied: keras-multi-head>=0.27.0 in /usr/local/lib/python3.6/dist-packages (from keras-transformer>=0.38.0->keras-bert) (0.27.0)\n",
            "Requirement already satisfied: keras-pos-embd>=0.11.0 in /usr/local/lib/python3.6/dist-packages (from keras-transformer>=0.38.0->keras-bert) (0.11.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.4.3->keras-bert) (2.10.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.4.3->keras-bert) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.4.3->keras-bert) (3.13)\n",
            "Requirement already satisfied: keras-self-attention==0.46.0 in /usr/local/lib/python3.6/dist-packages (from keras-multi-head>=0.27.0->keras-transformer>=0.38.0->keras-bert) (0.46.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->Keras>=2.4.3->keras-bert) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Eh-sgIjGHaa"
      },
      "source": [
        "import os\n",
        "os.environ['TF_KERAS'] = '1'    # Required to use tensorflow.python.keras with keras-bert"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a--BKbtTGJwY"
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXlI_3KOGLtf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce49005e-41c9-4ac2-dc80-ecc7e0aa2ac7"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "    print('We will use the GPU:', device_name)\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "We will use the GPU: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4E1D2R2qGNVU"
      },
      "source": [
        "train = pd.read_csv('/content/drive/My Drive/Colab Notebooks/train_file.txt', sep='{}{}{}', engine = 'python')\n",
        "test = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/test_file.txt\", sep= '{}{}{}', engine = 'python')\n",
        "\n",
        "#from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, val =  train,test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4t22qlGLILMN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3kcZjJQGU6s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b5f7329-d352-4b82-f1f7-1b52af6388ca"
      },
      "source": [
        "# Give -nc (--no-clobber) argument so that the file isn't downloaded multiple times \n",
        "!wget -nc https://storage.googleapis.com/bert_models/2018_10_18/cased_L-12_H-768_A-12.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File ‘cased_L-12_H-768_A-12.zip’ already there; not retrieving.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCTHImPIG-mJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c62aceed-9049-4009-b3bb-395f909f76a6"
      },
      "source": [
        "# Give -n argument so that existing files aren't overwritten \n",
        "!unzip -n cased_L-12_H-768_A-12.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  cased_L-12_H-768_A-12.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-UK3uFSHBDT"
      },
      "source": [
        "bert_vocab_path = 'cased_L-12_H-768_A-12/vocab.txt'\n",
        "bert_config_path = 'cased_L-12_H-768_A-12/bert_config.json'\n",
        "bert_checkpoint_path = 'cased_L-12_H-768_A-12/bert_model.ckpt'    # suffixes not required"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8sqldgoHDZp"
      },
      "source": [
        "model_is_cased = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OpqP4RwHFN4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "9fe38062-ff27-4554-87a3-1eaae49b9462"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "\n",
        "train = shuffle(train)\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5592</th>\n",
              "      <td>__label__ne</td>\n",
              "      <td>Regional Police also maintained a strong road ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8069</th>\n",
              "      <td>__label__pb</td>\n",
              "      <td>Two and a Half  We just got back today from 5 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5001</th>\n",
              "      <td>__label__ne</td>\n",
              "      <td>iPhone update on the way  A few days back we s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5518</th>\n",
              "      <td>__label__ne</td>\n",
              "      <td>Canadian Forces Snowbirds to be Inaugural Head...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13648</th>\n",
              "      <td>__label__sr</td>\n",
              "      <td>Paul Kent, Dean Ritchie and Paul Crawley discu...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Label                                               Text\n",
              "5592   __label__ne  Regional Police also maintained a strong road ...\n",
              "8069   __label__pb  Two and a Half  We just got back today from 5 ...\n",
              "5001   __label__ne  iPhone update on the way  A few days back we s...\n",
              "5518   __label__ne  Canadian Forces Snowbirds to be Inaugural Head...\n",
              "13648  __label__sr  Paul Kent, Dean Ritchie and Paul Crawley discu..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIuW4DTOHHLL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61cc5292-830c-48f3-a71e-036aa89e2de7"
      },
      "source": [
        "vocab = []\n",
        "with open(bert_vocab_path) as f:\n",
        "    for i, line in enumerate(f):\n",
        "        vocab.append(line.rstrip('\\n'))    # rstrip to remove newline characters\n",
        "\n",
        "\n",
        "# Print a list with every 500th vocabulary item\n",
        "print(vocab[0::500])\n",
        "print(len(vocab))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[PAD]', 'щ', '吉', 'told', 'space', 'operations', 'proposed', 'Oxford', 'showing', 'domestic', 'mountains', 'commission', 'voices', 'associate', 'hills', 'Guide', 'relaxed', 'Page', 'Heights', 'singers', 'Interior', 'considers', 'facilitate', 'shouting', '1826', 'constitute', 'alter', 'clip', 'Into', 'Memory', 'ballad', 'Owens', 'Langdon', 'aquatic', 'stereo', 'Cass', 'Shock', '195', '##tec', '##sonic', 'attested', '##rdes', '1840s', '##90', 'Guys', '##rien', 'Munro', 'Ursula', 'mesh', 'diplomacy', 'Newmarket', '##oughs', 'synthesizers', 'Drugs', 'monstrous', '##ynamic', 'troll', '##ٹ']\n",
            "28996\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnDOoM0bHJ5y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f028eaa3-1d43-4522-bd67-b2afca836334"
      },
      "source": [
        "from pprint import pprint    # pretty-printer for output\n",
        "import json\n",
        "\n",
        "with open(bert_config_path) as f:\n",
        "    config = json.load(f)\n",
        "\n",
        "\n",
        "# Print configuration contents\n",
        "pprint(config)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'attention_probs_dropout_prob': 0.1,\n",
            " 'hidden_act': 'gelu',\n",
            " 'hidden_dropout_prob': 0.1,\n",
            " 'hidden_size': 768,\n",
            " 'initializer_range': 0.02,\n",
            " 'intermediate_size': 3072,\n",
            " 'max_position_embeddings': 512,\n",
            " 'num_attention_heads': 12,\n",
            " 'num_hidden_layers': 12,\n",
            " 'type_vocab_size': 2,\n",
            " 'vocab_size': 28996}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4t0UGv2MHM1t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf9e43d2-af26-4653-f590-36e58f9723ea"
      },
      "source": [
        "import random\n",
        "# Create mapping from vocabulary items to their indices in the vocabulary\n",
        "token_dict = { v: i for i, v in enumerate(vocab) }\n",
        "\n",
        "\n",
        "# Print some random examples of the mapping\n",
        "pprint(dict(random.choices(list(token_dict.items()), k=10)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'##FM': 17938,\n",
            " '##father': 16064,\n",
            " '##Ţ': 28247,\n",
            " '1874': 7079,\n",
            " 'Azerbaijani': 19736,\n",
            " 'Community': 3704,\n",
            " 'Territories': 18057,\n",
            " 'Volunteer': 12744,\n",
            " 'centred': 17720,\n",
            " 'corresponds': 15497}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbXynyasHP5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99483353-f8ca-4142-987a-8b9ccf42d157"
      },
      "source": [
        "from keras_bert import Tokenizer\n",
        "\n",
        "\n",
        "tokenizer = Tokenizer(token_dict, cased=model_is_cased)\n",
        "\n",
        "\n",
        "# Let's test that out\n",
        "for s in ['Hello BERT!', 'Unknown: unknown 你']:\n",
        "    print('Original string:', s)\n",
        "    print('Tokenized:', tokenizer.tokenize(s))\n",
        "    indices, segments = tokenizer.encode(s, max_len=20)    # max_len for padding and truncation\n",
        "    print('Encoded:', indices)\n",
        "    print('Segments:', segments)\n",
        "    print('Decoded:', ' '.join(tokenizer.decode(indices)))\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original string: Hello BERT!\n",
            "Tokenized: ['[CLS]', 'Hello', 'B', '##ER', '##T', '!', '[SEP]']\n",
            "Encoded: [101, 8667, 139, 9637, 1942, 106, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Segments: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Decoded: Hello B ##ER ##T !\n",
            "\n",
            "Original string: Unknown: unknown 你\n",
            "Tokenized: ['[CLS]', 'Unknown', ':', 'unknown', '你', '[SEP]']\n",
            "Encoded: [101, 16285, 131, 3655, 100, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Segments: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Decoded: Unknown : unknown [UNK]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnaayjIMHSsc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd66eddf-3f59-41bc-e4ea-33a6c1d5437c"
      },
      "source": [
        "#print(train['Text'].values[17587])\n",
        "len(tokenizer.tokenize(train['Text'].values[17587]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "819"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYYaTmKJHXAQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc8ffe7f-1d31-485f-cc56-4b0d3b4e2a3c"
      },
      "source": [
        "train.head()\n",
        "train['Label'].values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['__label__ne', '__label__pb', '__label__ne', ..., '__label__ne',\n",
              "       '__label__qa', '__label__ib'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N99fjhQ0J8N8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd8b3827-5774-4bc3-b8ef-d180fac4886f"
      },
      "source": [
        "#Label encoding the label columns\n",
        "\n",
        "label_encode = {}\n",
        "for i, v  in enumerate(train['Label'].unique()):\n",
        "  label_encode[v] = i\n",
        "label_encode"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'__label__av': 18,\n",
              " '__label__df': 7,\n",
              " '__label__dp': 10,\n",
              " '__label__ds': 8,\n",
              " '__label__dt': 4,\n",
              " '__label__en': 11,\n",
              " '__label__fi': 21,\n",
              " '__label__fs': 24,\n",
              " '__label__ha': 17,\n",
              " '__label__ht': 6,\n",
              " '__label__ib': 5,\n",
              " '__label__it': 14,\n",
              " '__label__ne': 0,\n",
              " '__label__ob': 3,\n",
              " '__label__pb': 1,\n",
              " '__label__po': 23,\n",
              " '__label__qa': 9,\n",
              " '__label__ra': 22,\n",
              " '__label__re': 19,\n",
              " '__label__rs': 13,\n",
              " '__label__rv': 12,\n",
              " '__label__sl': 16,\n",
              " '__label__sr': 2,\n",
              " '__label__ss': 20,\n",
              " '__label__tb': 15,\n",
              " '__label__tv': 25}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvqB5ZMHJ8Q-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "f0cd82de-b02a-4482-fa9d-f479e57569ec"
      },
      "source": [
        "train['Label_enc'] = train['Label'].map(label_encode)\n",
        "val['Label_enc'] = val['Label'].map(label_encode)\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Text</th>\n",
              "      <th>Label_enc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5592</th>\n",
              "      <td>__label__ne</td>\n",
              "      <td>Regional Police also maintained a strong road ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8069</th>\n",
              "      <td>__label__pb</td>\n",
              "      <td>Two and a Half  We just got back today from 5 ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5001</th>\n",
              "      <td>__label__ne</td>\n",
              "      <td>iPhone update on the way  A few days back we s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5518</th>\n",
              "      <td>__label__ne</td>\n",
              "      <td>Canadian Forces Snowbirds to be Inaugural Head...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13648</th>\n",
              "      <td>__label__sr</td>\n",
              "      <td>Paul Kent, Dean Ritchie and Paul Crawley discu...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Label  ... Label_enc\n",
              "5592   __label__ne  ...         0\n",
              "8069   __label__pb  ...         1\n",
              "5001   __label__ne  ...         0\n",
              "5518   __label__ne  ...         0\n",
              "13648  __label__sr  ...         2\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aR054CJHdj5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f96184f3-5774-4c61-d65a-3dc20ea24865"
      },
      "source": [
        "print(\"Training Set Shape :\", train.shape)\n",
        "print(\"Test Set Shape :\", val.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Set Shape : (17588, 3)\n",
            "Test Set Shape : (2210, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axqRqtaSJFqh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9ed9577-7749-4bd4-fb69-8a650f1996f5"
      },
      "source": [
        "#Get value counts of each classes\n",
        "\n",
        "train['Label_enc'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     5577\n",
              "2     1711\n",
              "3     1445\n",
              "7     1268\n",
              "1     1203\n",
              "4     1108\n",
              "12     802\n",
              "9      638\n",
              "6      586\n",
              "8      482\n",
              "16     369\n",
              "11     326\n",
              "13     323\n",
              "22     294\n",
              "5      236\n",
              "18     222\n",
              "10     213\n",
              "14     193\n",
              "17     145\n",
              "20     129\n",
              "15      90\n",
              "19      89\n",
              "21      76\n",
              "23      38\n",
              "24      16\n",
              "25       9\n",
              "Name: Label_enc, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVNFWSgpILJL"
      },
      "source": [
        "# Separate the dataset for the purpose of upsampling and downsampling based on threshold of 802\n",
        "\n",
        "trainDown = train[train['Label_enc'].map(train['Label_enc'].value_counts()) >= 802]\n",
        "trainUp = train[train['Label_enc'].map(train['Label_enc'].value_counts()) <= 802]\n",
        "#trainUp['Label_enc'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMYdaoslH7X5"
      },
      "source": [
        "# Separate the dataset for the purpose of upsampling and downsampling based on threshold of 802\n",
        "\n",
        "trainDown = train[train['Label_enc'].map(train['Label_enc'].value_counts()) >= 802]\n",
        "trainUp = train[train['Label_enc'].map(train['Label_enc'].value_counts()) <= 802]\n",
        "#trainUp['Label_enc'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVCpnT3FKTeC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66abc1d8-ebb2-40e8-d277-5a067185ff5b"
      },
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "rus = RandomUnderSampler(random_state=0)\n",
        "ros = RandomOverSampler(random_state = 0)\n",
        "\n",
        "X_down, y_down = rus.fit_resample(trainDown,trainDown['Label_enc'])\n",
        "X_up, u_up = ros.fit_resample(trainUp, trainUp['Label_enc'])\n",
        "# X_down, y_down = rus.fit_resample(trainDown['Text'], trainDown['Label'])\n",
        "# X_up, u_up = ros.fit_resample(trainUp['Text'], trainUp['Label'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlPIOTFFKWTv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f5858d7-04cd-40a3-d0f7-9a676c93b123"
      },
      "source": [
        "Xd = pd.DataFrame(X_down, columns = ['Label','Text','Label_enc'])\n",
        "#Xd=Xd[Xd.Label_enc != 6]\n",
        "Xd['Label_enc'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12    802\n",
              "7     802\n",
              "4     802\n",
              "3     802\n",
              "2     802\n",
              "1     802\n",
              "0     802\n",
              "Name: Label_enc, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MMn2XPhKZdp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bcf3bb8-5e42-44cd-a164-67d43ae45734"
      },
      "source": [
        "Xu = pd.DataFrame(X_up, columns = ['Label','Text','Label_enc'])\n",
        "Xu['Label_enc'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25    802\n",
              "24    802\n",
              "6     802\n",
              "8     802\n",
              "9     802\n",
              "10    802\n",
              "11    802\n",
              "12    802\n",
              "13    802\n",
              "14    802\n",
              "15    802\n",
              "16    802\n",
              "17    802\n",
              "18    802\n",
              "19    802\n",
              "20    802\n",
              "21    802\n",
              "22    802\n",
              "23    802\n",
              "5     802\n",
              "Name: Label_enc, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDLYdmdtdseN",
        "outputId": "937dcf4e-bd2f-489a-a70a-59909a04e010"
      },
      "source": [
        "Xu = Xu[Xu.Label_enc != 12]\r\n",
        "Xu['Label_enc'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25    802\n",
              "15    802\n",
              "6     802\n",
              "8     802\n",
              "9     802\n",
              "10    802\n",
              "11    802\n",
              "13    802\n",
              "14    802\n",
              "16    802\n",
              "24    802\n",
              "17    802\n",
              "18    802\n",
              "19    802\n",
              "20    802\n",
              "21    802\n",
              "22    802\n",
              "23    802\n",
              "5     802\n",
              "Name: Label_enc, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONoOC4z7KcZJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97ea74fc-3da2-48ac-aee3-17f1ca364733"
      },
      "source": [
        "new_df = pd.concat([Xd,Xu]).reset_index(drop=True)\n",
        "new_df['Label_enc'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25    802\n",
              "24    802\n",
              "1     802\n",
              "2     802\n",
              "3     802\n",
              "4     802\n",
              "5     802\n",
              "6     802\n",
              "7     802\n",
              "8     802\n",
              "9     802\n",
              "10    802\n",
              "11    802\n",
              "12    802\n",
              "13    802\n",
              "14    802\n",
              "15    802\n",
              "16    802\n",
              "17    802\n",
              "18    802\n",
              "19    802\n",
              "20    802\n",
              "21    802\n",
              "22    802\n",
              "23    802\n",
              "0     802\n",
              "Name: Label_enc, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l02IH2muKg7e"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "train_token_indices, train_segment_ids = [], []  #bert tokenizer indices and their segment ids  (to separate sequences)\n",
        "val_token_indices, val_segment_ids = [], []\n",
        "for text in train['Text'].values:\n",
        "    # tokenizer.encode() returns a sequence of token indices\n",
        "    # and a sequence of segment IDs. BERT expects both as input,\n",
        "    # even if the segments IDs are just all zeros (like here).\n",
        "    ttid, tsid = tokenizer.encode(text, max_len=256)\n",
        "    train_token_indices.append(ttid)\n",
        "    train_segment_ids.append(tsid)\n",
        "\n",
        "for text in test['Text'].values:\n",
        "    # tokenizer.encode() returns a sequence of token indices\n",
        "    # and a sequence of segment IDs. BERT expects both as input,\n",
        "    # even if the segments IDs are just all zeros (like here).\n",
        "    vtid, vsid = tokenizer.encode(text, max_len=256)\n",
        "    val_token_indices.append(vtid)\n",
        "    val_segment_ids.append(vsid)\n",
        "\n",
        "# Format input as list of two numpy arrays\n",
        "train_X = [np.array(train_token_indices), np.array(train_segment_ids)]\n",
        "val_X = [np.array(val_token_indices), np.array(val_segment_ids)]\n",
        "\n",
        "\n",
        "# Print some examples\n",
        "# print('Token indices:')\n",
        "# print(val_X[0][:2])\n",
        "# print('Decoded:')\n",
        "# for i in val_X[0][:2]:\n",
        "#     print(tokenizer.decode(list(i)))\n",
        "# print('Segment ids:')\n",
        "# print(val_X[1][:2])\n",
        "# print()\n",
        "# print()\n",
        "\n",
        "# print('Token indices:')\n",
        "# print(train_X[0][:2])\n",
        "# print('Decoded:')\n",
        "# for i in train_X[0][:2]:\n",
        "#     print(tokenizer.decode(list(i)))\n",
        "# print('Segment ids:')\n",
        "# print(train_X[1][:2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmsFq5DGK_0B"
      },
      "source": [
        "from keras_bert import load_trained_model_from_checkpoint\n",
        "\n",
        "\n",
        "pretrained_model = load_trained_model_from_checkpoint(\n",
        "    config_file = bert_config_path,\n",
        "    checkpoint_file = bert_checkpoint_path,\n",
        "    training = False,\n",
        "    trainable = True,\n",
        "    seq_len = 256\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mesq8_g4NDkf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1870c3e8-3fc7-40ca-ff11-afa94fb011f5"
      },
      "source": [
        "# This is a keras model, so we can figure out what inputs it takes like so:\n",
        "pretrained_model.inputs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor 'Input-Token:0' shape=(None, 256) dtype=float32>,\n",
              " <tf.Tensor 'Input-Segment:0' shape=(None, 256) dtype=float32>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0VHp67RNOm5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bb938a3-6052-4ad7-a018-2b9699966194"
      },
      "source": [
        "# And similarly for outputs:\n",
        "pretrained_model.outputs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor 'Encoder-12-FeedForward-Norm/add_1:0' shape=(None, 256, 768) dtype=float32>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DP5YmQQhNQ5j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df569c8a-5ce4-4318-e8d5-fd82c3e9ea07"
      },
      "source": [
        "#@title Default title text\n",
        "\n",
        "pretrained_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "Input-Token (InputLayer)        [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Input-Segment (InputLayer)      [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Token (TokenEmbedding [(None, 256, 768), ( 22268928    Input-Token[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Segment (Embedding)   (None, 256, 768)     1536        Input-Segment[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Token-Segment (Add)   (None, 256, 768)     0           Embedding-Token[0][0]            \n",
            "                                                                 Embedding-Segment[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Position (PositionEmb (None, 256, 768)     196608      Embedding-Token-Segment[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Dropout (Dropout)     (None, 256, 768)     0           Embedding-Position[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Norm (LayerNormalizat (None, 256, 768)     1536        Embedding-Dropout[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, 256, 768)     2362368     Embedding-Norm[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-1-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, 256, 768)     0           Embedding-Norm[0][0]             \n",
            "                                                                 Encoder-1-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-1-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-1-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-1-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-1-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-1-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-1-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, 256, 768)     2362368     Encoder-1-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-2-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-1-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-2-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-2-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-2-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-2-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-2-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-2-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-2-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttentio (None, 256, 768)     2362368     Encoder-2-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-3-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-2-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-3-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-3-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-3-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-3-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-3-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-3-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-3-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttentio (None, 256, 768)     2362368     Encoder-3-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-4-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-3-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-4-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-4-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-4-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-4-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-4-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-4-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-4-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttentio (None, 256, 768)     2362368     Encoder-4-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-5-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-4-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-5-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-5-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-5-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-5-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-5-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-5-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-5-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttentio (None, 256, 768)     2362368     Encoder-5-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-6-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-5-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-6-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-6-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-6-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-6-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-6-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-6-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-6-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttentio (None, 256, 768)     2362368     Encoder-6-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-7-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-6-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-7-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-7-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-7-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-7-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-7-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-7-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-7-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttentio (None, 256, 768)     2362368     Encoder-7-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-8-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-7-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-8-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-8-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-8-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-8-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-8-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-8-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-8-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttentio (None, 256, 768)     2362368     Encoder-8-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-9-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-8-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-9-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-9-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-9-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-9-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-9-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-9-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-9-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttenti (None, 256, 768)     2362368     Encoder-9-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttenti (None, 256, 768)     0           Encoder-10-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttenti (None, 256, 768)     0           Encoder-9-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-10-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttenti (None, 256, 768)     1536        Encoder-10-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward (FeedFor (None, 256, 768)     4722432     Encoder-10-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward-Dropout  (None, 256, 768)     0           Encoder-10-FeedForward[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward-Add (Add (None, 256, 768)     0           Encoder-10-MultiHeadSelfAttention\n",
            "                                                                 Encoder-10-FeedForward-Dropout[0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward-Norm (La (None, 256, 768)     1536        Encoder-10-FeedForward-Add[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttenti (None, 256, 768)     2362368     Encoder-10-FeedForward-Norm[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttenti (None, 256, 768)     0           Encoder-11-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttenti (None, 256, 768)     0           Encoder-10-FeedForward-Norm[0][0]\n",
            "                                                                 Encoder-11-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttenti (None, 256, 768)     1536        Encoder-11-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward (FeedFor (None, 256, 768)     4722432     Encoder-11-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward-Dropout  (None, 256, 768)     0           Encoder-11-FeedForward[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward-Add (Add (None, 256, 768)     0           Encoder-11-MultiHeadSelfAttention\n",
            "                                                                 Encoder-11-FeedForward-Dropout[0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward-Norm (La (None, 256, 768)     1536        Encoder-11-FeedForward-Add[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttenti (None, 256, 768)     2362368     Encoder-11-FeedForward-Norm[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttenti (None, 256, 768)     0           Encoder-12-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttenti (None, 256, 768)     0           Encoder-11-FeedForward-Norm[0][0]\n",
            "                                                                 Encoder-12-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttenti (None, 256, 768)     1536        Encoder-12-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward (FeedFor (None, 256, 768)     4722432     Encoder-12-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward-Dropout  (None, 256, 768)     0           Encoder-12-FeedForward[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward-Add (Add (None, 256, 768)     0           Encoder-12-MultiHeadSelfAttention\n",
            "                                                                 Encoder-12-FeedForward-Dropout[0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward-Norm (La (None, 256, 768)     1536        Encoder-12-FeedForward-Add[0][0] \n",
            "==================================================================================================\n",
            "Total params: 107,523,072\n",
            "Trainable params: 107,523,072\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXgeVGijNTqv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58f7dcb6-86ec-4780-9ea5-cbcbb15302dc"
      },
      "source": [
        "# model.outputs is a list, here with a single item. Here\n",
        "# pretrained_model.outputs[0] just grabs that item (the output tensor).\n",
        "# Indxing that tensor with [:,0] gives the first position in the sequence\n",
        "# for all elements in the batch (the `:`).\n",
        "bert_out = pretrained_model.outputs[0][:,0]\n",
        "\n",
        "print(bert_out)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"strided_slice:0\", shape=(None, 768), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G95iv8TBNWkl"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "#num_labels = 26\n",
        "\n",
        "dropout_layer = Dropout(.5, input_shape=(768,))(bert_out)\n",
        "out = Dense(26, activation='softmax')(dropout_layer)\n",
        "model = Model(\n",
        "    inputs=pretrained_model.inputs,\n",
        "    outputs=[out]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bbECF1KNZBs"
      },
      "source": [
        "from keras_bert import calc_train_steps, AdamWarmup\n",
        "\n",
        "\n",
        "# Calculate the number of steps for warmup\n",
        "total_steps, warmup_steps = calc_train_steps(\n",
        "    num_example=len(train['Text'].values),\n",
        "    batch_size=8,\n",
        "    epochs=3,\n",
        "    warmup_proportion=0.1,\n",
        ")\n",
        "\n",
        "optimizer = AdamWarmup(\n",
        "    total_steps,\n",
        "    warmup_steps,\n",
        "    lr=0.00002,\n",
        "    epsilon=1e-6,\n",
        "    weight_decay=0.01,\n",
        "    weight_decay_pattern=['embeddings', 'kernel', 'W1', 'W2', 'Wk', 'Wq', 'Wv', 'Wo']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjfiK3_ENep0"
      },
      "source": [
        "from keras.metrics import sparse_categorical_accuracy\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['sparse_categorical_accuracy']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zMAMj1_Nug0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f0e2f84-8eb9-4555-9e39-09d900cc3f80"
      },
      "source": [
        "Y = train['Label_enc'].values\n",
        "Y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, ..., 0, 9, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilam_ljSN0oq"
      },
      "source": [
        "val_y = val['Label_enc'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lt0O-n5XNhLb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d002f891-84ab-4c99-c00a-e35a08e949ba"
      },
      "source": [
        "# from tensorflow import keras\n",
        "# model = keras.models.load_model('/content/drive/My Drive/Colab Notebooks/assets')\n",
        "history = model.fit(\n",
        "    train_X,\n",
        "    Y,\n",
        "    epochs=3,\n",
        "    batch_size=8,\n",
        "    validation_data= (val_X,val_y)\n",
        "    \n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "2199/2199 [==============================] - 1034s 470ms/step - loss: 1.3520 - sparse_categorical_accuracy: 0.6242 - val_loss: 0.8408 - val_sparse_categorical_accuracy: 0.7516\n",
            "Epoch 2/3\n",
            "2199/2199 [==============================] - 1029s 468ms/step - loss: 0.6746 - sparse_categorical_accuracy: 0.8005 - val_loss: 0.7801 - val_sparse_categorical_accuracy: 0.7679\n",
            "Epoch 3/3\n",
            "2199/2199 [==============================] - 1028s 467ms/step - loss: 0.3877 - sparse_categorical_accuracy: 0.8845 - val_loss: 0.8544 - val_sparse_categorical_accuracy: 0.7697\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aG070qzMNjY8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba1b5b81-8c6d-415c-e0c9-e5d8eadc4432"
      },
      "source": [
        "train_X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[  101,  4723,  3284, ...,     0,     0,     0],\n",
              "        [  101,  1960,  1105, ...,  1211,  1552,   102],\n",
              "        [  101, 19641, 11984, ...,   146,   112,   102],\n",
              "        ...,\n",
              "        [  101, 20907,  2690, ...,   129,  1550,   102],\n",
              "        [  101, 11336, 24313, ...,     0,     0,     0],\n",
              "        [  101, 22449,  9241, ...,  1128,   112,   102]]),\n",
              " array([[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOt4yzkQOfqe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "b5071e99-7eb0-4d24-81a7-0da94149959d"
      },
      "source": [
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "def plot_history(history):\n",
        "    plt.plot(history.history['sparse_categorical_accuracy'],label=\"Training set accuracy\")\n",
        "    plt.plot(history.history['val_sparse_categorical_accuracy'],label=\"Validation set accuracy\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_history(history)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gla90dBFOko0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa12a68d-2de8-4a2e-97a7-6e9bca2bce27"
      },
      "source": [
        "model.evaluate(val_X,val_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "70/70 [==============================] - 14s 194ms/step - loss: 0.8544 - sparse_categorical_accuracy: 0.7697\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.854388415813446, 0.7696832418441772]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_v5db5FQOoMZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}