{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KerasBert_Imbalanced.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "aE1XoS5cQX_y",
        "outputId": "a2b555e4-f758-45aa-aba2-3a64173aef03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kekwzNl1nRPM"
      },
      "source": [
        "###**Package Setup**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ItjdKxEQygl",
        "outputId": "9ea045c5-29bd-45dc-de96-6f6c1a2d4766",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "!pip install keras-bert"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras-bert in /usr/local/lib/python3.6/dist-packages (0.86.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-bert) (1.18.5)\n",
            "Requirement already satisfied: Keras>=2.4.3 in /usr/local/lib/python3.6/dist-packages (from keras-bert) (2.4.3)\n",
            "Requirement already satisfied: keras-transformer>=0.38.0 in /usr/local/lib/python3.6/dist-packages (from keras-bert) (0.38.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.4.3->keras-bert) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.4.3->keras-bert) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.4.3->keras-bert) (3.13)\n",
            "Requirement already satisfied: keras-multi-head>=0.27.0 in /usr/local/lib/python3.6/dist-packages (from keras-transformer>=0.38.0->keras-bert) (0.27.0)\n",
            "Requirement already satisfied: keras-position-wise-feed-forward>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from keras-transformer>=0.38.0->keras-bert) (0.6.0)\n",
            "Requirement already satisfied: keras-embed-sim>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from keras-transformer>=0.38.0->keras-bert) (0.8.0)\n",
            "Requirement already satisfied: keras-layer-normalization>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from keras-transformer>=0.38.0->keras-bert) (0.14.0)\n",
            "Requirement already satisfied: keras-pos-embd>=0.11.0 in /usr/local/lib/python3.6/dist-packages (from keras-transformer>=0.38.0->keras-bert) (0.11.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->Keras>=2.4.3->keras-bert) (1.15.0)\n",
            "Requirement already satisfied: keras-self-attention==0.46.0 in /usr/local/lib/python3.6/dist-packages (from keras-multi-head>=0.27.0->keras-transformer>=0.38.0->keras-bert) (0.46.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PM8YtZhnbeS"
      },
      "source": [
        "###**Tensorflow Configuration**\n",
        "\n",
        "We setup an environment variable for keras-bert to use tensorflow.python.keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWulnnIaQ4Bf"
      },
      "source": [
        "import os\n",
        "os.environ['TF_KERAS'] = '1'    # Required to use tensorflow.python.keras with keras-bert"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-Jtw4gXQ7cD"
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bo-qH8PanyQA"
      },
      "source": [
        "###**Settingup GPU**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAAW4Lm1TFbJ",
        "outputId": "1d3bf651-8b4a-42c5-b125-699e99bc4600",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "    print('We will use the GPU:', device_name)\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "We will use the GPU: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hU1yUKKMoX96"
      },
      "source": [
        "###**Load Train and Test Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xH0vPA--TGQm"
      },
      "source": [
        "train = pd.read_csv('/content/drive/My Drive/Colab Notebooks/train_file.txt', sep='{}{}{}', engine = 'python')\n",
        "test = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/test_file.txt\", sep= '{}{}{}', engine = 'python')\n",
        "\n",
        "#from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, val =  train,test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coe-uY3mocHk"
      },
      "source": [
        "###**Download Pretrained BERT Model**\n",
        "Here I have downloaded the Large Cased trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgzJxqytZjrU",
        "outputId": "a696ebdd-8d7d-4fa5-cf39-400f1b090d34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Give -nc (--no-clobber) argument so that the file isn't downloaded multiple times \n",
        "!wget -nc https://storage.googleapis.com/bert_models/2018_10_18/cased_L-12_H-768_A-12.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File ‘cased_L-12_H-768_A-12.zip’ already there; not retrieving.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sq-OtNp0aCPr",
        "outputId": "d6787438-f55a-478b-ad88-5840568aebed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Give -n argument so that existing files aren't overwritten \n",
        "!unzip -n cased_L-12_H-768_A-12.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  cased_L-12_H-768_A-12.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paCYkVC3owew"
      },
      "source": [
        "- vocab.txt is a plain file listing vocabulary items \n",
        "- bert_config.json consists of model configuration in JSON format\n",
        "- bert_model.ckpt.* consists of model checkpoint data with pretrained weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mF5quhtaK4p"
      },
      "source": [
        "bert_vocab_path = 'cased_L-12_H-768_A-12/vocab.txt'\n",
        "bert_config_path = 'cased_L-12_H-768_A-12/bert_config.json'\n",
        "bert_checkpoint_path = 'cased_L-12_H-768_A-12/bert_model.ckpt'    # suffixes not required\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXMipkcbtp2D"
      },
      "source": [
        "Make sure if the model we downloaded was case sensitive or not"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtKAgmlsad8n"
      },
      "source": [
        "model_is_cased = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uT5ZlsK-tzCi"
      },
      "source": [
        "Shuffle the data to avoid bias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_waBxcuVp_AY",
        "outputId": "59f3d883-cc5b-4e75-830f-8f5661c6347d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "\n",
        "train = shuffle(train)\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6416</th>\n",
              "      <td>__label__ne</td>\n",
              "      <td>\"Peter Hustinx, EDPS, says: \"Cloud computing c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3711</th>\n",
              "      <td>__label__ne</td>\n",
              "      <td>Austrian village wants to change name from cur...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7235</th>\n",
              "      <td>__label__pb</td>\n",
              "      <td>.  Thursday, October 27, 2011  I didn't think ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4103</th>\n",
              "      <td>__label__ne</td>\n",
              "      <td>The couple who were red zoned twice  GUTTED: A...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7401</th>\n",
              "      <td>__label__pb</td>\n",
              "      <td>I'm a PhD dropout, and I'm not ashamed to admi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Label                                               Text\n",
              "6416  __label__ne  \"Peter Hustinx, EDPS, says: \"Cloud computing c...\n",
              "3711  __label__ne  Austrian village wants to change name from cur...\n",
              "7235  __label__pb  .  Thursday, October 27, 2011  I didn't think ...\n",
              "4103  __label__ne  The couple who were red zoned twice  GUTTED: A...\n",
              "7401  __label__pb  I'm a PhD dropout, and I'm not ashamed to admi..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJjgZSoSt2hv"
      },
      "source": [
        "###**Load BERT Vocabulary**\n",
        "A plain text file with one vocabulary item per line"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEoG07Iiak7R",
        "outputId": "37bbc5fe-b407-44cf-a653-68f667364cb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "vocab = []\n",
        "with open(bert_vocab_path) as f:\n",
        "    for i, line in enumerate(f):\n",
        "        vocab.append(line.rstrip('\\n'))    # rstrip to remove newline characters\n",
        "\n",
        "\n",
        "# Print a list with every 500th vocabulary item\n",
        "print(vocab[0::500])\n",
        "print(len(vocab))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[PAD]', 'щ', '吉', 'told', 'space', 'operations', 'proposed', 'Oxford', 'showing', 'domestic', 'mountains', 'commission', 'voices', 'associate', 'hills', 'Guide', 'relaxed', 'Page', 'Heights', 'singers', 'Interior', 'considers', 'facilitate', 'shouting', '1826', 'constitute', 'alter', 'clip', 'Into', 'Memory', 'ballad', 'Owens', 'Langdon', 'aquatic', 'stereo', 'Cass', 'Shock', '195', '##tec', '##sonic', 'attested', '##rdes', '1840s', '##90', 'Guys', '##rien', 'Munro', 'Ursula', 'mesh', 'diplomacy', 'Newmarket', '##oughs', 'synthesizers', 'Drugs', 'monstrous', '##ynamic', 'troll', '##ٹ']\n",
            "28996\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZG2VctbAu9Ws"
      },
      "source": [
        "###**Load BERT Configuration File**\n",
        "The configuration is just a json file so we use json.load from python json library. We wont actually need to use these configuration details directly (keras-bert takes care of them for us). Lets see what information is contained in the config file. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e83kWLoDaxs1",
        "outputId": "ac956212-b0e4-4a8a-9469-ee13a190c724",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "from pprint import pprint    # pretty-printer for output\n",
        "import json\n",
        "\n",
        "with open(bert_config_path) as f:\n",
        "    config = json.load(f)\n",
        "\n",
        "\n",
        "# Print configuration contents\n",
        "pprint(config)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'attention_probs_dropout_prob': 0.1,\n",
            " 'hidden_act': 'gelu',\n",
            " 'hidden_dropout_prob': 0.1,\n",
            " 'hidden_size': 768,\n",
            " 'initializer_range': 0.02,\n",
            " 'intermediate_size': 3072,\n",
            " 'max_position_embeddings': 512,\n",
            " 'num_attention_heads': 12,\n",
            " 'num_hidden_layers': 12,\n",
            " 'type_vocab_size': 2,\n",
            " 'vocab_size': 28996}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbFHGVfOwRhP"
      },
      "source": [
        "###**Create BERT Tokenizer**\n",
        "\n",
        "To create the tokenizer, we'll need mapping from vocabulary items to their integer indices. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-DF4OVhbIoV",
        "outputId": "65bad388-14bc-4e5e-d0fe-2a9d80fb1bac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "import random\n",
        "# Create mapping from vocabulary items to their indices in the vocabulary\n",
        "token_dict = { v: i for i, v in enumerate(vocab) }\n",
        "\n",
        "\n",
        "# Print some random examples of the mapping\n",
        "pprint(dict(random.choices(list(token_dict.items()), k=10)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'##grounds': 26171,\n",
            " '##phy': 22192,\n",
            " 'Editorial': 23640,\n",
            " 'Market': 6923,\n",
            " 'citizenship': 9709,\n",
            " 'earl': 26593,\n",
            " 'hemisphere': 24114,\n",
            " 'prince': 6927,\n",
            " 'record': 1647,\n",
            " 'spreads': 23237}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6V1LA4AhyfJL"
      },
      "source": [
        "We'll use the keras-bert Tokenizer for BERT tokenization. The implementation supports\n",
        "\n",
        "- (Optional) lowercasing: Hello → hello\n",
        "- Basic tokenization: Hello! → Hello !, multi-part → multi - part\n",
        "- Wordpiece tokenization: comprehensively → comprehensive ##ly\n",
        "- Adding special tokens: Sentence → [CLS] Sentence [SEP]\n",
        "- Mapping to integer indices\n",
        "- Generating segment sequence\n",
        "- (Optional) padding and truncation to length\n",
        "\n",
        "In the following example, notice how words not in the dictionary are broken up into subwords (with continuation parts starting with ##) and how unknown characters are mapped to a special unknown word token [UNK].\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXCre_XJbn3U",
        "outputId": "96b42bea-6806-4390-cab4-f32ca5413f64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "from keras_bert import Tokenizer\n",
        "\n",
        "\n",
        "tokenizer = Tokenizer(token_dict, cased=model_is_cased)\n",
        "\n",
        "\n",
        "# Let's test that out\n",
        "for s in ['Hello BERT!', 'Unknown: unknown 你']:\n",
        "    print('Original string:', s)\n",
        "    print('Tokenized:', tokenizer.tokenize(s))\n",
        "    indices, segments = tokenizer.encode(s, max_len=20)    # max_len for padding and truncation\n",
        "    print('Encoded:', indices)\n",
        "    print('Segments:', segments)\n",
        "    print('Decoded:', ' '.join(tokenizer.decode(indices)))\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original string: Hello BERT!\n",
            "Tokenized: ['[CLS]', 'Hello', 'B', '##ER', '##T', '!', '[SEP]']\n",
            "Encoded: [101, 8667, 139, 9637, 1942, 106, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Segments: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Decoded: Hello B ##ER ##T !\n",
            "\n",
            "Original string: Unknown: unknown 你\n",
            "Tokenized: ['[CLS]', 'Unknown', ':', 'unknown', '你', '[SEP]']\n",
            "Encoded: [101, 16285, 131, 3655, 100, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Segments: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Decoded: Unknown : unknown [UNK]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opoaePkghOxv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jU6VNxAag9MG"
      },
      "source": [
        "# max_le = 0\n",
        "# i = 0\n",
        "# for i, document in enumerate (train['Text'].values):\n",
        "#   tokenized = tokenizer.tokenize(document)\n",
        "#   document_length = len(tokenized)\n",
        "\n",
        "#   if document_length > max_le:\n",
        "\n",
        "#     max_le = document_length\n",
        "#     i = i\n",
        "\n",
        "# print(max)\n",
        "# print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJa3IR_qmduv",
        "outputId": "9d128418-9bed-425c-aa52-bd5b85b4d299",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#print(train['Text'].values[17587])\n",
        "len(tokenizer.tokenize(train['Text'].values[17587]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1297"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3x_dewNeAA4",
        "outputId": "f2ab0f2c-abf7-4776-85f3-832143f51027",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "train.head()\n",
        "train['Label'].values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['__label__ne', '__label__ne', '__label__pb', ..., '__label__ne',\n",
              "       '__label__rv', '__label__ne'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljYGSct308Tk"
      },
      "source": [
        "###**Vectorize data**\n",
        "We'll use the  LabelEncoder for labels and the keras-bert Tokenizer for text data. Y is the representation of the labels that will be given to the model for training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blKQQb4abuxB",
        "outputId": "ddc780c4-5bd9-4fdf-ecd1-f480c69b8b68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "labels =train['Label'].values\n",
        "label_encoder = LabelEncoder()    # Turns class labels into integers\n",
        "Y = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Take note of how many unique labels there are in the data\n",
        "num_labels = len(set(Y))\n",
        "\n",
        "\n",
        "# Print out some examples\n",
        "print('Number of unique labels:', num_labels)\n",
        "print(type(labels), labels[:10])\n",
        "print(type(Y), Y[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of unique labels: 26\n",
            "<class 'numpy.ndarray'> ['__label__ne' '__label__ne' '__label__pb' '__label__ne' '__label__pb'\n",
            " '__label__dt' '__label__dt' '__label__sr' '__label__rv' '__label__ha']\n",
            "<class 'numpy.ndarray'> [12 12 14 12 14  4  4 22 20  8]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RT-ni8dp7Nk"
      },
      "source": [
        "y_val = label_encoder.fit_transform(test['Label'].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2EtoHqs6Fpy"
      },
      "source": [
        "Keep token indices and segment ids in separate lists and store as numpy arrays. X here is the final vectorized form of the input we'll be providing to the model for training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJU1bDLpe-dj"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "train_token_indices, train_segment_ids = [], []  #bert tokenizer indices and their segment ids  (to separate sequences)\n",
        "val_token_indices, val_segment_ids = [], []\n",
        "for text in train['Text'].values:\n",
        "    # tokenizer.encode() returns a sequence of token indices\n",
        "    # and a sequence of segment IDs. BERT expects both as input,\n",
        "    # even if the segments IDs are just all zeros (like here).\n",
        "    ttid, tsid = tokenizer.encode(text, max_len=256)\n",
        "    train_token_indices.append(ttid)\n",
        "    train_segment_ids.append(tsid)\n",
        "\n",
        "for text in test['Text'].values:\n",
        "    # tokenizer.encode() returns a sequence of token indices\n",
        "    # and a sequence of segment IDs. BERT expects both as input,\n",
        "    # even if the segments IDs are just all zeros (like here).\n",
        "    vtid, vsid = tokenizer.encode(text, max_len=256)\n",
        "    val_token_indices.append(vtid)\n",
        "    val_segment_ids.append(vsid)\n",
        "\n",
        "# Format input as list of two numpy arrays\n",
        "train_X = [np.array(train_token_indices), np.array(train_segment_ids)]\n",
        "val_X = [np.array(val_token_indices), np.array(val_segment_ids)]\n",
        "\n",
        "\n",
        "# Print some examples\n",
        "# print('Token indices:')\n",
        "# print(val_X[0][:2])\n",
        "# print('Decoded:')\n",
        "# for i in val_X[0][:2]:\n",
        "#     print(tokenizer.decode(list(i)))\n",
        "# print('Segment ids:')\n",
        "# print(val_X[1][:2])\n",
        "# print()\n",
        "# print()\n",
        "\n",
        "# print('Token indices:')\n",
        "# print(train_X[0][:2])\n",
        "# print('Decoded:')\n",
        "# for i in train_X[0][:2]:\n",
        "#     print(tokenizer.decode(list(i)))\n",
        "# print('Segment ids:')\n",
        "# print(train_X[1][:2])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_VwBzKMkbZz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TB3kFmUMTIu5"
      },
      "source": [
        "# label_encode = {}\n",
        "# for i, v  in enumerate(train['Label'].unique()):\n",
        "#   label_encode[v] = i\n",
        "# label_encode"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ah3JpbduTLIp"
      },
      "source": [
        "# train['Label_enc'] = train['Label'].map(label_encode)\n",
        "# val['Label_enc'] = val['Label'].map(label_encode)\n",
        "# val.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLnoTuuuThu2"
      },
      "source": [
        "from keras_bert import load_trained_model_from_checkpoint\n",
        "\n",
        "\n",
        "pretrained_model = load_trained_model_from_checkpoint(\n",
        "    config_file = bert_config_path,\n",
        "    checkpoint_file = bert_checkpoint_path,\n",
        "    training = False,\n",
        "    trainable = True,\n",
        "    seq_len = 256\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReHBEkTVqhqR",
        "outputId": "0630ce5e-7d51-43d0-927c-645f1c700ec5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# This is a keras model, so we can figure out what inputs it takes like so:\n",
        "pretrained_model.inputs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor 'Input-Token_1:0' shape=(None, 256) dtype=float32>,\n",
              " <tf.Tensor 'Input-Segment_1:0' shape=(None, 256) dtype=float32>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IL4f_2NWryRb",
        "outputId": "530cae23-2909-40e9-f433-69ed9354c731",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# And similarly for outputs:\n",
        "pretrained_model.outputs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor 'Encoder-12-FeedForward-Norm/add_3:0' shape=(None, 256, 768) dtype=float32>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrze7NjAr6Sk",
        "outputId": "2c9dc983-e6b6-4de1-81e6-ef77bc6139a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#@title Default title text\n",
        "\n",
        "pretrained_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_9\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "Input-Token (InputLayer)        [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Input-Segment (InputLayer)      [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Token (TokenEmbedding [(None, 256, 768), ( 22268928    Input-Token[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Segment (Embedding)   (None, 256, 768)     1536        Input-Segment[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Token-Segment (Add)   (None, 256, 768)     0           Embedding-Token[0][0]            \n",
            "                                                                 Embedding-Segment[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Position (PositionEmb (None, 256, 768)     196608      Embedding-Token-Segment[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Dropout (Dropout)     (None, 256, 768)     0           Embedding-Position[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Norm (LayerNormalizat (None, 256, 768)     1536        Embedding-Dropout[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, 256, 768)     2362368     Embedding-Norm[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-1-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, 256, 768)     0           Embedding-Norm[0][0]             \n",
            "                                                                 Encoder-1-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-1-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-1-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-1-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-1-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-1-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-1-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, 256, 768)     2362368     Encoder-1-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-2-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-1-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-2-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-2-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-2-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-2-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-2-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-2-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-2-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttentio (None, 256, 768)     2362368     Encoder-2-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-3-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-2-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-3-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-3-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-3-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-3-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-3-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-3-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-3-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttentio (None, 256, 768)     2362368     Encoder-3-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-4-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-3-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-4-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-4-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-4-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-4-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-4-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-4-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-4-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttentio (None, 256, 768)     2362368     Encoder-4-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-5-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-4-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-5-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-5-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-5-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-5-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-5-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-5-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-5-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttentio (None, 256, 768)     2362368     Encoder-5-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-6-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-5-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-6-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-6-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-6-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-6-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-6-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-6-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-6-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttentio (None, 256, 768)     2362368     Encoder-6-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-7-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-6-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-7-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-7-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-7-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-7-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-7-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-7-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-7-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttentio (None, 256, 768)     2362368     Encoder-7-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-8-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-7-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-8-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-8-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-8-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-8-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-8-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-8-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-8-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttentio (None, 256, 768)     2362368     Encoder-8-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-9-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-8-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-9-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-9-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-9-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-9-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-9-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-9-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-9-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttenti (None, 256, 768)     2362368     Encoder-9-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttenti (None, 256, 768)     0           Encoder-10-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttenti (None, 256, 768)     0           Encoder-9-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-10-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttenti (None, 256, 768)     1536        Encoder-10-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward (FeedFor (None, 256, 768)     4722432     Encoder-10-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward-Dropout  (None, 256, 768)     0           Encoder-10-FeedForward[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward-Add (Add (None, 256, 768)     0           Encoder-10-MultiHeadSelfAttention\n",
            "                                                                 Encoder-10-FeedForward-Dropout[0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward-Norm (La (None, 256, 768)     1536        Encoder-10-FeedForward-Add[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttenti (None, 256, 768)     2362368     Encoder-10-FeedForward-Norm[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttenti (None, 256, 768)     0           Encoder-11-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttenti (None, 256, 768)     0           Encoder-10-FeedForward-Norm[0][0]\n",
            "                                                                 Encoder-11-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttenti (None, 256, 768)     1536        Encoder-11-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward (FeedFor (None, 256, 768)     4722432     Encoder-11-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward-Dropout  (None, 256, 768)     0           Encoder-11-FeedForward[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward-Add (Add (None, 256, 768)     0           Encoder-11-MultiHeadSelfAttention\n",
            "                                                                 Encoder-11-FeedForward-Dropout[0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward-Norm (La (None, 256, 768)     1536        Encoder-11-FeedForward-Add[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttenti (None, 256, 768)     2362368     Encoder-11-FeedForward-Norm[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttenti (None, 256, 768)     0           Encoder-12-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttenti (None, 256, 768)     0           Encoder-11-FeedForward-Norm[0][0]\n",
            "                                                                 Encoder-12-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttenti (None, 256, 768)     1536        Encoder-12-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward (FeedFor (None, 256, 768)     4722432     Encoder-12-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward-Dropout  (None, 256, 768)     0           Encoder-12-FeedForward[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward-Add (Add (None, 256, 768)     0           Encoder-12-MultiHeadSelfAttention\n",
            "                                                                 Encoder-12-FeedForward-Dropout[0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward-Norm (La (None, 256, 768)     1536        Encoder-12-FeedForward-Add[0][0] \n",
            "==================================================================================================\n",
            "Total params: 107,523,072\n",
            "Trainable params: 107,523,072\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfxKioB9r8Hw",
        "outputId": "8da5985f-e2a0-487c-be39-49e2ca965363",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# model.outputs is a list, here with a single item. Here\n",
        "# pretrained_model.outputs[0] just grabs that item (the output tensor).\n",
        "# Indxing that tensor with [:,0] gives the first position in the sequence\n",
        "# for all elements in the batch (the `:`).\n",
        "bert_out = pretrained_model.outputs[0][:,0]\n",
        "\n",
        "print(bert_out)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"strided_slice_1:0\", shape=(None, 768), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jp83FyiJsHcK"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "#num_labels = 26\n",
        "\n",
        "dropout_layer = Dropout(.5, input_shape=(768,))(bert_out)\n",
        "out = Dense(num_labels, activation='softmax')(dropout_layer)\n",
        "model = Model(\n",
        "    inputs=pretrained_model.inputs,\n",
        "    outputs=[out]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aJC9vjFsP-T"
      },
      "source": [
        "from keras_bert import calc_train_steps, AdamWarmup\n",
        "\n",
        "\n",
        "# Calculate the number of steps for warmup\n",
        "total_steps, warmup_steps = calc_train_steps(\n",
        "    num_example=len(train['Text'].values),\n",
        "    batch_size=8,\n",
        "    epochs=3,\n",
        "    warmup_proportion=0.1,\n",
        ")\n",
        "\n",
        "optimizer = AdamWarmup(\n",
        "    total_steps,\n",
        "    warmup_steps,\n",
        "    lr=0.00002,\n",
        "    epsilon=1e-6,\n",
        "    weight_decay=0.01,\n",
        "    weight_decay_pattern=['embeddings', 'kernel', 'W1', 'W2', 'Wk', 'Wq', 'Wv', 'Wo']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78kOPfdnsSUc"
      },
      "source": [
        "from keras.metrics import sparse_categorical_accuracy\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['sparse_categorical_accuracy']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9Kx_porspDi",
        "outputId": "9c9b16ca-183a-4f0e-9875-1f6703725d3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "# from tensorflow import keras\n",
        "# model = keras.models.load_model('/content/drive/My Drive/Colab Notebooks/assets')\n",
        "history = model.fit(\n",
        "    train_X,\n",
        "    Y,\n",
        "    epochs=3,\n",
        "    batch_size=8,\n",
        "    validation_data= (val_X,y_val)\n",
        "    \n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "2199/2199 [==============================] - 1761s 801ms/step - loss: 1.4084 - sparse_categorical_accuracy: 0.6091 - val_loss: 0.9177 - val_sparse_categorical_accuracy: 0.7344\n",
            "Epoch 2/3\n",
            "2199/2199 [==============================] - 1749s 795ms/step - loss: 0.6884 - sparse_categorical_accuracy: 0.7948 - val_loss: 0.8140 - val_sparse_categorical_accuracy: 0.7670\n",
            "Epoch 3/3\n",
            "2199/2199 [==============================] - 1744s 793ms/step - loss: 0.4038 - sparse_categorical_accuracy: 0.8764 - val_loss: 0.8591 - val_sparse_categorical_accuracy: 0.7683\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwJJ1f6UrhQW",
        "outputId": "810b7b1b-cc9a-412e-cf30-69d0bfdce52f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "train_X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[  101,   107,  1943, ...,   131,  3341,   102],\n",
              "        [  101,  5488,  1491, ...,  1186,   117,   102],\n",
              "        [  101,   119,  9170, ...,  1146,   117,   102],\n",
              "        ...,\n",
              "        [  101, 18911,   143, ...,     0,     0,     0],\n",
              "        [  101,   139, 13791, ...,     0,     0,     0],\n",
              "        [  101,  1109, 14901, ..., 12636,  1107,   102]]),\n",
              " array([[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vu6WlILP4gTT"
      },
      "source": [
        "# os.chdir('/content/drive/My Drive/Colab Notebooks/')\n",
        "# os.getcwd()\n",
        "# !ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClYwkNhXsrkT"
      },
      "source": [
        "# #!pip install numba \n",
        "# from numba import cuda \n",
        "# device = cuda.get_current_device()\n",
        "# device.reset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Bf51wMa1LKJ",
        "outputId": "853eabc8-6c59-43af-a0d4-81228869e2b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "def plot_history(history):\n",
        "    plt.plot(history.history['sparse_categorical_accuracy'],label=\"Training set accuracy\")\n",
        "    plt.plot(history.history['val_sparse_categorical_accuracy'],label=\"Validation set accuracy\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_history(history)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEBKh6ozF86b",
        "outputId": "7d4dedc2-05fe-47f4-b647-9ef23bc592a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "model.evaluate(val_X,y_val)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "70/70 [==============================] - 44s 631ms/step - loss: 0.8591 - sparse_categorical_accuracy: 0.7683\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.85907381772995, 0.7683258056640625]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMWZUWYpvjj2",
        "outputId": "18423b7e-1a00-4556-aed7-e25fa3e69bc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "val_X[:2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[  101,  2066,  1330, ...,     0,     0,     0],\n",
              "        [  101,  2009,  2033, ...,  2638,  2231,   102],\n",
              "        [  101,  1332,  1234, ...,  8658,  1103,   102],\n",
              "        ...,\n",
              "        [  101, 21300,  1447, ...,  1234, 14884,   102],\n",
              "        [  101,  7993,  1240, ...,   146,  5782,   102],\n",
              "        [  101,  1188,  3674, ...,  1234,  1132,   102]]),\n",
              " array([[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lsVnnUzlgu5",
        "outputId": "bbbeb9af-b5b8-409d-8af1-8a827e4827e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        }
      },
      "source": [
        "a = model.predict([val_X[0][:5], val_X[1][:5]])\n",
        "a"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6.35013869e-03, 7.43028359e-04, 2.95069447e-04, 2.13022646e-03,\n",
              "        2.69028284e-02, 4.15252987e-04, 8.92208598e-04, 2.31711473e-03,\n",
              "        8.88575451e-04, 5.53901133e-04, 9.15635973e-02, 3.21498315e-04,\n",
              "        8.73713419e-02, 7.58864224e-01, 5.24825591e-04, 2.70262070e-04,\n",
              "        1.40699558e-03, 1.61204673e-02, 5.67743191e-05, 1.18046463e-03,\n",
              "        1.32986563e-04, 1.21679361e-04, 1.84957986e-04, 1.04647865e-04,\n",
              "        1.70789208e-04, 1.16137817e-04],\n",
              "       [7.35810725e-04, 2.80287117e-04, 1.19243421e-04, 5.82341600e-05,\n",
              "        3.21633765e-04, 1.85329773e-05, 1.20621058e-04, 9.26440407e-05,\n",
              "        9.85503430e-05, 5.34146166e-05, 6.88996213e-03, 1.79540017e-04,\n",
              "        6.75254986e-02, 9.22498703e-01, 1.22425845e-04, 5.88784787e-05,\n",
              "        2.89185758e-04, 3.56948498e-04, 5.46468755e-06, 6.77579155e-05,\n",
              "        1.44551523e-05, 1.15960484e-05, 4.33637433e-05, 9.39358779e-06,\n",
              "        1.68542992e-05, 1.10822830e-05],\n",
              "       [6.04250841e-03, 6.85084760e-01, 7.13663350e-04, 4.85074881e-04,\n",
              "        3.83020379e-03, 1.53173169e-03, 1.07400236e-03, 8.92708835e-04,\n",
              "        6.87452964e-04, 1.40863413e-03, 1.61283358e-03, 5.00630122e-04,\n",
              "        8.61611888e-02, 1.00180462e-01, 6.15869823e-04, 1.93423696e-03,\n",
              "        9.67160687e-02, 3.03317414e-04, 2.06866782e-04, 2.15393398e-03,\n",
              "        1.21588913e-04, 4.85381437e-03, 1.16273121e-03, 6.69220753e-04,\n",
              "        2.35017185e-04, 8.21450725e-04],\n",
              "       [2.20565678e-04, 4.29526590e-05, 4.83161930e-05, 3.58641701e-05,\n",
              "        4.74545930e-04, 6.37743642e-06, 2.22988328e-05, 2.27333570e-04,\n",
              "        9.99575859e-05, 1.95028606e-05, 1.26103498e-03, 2.44228831e-05,\n",
              "        3.59328859e-03, 9.92911160e-01, 5.28122007e-04, 6.20517094e-05,\n",
              "        4.16281655e-05, 3.66333479e-05, 1.39576723e-05, 1.87542784e-04,\n",
              "        4.30431210e-05, 8.18480021e-06, 2.51456004e-05, 4.80866220e-05,\n",
              "        1.41367673e-05, 3.81012114e-06],\n",
              "       [3.14106670e-04, 3.75732174e-03, 2.15242311e-04, 7.92442515e-05,\n",
              "        2.37154745e-04, 5.06511606e-05, 1.43104684e-04, 2.56575411e-04,\n",
              "        1.06934924e-04, 6.69440124e-05, 1.07675756e-03, 6.62880426e-04,\n",
              "        2.28886634e-01, 7.61332095e-01, 3.55781027e-04, 6.51695009e-05,\n",
              "        1.47884770e-03, 1.92123567e-04, 3.23702770e-05, 3.07022710e-04,\n",
              "        6.17568148e-05, 1.87366240e-05, 1.42164601e-04, 4.81625357e-05,\n",
              "        4.78218353e-05, 6.44675893e-05]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vl4GkiMwuhHj",
        "outputId": "1d60b874-6a2f-4cfd-e377-8cf04f113a53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a.argmax(axis = 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([13, 13,  1, 13, 13])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdpozPAeyWD6",
        "outputId": "538f20c9-5e16-420b-8945-0feb7a31bcc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_val[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([13, 13, 13, 13, 13])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeDyC9jxzdH4",
        "outputId": "f4aae961-e01e-41a9-81f2-83361a903898",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        }
      },
      "source": [
        "\n",
        "[val_X[0][1], val_X[1][1]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([  101,  2009,  2033, 16646,  1154,  5463,  5448,  2144,   112,\n",
              "          189,  5194,  1146,  1109,  1433,  1110,  1268,  1106,  6043,\n",
              "         5463,  2557,   136,   118,   118,   136,  1256,  1343,  1576,\n",
              "         1118, 18943,   155,  2042, 11429,   136,   118,   118,   136,\n",
              "         1106,  6268,  2880,  3239,  1111, 17217,  1415,  3203,   119,\n",
              "         1252,  1136,  1272,  1175,   112,   188,  1199,  3501,  2463,\n",
              "         1114,  1925,  3239,  1781,  5463,  5448,   119,  2809,  1314,\n",
              "         1989,  6314,  1108,   171, 20219,  1158,  1164,  1103,  1884,\n",
              "        20831,  1348,  1544,   118, 27005,  8876, 15826,  1104,  5151,\n",
              "         1909,  1154,  1103,  3979,  2380,   113,  8267,  1543,   170,\n",
              "        14660,  5075,  1104,  3270, 15176,   112,   188,  4892, 22669,\n",
              "         1115,  1103,  3641,  1156,  7031,  1103,  2380,   114,   117,\n",
              "         1133,  1115, 15826,  2947,  8251,  1191,  1175,  4597,   112,\n",
              "          189, 26620, 10715,  3239,  1907,  1106,  3076,  1105,  1173,\n",
              "         1576,  3203,   119,  1109,  3501,  3779, 21374,   136,   118,\n",
              "          118,   136,  2693,  2501,  3736,  1216,  1112,  4111,  5638,\n",
              "         1105,  1795, 13724,  1116,  1515,  1151,  1113,  1103,  7358,\n",
              "        19714,  1990,  1111,  1103,  2592,  1118,  4926,  4823,  1115,\n",
              "         1521,  1106,  1103,  4544,  1104,  9892, 12107, 18353, 11225,\n",
              "          136,   118,   118,   136,  1110,  1115, 16646,  1132,  3764,\n",
              "         1149,  1113,  5448,   117,  2521,  1343, 13577,  1118,  8354,\n",
              "         1116, 12759,  5863,   119,  1252,  1103,  2463,  1110,  1175,\n",
              "         4597,   112,   189,  1115,  1242, 10715, 16646,  1702,  1111,\n",
              "         5448,   119,  4823,   112,   188, 10301,  1110,  1115,  1103,\n",
              "         3979,  4291,  1547,  1129,  3164,   117,  1288, 19288, 21159,\n",
              "         1603,  1118,  1410,   119,   160, 18649,   117,  1549,  1103,\n",
              "         2450,  1104,  5463,  2380,  5448,   117,  1122,  2228,  1376,\n",
              "         2670,  2305,  1106,  7568,  1234,  1121,  1558,  9335,  1107,\n",
              "         1103,  2638,  2231,   102]),\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1W4hmuHzpZ8",
        "outputId": "e09b7658-cd8b-4a1c-9134-bfa3611c33e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "source": [
        "from sklearn import metrics\n",
        "matrix = metrics.confusion_matrix(y_val, y_pred=)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AxisError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-86-dfac7cae8d02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8QOtgNRtZxf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}