{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "BERT_HuggingFace.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ae824e242b82499387acf8c8fb54c478": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9ece846a6ebb4001a6054456b25ea0a5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8cef1460b26c4fb0ad85323cc421a336",
              "IPY_MODEL_068315e1ded34ec7b1ef9d1142bf984b"
            ]
          }
        },
        "9ece846a6ebb4001a6054456b25ea0a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8cef1460b26c4fb0ad85323cc421a336": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_554634678699492c8702a7b5fffbd84d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a4752cbc46f84395a9958054b99c5be6"
          }
        },
        "068315e1ded34ec7b1ef9d1142bf984b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_553772627ec240af9eb8345d2e53f781",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 627kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0a16bd938be6406ca96fc2e0528fbbbc"
          }
        },
        "554634678699492c8702a7b5fffbd84d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a4752cbc46f84395a9958054b99c5be6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "553772627ec240af9eb8345d2e53f781": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0a16bd938be6406ca96fc2e0528fbbbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b7c1062d1402433ba516b128a8c8c3bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e48bd79373764e55b0a2a8b8c3d6b67e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8d1f7168bebf47beafd18ec45a1c5334",
              "IPY_MODEL_6f55329118564b3792c04a67e5c7a9b2"
            ]
          }
        },
        "e48bd79373764e55b0a2a8b8c3d6b67e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8d1f7168bebf47beafd18ec45a1c5334": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_efc9df13de48461fa35f51d738aef169",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f1959cfe09b54243bbcc6a6474ef8f74"
          }
        },
        "6f55329118564b3792c04a67e5c7a9b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d2d0f178333d419bae81b8c113a598a4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 3.47kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cff91deaeb3f4bc69a950736fc72926c"
          }
        },
        "efc9df13de48461fa35f51d738aef169": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f1959cfe09b54243bbcc6a6474ef8f74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d2d0f178333d419bae81b8c113a598a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cff91deaeb3f4bc69a950736fc72926c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b863c4fc317847a898533ee76f357106": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d8dabc2be1c24c55acb477d9e1a07aec",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_eabe21a4c98840498e6efc26aa7e9483",
              "IPY_MODEL_2c755b19a07b4529b22f3a728faa845e"
            ]
          }
        },
        "d8dabc2be1c24c55acb477d9e1a07aec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eabe21a4c98840498e6efc26aa7e9483": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_759135d77825437788af32ad637e1bf0",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_50be2e9edb784384a7b251f2a36d5451"
          }
        },
        "2c755b19a07b4529b22f3a728faa845e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1f3b356e20694a158510ac83bfbaf6d9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:08&lt;00:00, 49.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2343e466de5d4c1ea3a4e82dfd8dd4c5"
          }
        },
        "759135d77825437788af32ad637e1bf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "50be2e9edb784384a7b251f2a36d5451": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1f3b356e20694a158510ac83bfbaf6d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2343e466de5d4c1ea3a4e82dfd8dd4c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTdoo4yF0z7E",
        "outputId": "42de0bb9-cbd6-49ab-b174-f2574a68ef6f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QV3aGrCp034m",
        "outputId": "9d98d1b4-98ce-4e0b-8bbc-6824775bb58a"
      },
      "source": [
        "!pip install torch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.7.0+cu101)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch) (0.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "7H-mEyAjQm-N",
        "outputId": "9e0be839-b37e-4274-afe9-aac2cdddc70d"
      },
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "torch.cuda.memory_summary(device=None, abbreviated=False)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Allocations           |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1VVKk67IWWn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMtL0ckQ5caX",
        "outputId": "d172f38f-40b1-43dd-d5ac-4a2331e1fe68"
      },
      "source": [
        "!pip install transformers==3.0.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==3.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/35/1c3f6e62d81f5f0daff1384e6d5e6c5758682a8357ebc765ece2b9def62b/transformers-3.0.0-py3-none-any.whl (754kB)\n",
            "\r\u001b[K     |▍                               | 10kB 21.6MB/s eta 0:00:01\r\u001b[K     |▉                               | 20kB 26.9MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30kB 26.7MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40kB 19.4MB/s eta 0:00:01\r\u001b[K     |██▏                             | 51kB 16.3MB/s eta 0:00:01\r\u001b[K     |██▋                             | 61kB 17.9MB/s eta 0:00:01\r\u001b[K     |███                             | 71kB 14.4MB/s eta 0:00:01\r\u001b[K     |███▌                            | 81kB 14.8MB/s eta 0:00:01\r\u001b[K     |████                            | 92kB 14.8MB/s eta 0:00:01\r\u001b[K     |████▍                           | 102kB 13.8MB/s eta 0:00:01\r\u001b[K     |████▊                           | 112kB 13.8MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 122kB 13.8MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 133kB 13.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 143kB 13.8MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 153kB 13.8MB/s eta 0:00:01\r\u001b[K     |███████                         | 163kB 13.8MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 174kB 13.8MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 184kB 13.8MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 194kB 13.8MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 204kB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 215kB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 225kB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 235kB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 245kB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 256kB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 266kB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 276kB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 286kB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 296kB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 307kB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 317kB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 327kB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 337kB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 348kB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 358kB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 368kB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 378kB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 389kB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 399kB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 409kB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 419kB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 430kB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 440kB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 450kB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 460kB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 471kB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 481kB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 491kB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 501kB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 512kB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 522kB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 532kB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 542kB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 552kB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 563kB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 573kB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 583kB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 593kB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 604kB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 614kB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 624kB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 634kB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 645kB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 655kB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 665kB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 675kB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 686kB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 696kB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 706kB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 716kB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 727kB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 737kB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 747kB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 757kB 13.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.0) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.0) (1.18.5)\n",
            "Collecting tokenizers==0.8.0-rc4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e8/bd/e5abec46af977c8a1375c1dca7cb1e5b3ec392ef279067af7f6bc50491a0/tokenizers-0.8.0rc4-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 33.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.0) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.0) (2019.12.20)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 60.0MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 56.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.0) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.0) (0.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.0) (20.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.0.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.0.0) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.0.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.0.0) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.0.0) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.0.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.0.0) (0.17.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.0.0) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=719635c925f83d3bfaccaa6221c23e8178d234a54d9ce976b3c724f5bc19ec65\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.94 tokenizers-0.8.0rc4 transformers-3.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ff2f8k6F2K_2"
      },
      "source": [
        "from transformers import XLNetConfig, XLNetTokenizer, XLNetForSequenceClassification\n",
        "from transformers import BertTokenizer, BertModel\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHOYS7rG5Zt8"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "train = pd.read_csv('/content/drive/My Drive/Colab Notebooks/train_file.txt', sep='{}{}{}', engine = 'python')\n",
        "test = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/test_file.txt\", sep= '{}{}{}', engine = 'python')\n",
        "devset = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/devset.txt\", sep= '{}{}{}', engine = 'python')\n",
        "#train_inputs, validation_inputs, train_labels, validation_labels = train_test_split()\n",
        "#from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, val =  train,test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "mC-mMsys_Ell",
        "outputId": "9aa87c7c-78e1-460b-a4f7-f6cc3d419362"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "\n",
        "train = shuffle(train)\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10064</th>\n",
              "      <td>__label__dt</td>\n",
              "      <td>Tiki  Description  The Tiki is not really an i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8195</th>\n",
              "      <td>__label__pb</td>\n",
              "      <td>On Monday 20 August, preparing to leave New Ze...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7631</th>\n",
              "      <td>__label__pb</td>\n",
              "      <td>My unforgettable Olympic experience  October 9...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5821</th>\n",
              "      <td>__label__ne</td>\n",
              "      <td>Netlore Archive: Forwarded email recounts the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5228</th>\n",
              "      <td>__label__ne</td>\n",
              "      <td>News  Dick Taylor of the Rolling Stones &amp; the ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Label                                               Text\n",
              "10064  __label__dt  Tiki  Description  The Tiki is not really an i...\n",
              "8195   __label__pb  On Monday 20 August, preparing to leave New Ze...\n",
              "7631   __label__pb  My unforgettable Olympic experience  October 9...\n",
              "5821   __label__ne  Netlore Archive: Forwarded email recounts the ...\n",
              "5228   __label__ne  News  Dick Taylor of the Rolling Stones & the ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKCkR8OkA-Gk",
        "outputId": "d7711007-4cab-41aa-860b-7f7580a72fb3"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "labels =train['Label'].values\n",
        "label_encoder = LabelEncoder()    # Turns class labels into integers\n",
        "Y = label_encoder.fit_transform(labels)\n",
        "labels_dev=devset['Label'].values\n",
        "\n",
        "# Take note of how many unique labels there are in the data\n",
        "num_labels = len(set(Y))\n",
        "\n",
        "\n",
        "# Print out some examples\n",
        "print('Number of unique labels:', num_labels)\n",
        "print(type(labels), labels[:10])\n",
        "print(type(Y), Y[:10])\n",
        "print('\\n')\n",
        "print(labels_dev[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of unique labels: 26\n",
            "<class 'numpy.ndarray'> ['__label__dt' '__label__pb' '__label__pb' '__label__ne' '__label__ne'\n",
            " '__label__ne' '__label__qa' '__label__ne' '__label__rv' '__label__ne']\n",
            "<class 'numpy.ndarray'> [ 4 14 14 12 12 12 16 12 20 12]\n",
            "\n",
            "\n",
            "['__label__ht' '__label__ht' '__label__ht' '__label__ht' '__label__ht'\n",
            " '__label__ht' '__label__ht' '__label__ht' '__label__ht' '__label__ht']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvJBt7MQRbNk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkzTNYewDAKN"
      },
      "source": [
        "Y_val = label_encoder.fit_transform(test['Label'].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bS64SQIKDEcD",
        "outputId": "471e32b4-52c2-47b7-971d-cdaa3338aaa1"
      },
      "source": [
        "Y_val"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([13, 13, 13, ...,  9,  9,  9])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "iRle8Oj3DHSC",
        "outputId": "395a33b3-3e89-4649-8475-6f408cdc43bf"
      },
      "source": [
        "\n",
        "# Get sentence data\n",
        "sents = train.Text.to_list()\n",
        "sents[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tiki  Description  The Tiki is not really an indicator (in the sense of moving averages ), but it can be used as an indicator when day trading. The Tiki is one of three market internals, with the Trin and Ticks being the other two. The Tiki compares the number of upticking (price increasing) and downticking (price decreasing) stocks in the Dow Jones Stock Index, and calculates a ratio showing whether there are more upticking or downticking stocks.  The Tiki is based upon the stocks that are included in the Dow Jones Stock Index, so it is primarily (actually almost exclusively) used as an indicator for the US markets, but the same principles and formulae can be applied to the European and Asian markets.  The Tiki can be displayed as a single line, or as a bar chart, but it is always displayed on its own chart, separate from the price bars.  Calculation  Description : The Tiki (T) is a comparison of the number of upticking and downticking stocks.  Calculation : T = Upticking Stocks - Downticking Stocks  Note that the calculation of the Tiki is exactly the same as the Ticks, so the only difference is that the Ticks includes all of the stocks that are traded on the NYSE, but the Tiki only includes the stocks that are part of the Dow Jones Stock Index.  Trading Use  The Tiki shows whether there are more individual stocks with increasing prices or decreasing prices, so it provides a detailed overview (detailed because it uses the individual stocks, and overview because it calculates a single value) of the sentiment of the markets. As the Tiki includes less stocks than the Ticks, it reacts faster than the Ticks, and will often signal something interesting before the Ticks. As the Ticks can be displayed as a bar chart, it can be interpreted like a price bar chart, using concepts such as support and resistance and trend lines. The Ticks can be used independently, or as part of a larger trading system.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2mLv0B3DXDA",
        "outputId": "504d565a-f403-497f-e780-c7b3513b488d"
      },
      "source": [
        "labels = train.Label.to_list()\n",
        "print(labels[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__label__dt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeITJ0DSDZum"
      },
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqPkvbQpFc3c",
        "outputId": "dd9ac6e9-5a64-4bd4-f2a6-1a2a8848fd24"
      },
      "source": [
        "n_gpu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lz6gPqqDJcmj"
      },
      "source": [
        "### Bert Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qIl1-yvFeMG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "ae824e242b82499387acf8c8fb54c478",
            "9ece846a6ebb4001a6054456b25ea0a5",
            "8cef1460b26c4fb0ad85323cc421a336",
            "068315e1ded34ec7b1ef9d1142bf984b",
            "554634678699492c8702a7b5fffbd84d",
            "a4752cbc46f84395a9958054b99c5be6",
            "553772627ec240af9eb8345d2e53f781",
            "0a16bd938be6406ca96fc2e0528fbbbc"
          ]
        },
        "outputId": "cbf40aa5-57d8-465e-f1a4-f970a7d8461c"
      },
      "source": [
        "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
        "import logging\n",
        "#logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "# Load pre-trained model tokenizer (vocabulary)\n",
        "tokenizer_bert = BertTokenizer.from_pretrained('bert-base-uncased', output_hidden_states = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ae824e242b82499387acf8c8fb54c478",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eMKiLrXGgdo"
      },
      "source": [
        "### Tokenization using XLNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3grhQzzHY5KO",
        "outputId": "7b2bac79-5d32-4595-98ca-7dc266f85f3b"
      },
      "source": [
        "list(tokenizer_bert.vocab.keys())[5000:5020]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['knight',\n",
              " 'lap',\n",
              " 'survey',\n",
              " 'ma',\n",
              " '##ow',\n",
              " 'noise',\n",
              " 'billy',\n",
              " '##ium',\n",
              " 'shooting',\n",
              " 'guide',\n",
              " 'bedroom',\n",
              " 'priest',\n",
              " 'resistance',\n",
              " 'motor',\n",
              " 'homes',\n",
              " 'sounded',\n",
              " 'giant',\n",
              " '##mer',\n",
              " '150',\n",
              " 'scenes']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWp7tTttGbKP",
        "outputId": "a817e434-b200-429b-c343-93c82cc97065"
      },
      "source": [
        "!pip install sentencepiece\n",
        "vocabulary = '/content/drive/My Drive/Colab Notebooks/xlnet-base-cased-spiece.model'\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (0.1.94)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgcAUOTgGn2A"
      },
      "source": [
        "max_len  = 256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BswrMpy2GsZM"
      },
      "source": [
        "# With cased model, set do_lower_case = False\n",
        "#tokenizer_xlnet = XLNetTokenizer(vocab_file=vocabulary,do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCRtEf1LGyfK",
        "outputId": "e01111f7-6413-4059-b494-2e55a085cafa"
      },
      "source": [
        "var = tokenizer_bert(\"god is great , the movie's not\")\n",
        "print(var['input_ids'])\n",
        "print(var['token_type_ids'])\n",
        "print(var['attention_mask'])\n",
        "print(tokenizer_bert.tokenize(\"god is great , the movie's not\"))\n",
        "print(tokenizer_bert.encode('_god'))\n",
        "print(tokenizer_bert.decode(101))\n",
        "print(tokenizer_bert.decode(102))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[101, 2643, 2003, 2307, 1010, 1996, 3185, 1005, 1055, 2025, 102]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "['god', 'is', 'great', ',', 'the', 'movie', \"'\", 's', 'not']\n",
            "[101, 1035, 2643, 102]\n",
            "[ C L S ]\n",
            "[ S E P ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgVBSuE9G5KP"
      },
      "source": [
        "# var = tokenizer_bert(\"god is great , the movie's not\")\n",
        "# print(var['input_ids'])\n",
        "# print(var['token_type_ids'])\n",
        "# print(var['attention_mask'])\n",
        "# print(tokenizer_xlnet.tokenize(\"god is great , the movie's not\"))\n",
        "# print(tokenizer_xlnet.encode('_god'))\n",
        "# print(tokenizer_xlnet.decode(3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3s_vRruHFNS",
        "outputId": "21e3f321-8823-4c2a-97c9-adffe505713b"
      },
      "source": [
        "tokenizer_bert.encode('word')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[101, 2773, 102]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiW8FPVIHsEz"
      },
      "source": [
        "#tokenizer_xlnet.encode('word')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edIgy3fmHy0N"
      },
      "source": [
        "### BERT Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eHPrQKdHt2k",
        "outputId": "928f1b57-19c3-4817-f020-49028a468f22"
      },
      "source": [
        "var = tokenizer_bert(['This is great world.','World is good.'], add_special_tokens= True, max_length=20,  padding= 'max_length', return_attention_mask=True )\n",
        "var"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [[101, 2023, 2003, 2307, 2088, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2088, 2003, 2204, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "231gC7G1JoxJ"
      },
      "source": [
        "tokenized_text_bert = tokenizer_bert(list(train.Text.values), \n",
        "                                     add_special_tokens= True,\n",
        "                                     max_length=256,  \n",
        "                                     padding= 'max_length', \n",
        "                                     return_attention_mask=True,\n",
        "                                     return_tensors='pt', \n",
        "                                     truncation=True )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIyOHcoIsxtU"
      },
      "source": [
        "# tokenized_text_xl = tokenizer_xlnet( vocabulary, max_length=256,add_special_tokens =True , padding= 'max_length', return_tensors='pt',truncation=True )\n",
        "# tokenized_text_xl.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLTfWEA3SG1-"
      },
      "source": [
        "tokenizedtext_bert_test = tokenizer_bert(list(test.Text.values), \n",
        "                                     add_special_tokens= True,\n",
        "                                     max_length=256,  \n",
        "                                     padding= 'max_length', \n",
        "                                     return_attention_mask=True,\n",
        "                                     return_tensors='pt', \n",
        "                                     truncation=True \n",
        "    \n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WROl8wjES5DU"
      },
      "source": [
        "# train.Text.values[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRsGwDgrTDou",
        "outputId": "32e1f4f6-57ab-4539-f404-fa740873b362"
      },
      "source": [
        "#print((tokenized_text['input_ids'][:2]))\n",
        "tokenized_text_bert.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-eRBKFUNZJD",
        "outputId": "609bc3eb-3a42-4f94-95fb-8bc1c00b3cfd"
      },
      "source": [
        "input_ids = tokenized_text_bert['input_ids']\n",
        "attention_masks = tokenized_text_bert['attention_mask']\n",
        "Y [:10]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 4, 14, 14, 12, 12, 12, 16, 12, 20, 12])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gC-6nUr2Sb2C"
      },
      "source": [
        "inputid_test = tokenizedtext_bert_test['input_ids']\n",
        "attentionmask_test = tokenizedtext_bert_test['attention_mask']\n",
        "Y_val = torch.Tensor(Y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWKUVPERDdrl"
      },
      "source": [
        "# from transformers import BertTokenizer\n",
        "\n",
        "# # Load the BERT tokenizer.\n",
        "# print('Loading BERT tokenizer...')\n",
        "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "# max_len = 0\n",
        "\n",
        "# # For every sentence...\n",
        "# for sent in sentences:\n",
        "\n",
        "#     # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "#     input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "\n",
        "#     # Update the maximum sentence length.\n",
        "#     max_len = max(max_len, len(input_ids))\n",
        "\n",
        "# print('Max sentence length: ', max_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSojfbvNU-l2"
      },
      "source": [
        "#tokenized_text['token_type_ids'][:2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b7c1062d1402433ba516b128a8c8c3bb",
            "e48bd79373764e55b0a2a8b8c3d6b67e",
            "8d1f7168bebf47beafd18ec45a1c5334",
            "6f55329118564b3792c04a67e5c7a9b2",
            "efc9df13de48461fa35f51d738aef169",
            "f1959cfe09b54243bbcc6a6474ef8f74",
            "d2d0f178333d419bae81b8c113a598a4",
            "cff91deaeb3f4bc69a950736fc72926c",
            "b863c4fc317847a898533ee76f357106",
            "d8dabc2be1c24c55acb477d9e1a07aec",
            "eabe21a4c98840498e6efc26aa7e9483",
            "2c755b19a07b4529b22f3a728faa845e",
            "759135d77825437788af32ad637e1bf0",
            "50be2e9edb784384a7b251f2a36d5451",
            "1f3b356e20694a158510ac83bfbaf6d9",
            "2343e466de5d4c1ea3a4e82dfd8dd4c5"
          ]
        },
        "id": "UTI4OGrGban5",
        "outputId": "b6a41b87-2b19-47e1-aa2f-06f704d3bafa"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 26, # The number of output \n",
        "    \n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b7c1062d1402433ba516b128a8c8c3bb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b863c4fc317847a898533ee76f357106",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=26, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlNLMKhxfYPd",
        "outputId": "e6526562-4e5d-4d48-89db-52361e5987ea"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                          (26, 768)\n",
            "classifier.bias                                                (26,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzR2VKYisskN"
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 5e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgya1C45QdWG",
        "outputId": "4cd81a55-e41d-4432-ff29-35c1587315d9"
      },
      "source": [
        "Y = torch.tensor(Y)\n",
        "#Y_val = torch.tensor(Y_val)\n",
        "Y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 4, 14, 14,  ...,  1, 12,  5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnhyNvwqCoui",
        "outputId": "e31f1a17-f272-45e6-fd24-1866e06bca41"
      },
      "source": [
        "Y_val = torch.tensor(Y_val, dtype=torch.long)\n",
        "Y_val"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([13, 13, 13,  ...,  9,  9,  9])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgHkjb3RANPM"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "train_dataset = TensorDataset(input_ids, attention_masks, Y ) #labels = Y\n",
        "val_dataset = TensorDataset(inputid_test,attentionmask_test,Y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9TJIgSdQ8co",
        "outputId": "46d8833b-d717-4da3-ceaa-f9949cff1250"
      },
      "source": [
        "train_dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataset.TensorDataset at 0x7fd359773da0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "It7joUSR9EWt"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 32\n",
        "\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLOMvjQ8ff5z",
        "outputId": "820e044b-353c-4595-f383-2c29e6c37c89"
      },
      "source": [
        "for batch in validation_dataloader:\n",
        "  print((batch[2].to(device)))\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
            "        13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13],\n",
            "       device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S20RgSHDIqgH",
        "outputId": "f955de28-1921-4d51-f7d2-394a9e1bcf51"
      },
      "source": [
        "for batch in train_dataloader:\n",
        "  print((batch[2].to(device)))\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([22, 16, 12, 22,  9, 17, 19, 12,  8, 12, 22, 12,  3, 12, 14, 22, 12,  1,\n",
            "        12,  1, 24, 17, 13, 22,  4, 14,  5,  1,  9, 12, 12, 20],\n",
            "       device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQ26wPBn15Gz"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 8\n",
        "batch_size = 32\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HARjQ0ub1-Mz"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbW-2yNSy-K3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DPChyj5vIKw",
        "outputId": "062973ba-5bcc-4e9a-8586-aef359c99863"
      },
      "source": [
        "import numpy as np\n",
        "a  = np.array([[0., 0.03,.01, 0., 0.02,.1,0.0, 0.5,.2,.1], [0., 0.03,.01, 0., 0.02,.1,0.0, 0.5,.2,.1], [0., 0.03,.01, 0., 0.02,.1,0.0, 0.5,.2,.1],[0., 0.03,.01, 0., 0.02,.1,0.0, 0.5,.2,.1]])\n",
        "a"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.  , 0.03, 0.01, 0.  , 0.02, 0.1 , 0.  , 0.5 , 0.2 , 0.1 ],\n",
              "       [0.  , 0.03, 0.01, 0.  , 0.02, 0.1 , 0.  , 0.5 , 0.2 , 0.1 ],\n",
              "       [0.  , 0.03, 0.01, 0.  , 0.02, 0.1 , 0.  , 0.5 , 0.2 , 0.1 ],\n",
              "       [0.  , 0.03, 0.01, 0.  , 0.02, 0.1 , 0.  , 0.5 , 0.2 , 0.1 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aF15qyKwKZm"
      },
      "source": [
        "#conf(np.argmax(a), truelabe)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jvw9WFGT2DOO"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oC2OLL1iZ4_-"
      },
      "source": [
        "def wipe_memory(self): # DOES WORK\n",
        "    self._optimizer_to(torch.device('cpu'))\n",
        "    del self.optimizer\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "def _optimizer_to(self, device):\n",
        "    for param in self.optimizer.state.values():\n",
        "        # Not sure there are any global tensors in the state dict\n",
        "        if isinstance(param, torch.Tensor):\n",
        "            param.data = param.data.to(device)\n",
        "            if param._grad is not None:\n",
        "                param._grad.data = param._grad.data.to(device)\n",
        "        elif isinstance(param, dict):\n",
        "            for subparam in param.values():\n",
        "                if isinstance(subparam, torch.Tensor):\n",
        "                    subparam.data = subparam.data.to(device)\n",
        "                    if subparam._grad is not None:\n",
        "                        subparam._grad.data = subparam._grad.data.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVCkzWE82IMx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1506966d-68db-4829-a4ab-eed5c9623c6f"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "      \n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        if torch.cuda.is_available():\n",
        "          b_input_ids = batch[0].to(device)\n",
        "          b_input_mask = batch[1].to(device)\n",
        "          b_labels = batch[2].to(device)\n",
        "        else:\n",
        "          torch.cuda.empty_cache()\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # arge given and what flags are set. For our useage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\n",
        "        # outputs prior to activation.\n",
        "        if torch.cuda.is_available():\n",
        "          loss, logits = model(b_input_ids, \n",
        "                              token_type_ids=None, \n",
        "                              attention_mask=b_input_mask, \n",
        "                              labels=b_labels)\n",
        "        else:\n",
        "          torch.cuda.empty_cache()\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    predictions = [] #store prediction\n",
        "    true_labels = []\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        " \n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            if torch.cuda.is_available():\n",
        "              (loss, logits) = model(b_input_ids, \n",
        "              token_type_ids=None, \n",
        "              attention_mask=b_input_mask,\n",
        "              labels=b_labels)\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        #collect predictions\n",
        "        # \n",
        "        pred = np.argmax(logits, 1)\n",
        "        predictions.append(pred)\n",
        "        #prediction.append(logits)\n",
        "        true_labels.append(label_ids)\n",
        "\n",
        "      \n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 8 ========\n",
            "Training...\n",
            "  Batch    40  of    550.    Elapsed: 0:00:18.\n",
            "  Batch    80  of    550.    Elapsed: 0:00:36.\n",
            "  Batch   120  of    550.    Elapsed: 0:00:54.\n",
            "  Batch   160  of    550.    Elapsed: 0:01:12.\n",
            "  Batch   200  of    550.    Elapsed: 0:01:31.\n",
            "  Batch   240  of    550.    Elapsed: 0:01:49.\n",
            "  Batch   280  of    550.    Elapsed: 0:02:07.\n",
            "  Batch   320  of    550.    Elapsed: 0:02:25.\n",
            "  Batch   360  of    550.    Elapsed: 0:02:43.\n",
            "  Batch   400  of    550.    Elapsed: 0:03:01.\n",
            "  Batch   440  of    550.    Elapsed: 0:03:19.\n",
            "  Batch   480  of    550.    Elapsed: 0:03:37.\n",
            "  Batch   520  of    550.    Elapsed: 0:03:55.\n",
            "\n",
            "  Average training loss: 1.22\n",
            "  Training epcoh took: 0:04:09\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.74\n",
            "  Validation Loss: 0.88\n",
            "  Validation took: 0:00:10\n",
            "\n",
            "======== Epoch 2 / 8 ========\n",
            "Training...\n",
            "  Batch    40  of    550.    Elapsed: 0:00:18.\n",
            "  Batch    80  of    550.    Elapsed: 0:00:36.\n",
            "  Batch   120  of    550.    Elapsed: 0:00:54.\n",
            "  Batch   160  of    550.    Elapsed: 0:01:13.\n",
            "  Batch   200  of    550.    Elapsed: 0:01:31.\n",
            "  Batch   240  of    550.    Elapsed: 0:01:49.\n",
            "  Batch   280  of    550.    Elapsed: 0:02:07.\n",
            "  Batch   320  of    550.    Elapsed: 0:02:25.\n",
            "  Batch   360  of    550.    Elapsed: 0:02:43.\n",
            "  Batch   400  of    550.    Elapsed: 0:03:01.\n",
            "  Batch   440  of    550.    Elapsed: 0:03:20.\n",
            "  Batch   480  of    550.    Elapsed: 0:03:38.\n",
            "  Batch   520  of    550.    Elapsed: 0:03:56.\n",
            "\n",
            "  Average training loss: 0.61\n",
            "  Training epcoh took: 0:04:09\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.76\n",
            "  Validation Loss: 0.86\n",
            "  Validation took: 0:00:10\n",
            "\n",
            "======== Epoch 3 / 8 ========\n",
            "Training...\n",
            "  Batch    40  of    550.    Elapsed: 0:00:18.\n",
            "  Batch    80  of    550.    Elapsed: 0:00:36.\n",
            "  Batch   120  of    550.    Elapsed: 0:00:54.\n",
            "  Batch   160  of    550.    Elapsed: 0:01:13.\n",
            "  Batch   200  of    550.    Elapsed: 0:01:31.\n",
            "  Batch   240  of    550.    Elapsed: 0:01:49.\n",
            "  Batch   280  of    550.    Elapsed: 0:02:07.\n",
            "  Batch   320  of    550.    Elapsed: 0:02:25.\n",
            "  Batch   360  of    550.    Elapsed: 0:02:43.\n",
            "  Batch   400  of    550.    Elapsed: 0:03:02.\n",
            "  Batch   440  of    550.    Elapsed: 0:03:20.\n",
            "  Batch   480  of    550.    Elapsed: 0:03:38.\n",
            "  Batch   520  of    550.    Elapsed: 0:03:56.\n",
            "\n",
            "  Average training loss: 0.34\n",
            "  Training epcoh took: 0:04:10\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.75\n",
            "  Validation Loss: 0.92\n",
            "  Validation took: 0:00:10\n",
            "\n",
            "======== Epoch 4 / 8 ========\n",
            "Training...\n",
            "  Batch    40  of    550.    Elapsed: 0:00:18.\n",
            "  Batch    80  of    550.    Elapsed: 0:00:36.\n",
            "  Batch   120  of    550.    Elapsed: 0:00:54.\n",
            "  Batch   160  of    550.    Elapsed: 0:01:13.\n",
            "  Batch   200  of    550.    Elapsed: 0:01:31.\n",
            "  Batch   240  of    550.    Elapsed: 0:01:49.\n",
            "  Batch   280  of    550.    Elapsed: 0:02:07.\n",
            "  Batch   320  of    550.    Elapsed: 0:02:25.\n",
            "  Batch   360  of    550.    Elapsed: 0:02:43.\n",
            "  Batch   400  of    550.    Elapsed: 0:03:02.\n",
            "  Batch   440  of    550.    Elapsed: 0:03:20.\n",
            "  Batch   480  of    550.    Elapsed: 0:03:38.\n",
            "  Batch   520  of    550.    Elapsed: 0:03:56.\n",
            "\n",
            "  Average training loss: 0.18\n",
            "  Training epcoh took: 0:04:09\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.75\n",
            "  Validation Loss: 1.06\n",
            "  Validation took: 0:00:10\n",
            "\n",
            "======== Epoch 5 / 8 ========\n",
            "Training...\n",
            "  Batch    40  of    550.    Elapsed: 0:00:18.\n",
            "  Batch    80  of    550.    Elapsed: 0:00:36.\n",
            "  Batch   120  of    550.    Elapsed: 0:00:54.\n",
            "  Batch   160  of    550.    Elapsed: 0:01:12.\n",
            "  Batch   200  of    550.    Elapsed: 0:01:31.\n",
            "  Batch   240  of    550.    Elapsed: 0:01:49.\n",
            "  Batch   280  of    550.    Elapsed: 0:02:07.\n",
            "  Batch   320  of    550.    Elapsed: 0:02:25.\n",
            "  Batch   360  of    550.    Elapsed: 0:02:43.\n",
            "  Batch   400  of    550.    Elapsed: 0:03:01.\n",
            "  Batch   440  of    550.    Elapsed: 0:03:19.\n",
            "  Batch   480  of    550.    Elapsed: 0:03:37.\n",
            "  Batch   520  of    550.    Elapsed: 0:03:55.\n",
            "\n",
            "  Average training loss: 0.10\n",
            "  Training epcoh took: 0:04:09\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.75\n",
            "  Validation Loss: 1.21\n",
            "  Validation took: 0:00:10\n",
            "\n",
            "======== Epoch 6 / 8 ========\n",
            "Training...\n",
            "  Batch    40  of    550.    Elapsed: 0:00:18.\n",
            "  Batch    80  of    550.    Elapsed: 0:00:36.\n",
            "  Batch   120  of    550.    Elapsed: 0:00:54.\n",
            "  Batch   160  of    550.    Elapsed: 0:01:12.\n",
            "  Batch   200  of    550.    Elapsed: 0:01:30.\n",
            "  Batch   240  of    550.    Elapsed: 0:01:48.\n",
            "  Batch   280  of    550.    Elapsed: 0:02:06.\n",
            "  Batch   320  of    550.    Elapsed: 0:02:24.\n",
            "  Batch   360  of    550.    Elapsed: 0:02:43.\n",
            "  Batch   400  of    550.    Elapsed: 0:03:01.\n",
            "  Batch   440  of    550.    Elapsed: 0:03:19.\n",
            "  Batch   480  of    550.    Elapsed: 0:03:37.\n",
            "  Batch   520  of    550.    Elapsed: 0:03:55.\n",
            "\n",
            "  Average training loss: 0.05\n",
            "  Training epcoh took: 0:04:08\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.75\n",
            "  Validation Loss: 1.31\n",
            "  Validation took: 0:00:10\n",
            "\n",
            "======== Epoch 7 / 8 ========\n",
            "Training...\n",
            "  Batch    40  of    550.    Elapsed: 0:00:18.\n",
            "  Batch    80  of    550.    Elapsed: 0:00:36.\n",
            "  Batch   120  of    550.    Elapsed: 0:00:54.\n",
            "  Batch   160  of    550.    Elapsed: 0:01:12.\n",
            "  Batch   200  of    550.    Elapsed: 0:01:30.\n",
            "  Batch   240  of    550.    Elapsed: 0:01:48.\n",
            "  Batch   280  of    550.    Elapsed: 0:02:06.\n",
            "  Batch   320  of    550.    Elapsed: 0:02:24.\n",
            "  Batch   360  of    550.    Elapsed: 0:02:42.\n",
            "  Batch   440  of    550.    Elapsed: 0:03:18.\n",
            "  Batch   480  of    550.    Elapsed: 0:03:36.\n",
            "  Batch   520  of    550.    Elapsed: 0:03:54.\n",
            "\n",
            "  Average training loss: 0.02\n",
            "  Training epcoh took: 0:04:07\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.74\n",
            "  Validation Loss: 1.45\n",
            "  Validation took: 0:00:10\n",
            "\n",
            "======== Epoch 8 / 8 ========\n",
            "Training...\n",
            "  Batch    40  of    550.    Elapsed: 0:00:18.\n",
            "  Batch    80  of    550.    Elapsed: 0:00:36.\n",
            "  Batch   120  of    550.    Elapsed: 0:00:54.\n",
            "  Batch   160  of    550.    Elapsed: 0:01:12.\n",
            "  Batch   200  of    550.    Elapsed: 0:01:30.\n",
            "  Batch   240  of    550.    Elapsed: 0:01:48.\n",
            "  Batch   280  of    550.    Elapsed: 0:02:06.\n",
            "  Batch   320  of    550.    Elapsed: 0:02:24.\n",
            "  Batch   360  of    550.    Elapsed: 0:02:42.\n",
            "  Batch   400  of    550.    Elapsed: 0:03:00.\n",
            "  Batch   440  of    550.    Elapsed: 0:03:18.\n",
            "  Batch   480  of    550.    Elapsed: 0:03:36.\n",
            "  Batch   520  of    550.    Elapsed: 0:03:54.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Training epcoh took: 0:04:07\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.75\n",
            "  Validation Loss: 1.45\n",
            "  Validation took: 0:00:10\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:34:26 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTIrQas82MUY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "69e6d104-e07e-4ad2-b97d-a0a7c979bc96"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.22</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0:04:09</td>\n",
              "      <td>0:00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.61</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0:04:09</td>\n",
              "      <td>0:00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.34</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0:04:10</td>\n",
              "      <td>0:00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.18</td>\n",
              "      <td>1.06</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0:04:09</td>\n",
              "      <td>0:00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.10</td>\n",
              "      <td>1.21</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0:04:09</td>\n",
              "      <td>0:00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.05</td>\n",
              "      <td>1.31</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0:04:08</td>\n",
              "      <td>0:00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.02</td>\n",
              "      <td>1.45</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0:04:07</td>\n",
              "      <td>0:00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.01</td>\n",
              "      <td>1.45</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0:04:07</td>\n",
              "      <td>0:00:10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               1.22         0.88           0.74       0:04:09         0:00:10\n",
              "2               0.61         0.86           0.76       0:04:09         0:00:10\n",
              "3               0.34         0.92           0.75       0:04:10         0:00:10\n",
              "4               0.18         1.06           0.75       0:04:09         0:00:10\n",
              "5               0.10         1.21           0.75       0:04:09         0:00:10\n",
              "6               0.05         1.31           0.75       0:04:08         0:00:10\n",
              "7               0.02         1.45           0.74       0:04:07         0:00:10\n",
              "8               0.01         1.45           0.75       0:04:07         0:00:10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YG9bnIFZ2PNf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "571f53e1-ebf0-4d94-ab00-c227f4adeb8a"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4,5,6,7,8])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znqIQ1EO2TSM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a58bf5dd-96f5-4a12-d984-5d48996543b7"
      },
      "source": [
        "# Testing on val set\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "total_eval_accuracy = 0\n",
        "total_eval_loss = 0\n",
        "nb_eval_steps = 0\n",
        "prediction = [] #store prediction\n",
        "\n",
        "# Evaluate data for one epoch\n",
        "for batch in validation_dataloader:\n",
        "    \n",
        "    # Unpack this training batch from our dataloader. \n",
        "    #\n",
        "    # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "    # the `to` method.\n",
        "    #\n",
        "    # `batch` contains three pytorch tensors:\n",
        "    #   [0]: input ids \n",
        "    #   [1]: attention masks\n",
        "    #   [2]: labels \n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_labels = batch[2].to(device)\n",
        "\n",
        "    \n",
        "    # Tell pytorch not to bother with constructing the compute graph during\n",
        "    # the forward pass, since this is only needed for backprop (training).\n",
        "    with torch.no_grad():        \n",
        "\n",
        "        # Forward pass, calculate logit predictions.\n",
        "        # token_type_ids is the same as the \"segment ids\", which \n",
        "        # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        (loss, logits) = model(b_input_ids, \n",
        "                                token_type_ids=None, \n",
        "                                attention_mask=b_input_mask,\n",
        "                                labels=b_labels)\n",
        "        \n",
        "    # Accumulate the validation loss.\n",
        "    total_eval_loss += loss.item()\n",
        "\n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    #collect predictions\n",
        "    # \n",
        "    pred = np.argmax(logits, 1)\n",
        "    prediction.append(pred)\n",
        "\n",
        "    # Calculate the accuracy for this batch of test sentences, and\n",
        "    # accumulate it over all batches.\n",
        "    total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "    \n",
        "\n",
        "# Report the final accuracy for this validation run.\n",
        "avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "# # Calculate the average loss over all of the batches.\n",
        "# avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "\n",
        "# # Measure how long the validation run took.\n",
        "# validation_time = format_time(time.time() - t0)\n",
        "\n",
        "print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "\n",
        "#print('Positive samples: %d of %d (%.2f%%)' % (train.label.sum(), len(train.label), (train.label.sum() / len(train.label) * 100.0)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.75\n",
            "  Validation Loss: 1.45\n",
            "  Validation took: 0:00:10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGFSsPwihqz5"
      },
      "source": [
        "# import os\n",
        "\n",
        "# # Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "# output_dir = '/content/drive/My Drive/Colab Notebooks/BERT/'\n",
        "\n",
        "# # Create output directory if needed\n",
        "# if not os.path.exists(output_dir):\n",
        "#     os.makedirs(output_dir)\n",
        "\n",
        "# print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# # Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# # They can then be reloaded using `from_pretrained()`\n",
        "# model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "# model_to_save.save_pretrained(output_dir)\n",
        "# tokenizer_bert.save_pretrained(output_dir)\n",
        "\n",
        "# # Good practice: save your training arguments together with the trained model\n",
        "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHnJluvF7BDl"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "#flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "flat_true_labels = [item for sublist in true_labels for item in sublist]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiFkZ1iRhxuf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40ad5447-f280-4508-d2ea-cf0d3e021832"
      },
      "source": [
        "len(flat_predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2210"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hbg517R6hzP7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cfe83ca-6f7d-4dac-f147-6627bf5b8fdc"
      },
      "source": [
        "len(flat_true_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2210"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uk-GrzKxh01C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8d04958-4f9c-4444-aad8-551d30f2e046"
      },
      "source": [
        "%matplotlib inline\r\n",
        "print(classification_report(flat_true_labels, flat_predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.37      0.58      0.45        31\n",
            "           1       0.84      0.72      0.77       180\n",
            "           2       0.63      0.63      0.63        30\n",
            "           3       0.56      0.71      0.62        69\n",
            "           4       0.65      0.57      0.61       150\n",
            "           5       0.89      0.91      0.90        46\n",
            "           6       0.50      0.70      0.58        10\n",
            "           7       0.00      0.00      0.00         2\n",
            "           8       0.85      0.55      0.67        20\n",
            "           9       0.78      0.72      0.75        83\n",
            "          10       0.12      0.15      0.14        33\n",
            "          11       0.77      0.63      0.69        27\n",
            "          12       0.90      0.81      0.85       614\n",
            "          13       0.59      0.64      0.61       188\n",
            "          14       0.61      0.64      0.62       138\n",
            "          15       0.60      0.60      0.60         5\n",
            "          16       0.76      0.88      0.82        91\n",
            "          17       0.98      1.00      0.99        41\n",
            "          18       0.62      0.83      0.71        12\n",
            "          19       0.84      0.80      0.82        46\n",
            "          20       0.81      0.75      0.77        83\n",
            "          21       0.93      0.96      0.94        52\n",
            "          22       0.82      0.97      0.89       229\n",
            "          23       0.80      0.71      0.75        17\n",
            "          24       0.33      0.42      0.37        12\n",
            "          25       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.75      2210\n",
            "   macro avg       0.64      0.65      0.64      2210\n",
            "weighted avg       0.77      0.75      0.76      2210\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytaJht6giGoD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d4ebd30-bda1-4f61-b2da-f3e55d648c20"
      },
      "source": [
        "from sklearn.metrics import f1_score\r\n",
        "f1_score(flat_true_labels, flat_predictions, average='micro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7547511312217194"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkEqcbHxg1oi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5accbbfc-1d3e-4969-ae63-b9e9a88c7e54"
      },
      "source": [
        "f1_score(flat_true_labels, flat_predictions, average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6375211074865211"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8lL2wK8scI1",
        "outputId": "20fc0f39-9c57-43cc-c389-c8ab174973f5"
      },
      "source": [
        "f1_score(flat_true_labels, flat_predictions, average='weighted')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7577297437537398"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzoI1QUYsyBH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}